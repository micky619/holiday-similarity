{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.core import Activation, Dense, Dropout, Lambda\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [2]:\n",
    "DATA_DIR = \"\"\n",
    "IMAGE_DIR = os.path.join(DATA_DIR, \"images\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 900 pos + 900 neg = 1800 total image triples\n",
      "Generated 1656 pos + 1656 neg = 3312 total image triples\n"
     ]
    }
   ],
   "source": [
    "image_groups = {}\n",
    "for image_name in os.listdir(IMAGE_DIR):\n",
    "    base_name = image_name[0:-4]\n",
    "    group_name = base_name[0:4]\n",
    "    if group_name in image_groups:\n",
    "        image_groups[group_name].append(image_name)\n",
    "    else:\n",
    "        image_groups[group_name] = [image_name]\n",
    "num_sims = 0\n",
    "image_triples = []\n",
    "group_list = sorted(list(image_groups.keys()))\n",
    "for i, g in enumerate(group_list):\n",
    "    if num_sims % 100 == 0:\n",
    "        print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\"\n",
    "                .format(num_sims, num_sims, 2*num_sims))\n",
    "    images_in_group = image_groups[g]\n",
    "    sim_pairs_it = itertools.combinations(images_in_group, 2)\n",
    "    # for each similar pair, generate a corresponding different pair\n",
    "    for ref_image, sim_image in sim_pairs_it:\n",
    "        image_triples.append((ref_image, sim_image, 1))\n",
    "        num_sims += 1\n",
    "        while True:\n",
    "            j = np.random.randint(low=0, high=len(group_list), size=1)[0]\n",
    "            if j != i:\n",
    "                break\n",
    "        dif_image_candidates = image_groups[group_list[j]]\n",
    "        k = np.random.randint(low=0, high=len(dif_image_candidates), size=1)[0]\n",
    "        dif_image = dif_image_candidates[k]\n",
    "        image_triples.append((ref_image, dif_image, 0))\n",
    "print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\"\n",
    "        .format(num_sims, num_sims, 2*num_sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('010006.jpg', '010003.jpg', 1),\n",
       " ('010006.jpg', '400009.jpg', 0),\n",
       " ('010006.jpg', '010004.jpg', 1),\n",
       " ('010006.jpg', '390001.jpg', 0),\n",
       " ('010006.jpg', '010007.jpg', 1),\n",
       " ('010006.jpg', '150007.jpg', 0),\n",
       " ('010006.jpg', '010001.jpg', 1),\n",
       " ('010006.jpg', '120003.jpg', 0),\n",
       " ('010006.jpg', '010005.jpg', 1),\n",
       " ('010006.jpg', '170001.jpg', 0),\n",
       " ('010006.jpg', '010008.jpg', 1),\n",
       " ('010006.jpg', '200008.jpg', 0),\n",
       " ('010006.jpg', '010009.jpg', 1),\n",
       " ('010006.jpg', '430009.jpg', 0),\n",
       " ('010006.jpg', '010002.jpg', 1),\n",
       " ('010006.jpg', '390007.jpg', 0),\n",
       " ('010003.jpg', '010004.jpg', 1),\n",
       " ('010003.jpg', '220009.jpg', 0),\n",
       " ('010003.jpg', '010007.jpg', 1),\n",
       " ('010003.jpg', '130008.jpg', 0),\n",
       " ('010003.jpg', '010001.jpg', 1),\n",
       " ('010003.jpg', '050004.jpg', 0),\n",
       " ('010003.jpg', '010005.jpg', 1),\n",
       " ('010003.jpg', '320005.jpg', 0),\n",
       " ('010003.jpg', '010008.jpg', 1),\n",
       " ('010003.jpg', '160001.jpg', 0),\n",
       " ('010003.jpg', '010009.jpg', 1),\n",
       " ('010003.jpg', '370005.jpg', 0),\n",
       " ('010003.jpg', '010002.jpg', 1),\n",
       " ('010003.jpg', '110007.jpg', 0),\n",
       " ('010004.jpg', '010007.jpg', 1),\n",
       " ('010004.jpg', '270009.jpg', 0),\n",
       " ('010004.jpg', '010001.jpg', 1),\n",
       " ('010004.jpg', '040004.jpg', 0),\n",
       " ('010004.jpg', '010005.jpg', 1),\n",
       " ('010004.jpg', '100005.jpg', 0),\n",
       " ('010004.jpg', '010008.jpg', 1),\n",
       " ('010004.jpg', '130003.jpg', 0),\n",
       " ('010004.jpg', '010009.jpg', 1),\n",
       " ('010004.jpg', '400003.jpg', 0),\n",
       " ('010004.jpg', '010002.jpg', 1),\n",
       " ('010004.jpg', '270003.jpg', 0),\n",
       " ('010007.jpg', '010001.jpg', 1),\n",
       " ('010007.jpg', '410003.jpg', 0),\n",
       " ('010007.jpg', '010005.jpg', 1),\n",
       " ('010007.jpg', '300002.jpg', 0),\n",
       " ('010007.jpg', '010008.jpg', 1),\n",
       " ('010007.jpg', '310003.jpg', 0),\n",
       " ('010007.jpg', '010009.jpg', 1),\n",
       " ('010007.jpg', '200008.jpg', 0),\n",
       " ('010007.jpg', '010002.jpg', 1),\n",
       " ('010007.jpg', '230002.jpg', 0),\n",
       " ('010001.jpg', '010005.jpg', 1),\n",
       " ('010001.jpg', '400003.jpg', 0),\n",
       " ('010001.jpg', '010008.jpg', 1),\n",
       " ('010001.jpg', '270008.jpg', 0),\n",
       " ('010001.jpg', '010009.jpg', 1),\n",
       " ('010001.jpg', '100007.jpg', 0),\n",
       " ('010001.jpg', '010002.jpg', 1),\n",
       " ('010001.jpg', '090004.jpg', 0),\n",
       " ('010005.jpg', '010008.jpg', 1),\n",
       " ('010005.jpg', '080008.jpg', 0),\n",
       " ('010005.jpg', '010009.jpg', 1),\n",
       " ('010005.jpg', '220003.jpg', 0),\n",
       " ('010005.jpg', '010002.jpg', 1),\n",
       " ('010005.jpg', '420002.jpg', 0),\n",
       " ('010008.jpg', '010009.jpg', 1),\n",
       " ('010008.jpg', '370008.jpg', 0),\n",
       " ('010008.jpg', '010002.jpg', 1),\n",
       " ('010008.jpg', '460009.jpg', 0),\n",
       " ('010009.jpg', '010002.jpg', 1),\n",
       " ('010009.jpg', '260002.jpg', 0),\n",
       " ('020002.jpg', '020009.jpg', 1),\n",
       " ('020002.jpg', '010007.jpg', 0),\n",
       " ('020002.jpg', '020008.jpg', 1),\n",
       " ('020002.jpg', '290003.jpg', 0),\n",
       " ('020002.jpg', '020005.jpg', 1),\n",
       " ('020002.jpg', '230001.jpg', 0),\n",
       " ('020002.jpg', '020007.jpg', 1),\n",
       " ('020002.jpg', '400009.jpg', 0),\n",
       " ('020002.jpg', '020003.jpg', 1),\n",
       " ('020002.jpg', '430001.jpg', 0),\n",
       " ('020002.jpg', '020001.jpg', 1),\n",
       " ('020002.jpg', '070007.jpg', 0),\n",
       " ('020002.jpg', '020004.jpg', 1),\n",
       " ('020002.jpg', '220006.jpg', 0),\n",
       " ('020002.jpg', '020006.jpg', 1),\n",
       " ('020002.jpg', '240007.jpg', 0),\n",
       " ('020009.jpg', '020008.jpg', 1),\n",
       " ('020009.jpg', '040006.jpg', 0),\n",
       " ('020009.jpg', '020005.jpg', 1),\n",
       " ('020009.jpg', '430008.jpg', 0),\n",
       " ('020009.jpg', '020007.jpg', 1),\n",
       " ('020009.jpg', '350001.jpg', 0),\n",
       " ('020009.jpg', '020003.jpg', 1),\n",
       " ('020009.jpg', '030007.jpg', 0),\n",
       " ('020009.jpg', '020001.jpg', 1),\n",
       " ('020009.jpg', '410002.jpg', 0),\n",
       " ('020009.jpg', '020004.jpg', 1),\n",
       " ('020009.jpg', '130005.jpg', 0),\n",
       " ('020009.jpg', '020006.jpg', 1),\n",
       " ('020009.jpg', '450007.jpg', 0),\n",
       " ('020008.jpg', '020005.jpg', 1),\n",
       " ('020008.jpg', '120008.jpg', 0),\n",
       " ('020008.jpg', '020007.jpg', 1),\n",
       " ('020008.jpg', '380005.jpg', 0),\n",
       " ('020008.jpg', '020003.jpg', 1),\n",
       " ('020008.jpg', '060003.jpg', 0),\n",
       " ('020008.jpg', '020001.jpg', 1),\n",
       " ('020008.jpg', '300008.jpg', 0),\n",
       " ('020008.jpg', '020004.jpg', 1),\n",
       " ('020008.jpg', '140004.jpg', 0),\n",
       " ('020008.jpg', '020006.jpg', 1),\n",
       " ('020008.jpg', '460006.jpg', 0),\n",
       " ('020005.jpg', '020007.jpg', 1),\n",
       " ('020005.jpg', '230002.jpg', 0),\n",
       " ('020005.jpg', '020003.jpg', 1),\n",
       " ('020005.jpg', '010001.jpg', 0),\n",
       " ('020005.jpg', '020001.jpg', 1),\n",
       " ('020005.jpg', '350002.jpg', 0),\n",
       " ('020005.jpg', '020004.jpg', 1),\n",
       " ('020005.jpg', '390001.jpg', 0),\n",
       " ('020005.jpg', '020006.jpg', 1),\n",
       " ('020005.jpg', '360003.jpg', 0),\n",
       " ('020007.jpg', '020003.jpg', 1),\n",
       " ('020007.jpg', '330002.jpg', 0),\n",
       " ('020007.jpg', '020001.jpg', 1),\n",
       " ('020007.jpg', '320005.jpg', 0),\n",
       " ('020007.jpg', '020004.jpg', 1),\n",
       " ('020007.jpg', '180005.jpg', 0),\n",
       " ('020007.jpg', '020006.jpg', 1),\n",
       " ('020007.jpg', '350004.jpg', 0),\n",
       " ('020003.jpg', '020001.jpg', 1),\n",
       " ('020003.jpg', '160007.jpg', 0),\n",
       " ('020003.jpg', '020004.jpg', 1),\n",
       " ('020003.jpg', '410007.jpg', 0),\n",
       " ('020003.jpg', '020006.jpg', 1),\n",
       " ('020003.jpg', '450002.jpg', 0),\n",
       " ('020001.jpg', '020004.jpg', 1),\n",
       " ('020001.jpg', '380009.jpg', 0),\n",
       " ('020001.jpg', '020006.jpg', 1),\n",
       " ('020001.jpg', '390007.jpg', 0),\n",
       " ('020004.jpg', '020006.jpg', 1),\n",
       " ('020004.jpg', '050006.jpg', 0),\n",
       " ('030001.jpg', '030006.jpg', 1),\n",
       " ('030001.jpg', '110008.jpg', 0),\n",
       " ('030001.jpg', '030003.jpg', 1),\n",
       " ('030001.jpg', '400001.jpg', 0),\n",
       " ('030001.jpg', '030002.jpg', 1),\n",
       " ('030001.jpg', '230007.jpg', 0),\n",
       " ('030001.jpg', '030007.jpg', 1),\n",
       " ('030001.jpg', '160001.jpg', 0),\n",
       " ('030001.jpg', '030009.jpg', 1),\n",
       " ('030001.jpg', '440001.jpg', 0),\n",
       " ('030001.jpg', '030008.jpg', 1),\n",
       " ('030001.jpg', '100009.jpg', 0),\n",
       " ('030001.jpg', '030005.jpg', 1),\n",
       " ('030001.jpg', '270008.jpg', 0),\n",
       " ('030001.jpg', '030004.jpg', 1),\n",
       " ('030001.jpg', '230009.jpg', 0),\n",
       " ('030006.jpg', '030003.jpg', 1),\n",
       " ('030006.jpg', '410006.jpg', 0),\n",
       " ('030006.jpg', '030002.jpg', 1),\n",
       " ('030006.jpg', '370006.jpg', 0),\n",
       " ('030006.jpg', '030007.jpg', 1),\n",
       " ('030006.jpg', '070006.jpg', 0),\n",
       " ('030006.jpg', '030009.jpg', 1),\n",
       " ('030006.jpg', '150009.jpg', 0),\n",
       " ('030006.jpg', '030008.jpg', 1),\n",
       " ('030006.jpg', '120004.jpg', 0),\n",
       " ('030006.jpg', '030005.jpg', 1),\n",
       " ('030006.jpg', '010006.jpg', 0),\n",
       " ('030006.jpg', '030004.jpg', 1),\n",
       " ('030006.jpg', '310009.jpg', 0),\n",
       " ('030003.jpg', '030002.jpg', 1),\n",
       " ('030003.jpg', '300006.jpg', 0),\n",
       " ('030003.jpg', '030007.jpg', 1),\n",
       " ('030003.jpg', '130003.jpg', 0),\n",
       " ('030003.jpg', '030009.jpg', 1),\n",
       " ('030003.jpg', '060004.jpg', 0),\n",
       " ('030003.jpg', '030008.jpg', 1),\n",
       " ('030003.jpg', '420007.jpg', 0),\n",
       " ('030003.jpg', '030005.jpg', 1),\n",
       " ('030003.jpg', '380007.jpg', 0),\n",
       " ('030003.jpg', '030004.jpg', 1),\n",
       " ('030003.jpg', '070003.jpg', 0),\n",
       " ('030002.jpg', '030007.jpg', 1),\n",
       " ('030002.jpg', '440003.jpg', 0),\n",
       " ('030002.jpg', '030009.jpg', 1),\n",
       " ('030002.jpg', '300006.jpg', 0),\n",
       " ('030002.jpg', '030008.jpg', 1),\n",
       " ('030002.jpg', '460007.jpg', 0),\n",
       " ('030002.jpg', '030005.jpg', 1),\n",
       " ('030002.jpg', '100005.jpg', 0),\n",
       " ('030002.jpg', '030004.jpg', 1),\n",
       " ('030002.jpg', '410009.jpg', 0),\n",
       " ('030007.jpg', '030009.jpg', 1),\n",
       " ('030007.jpg', '320003.jpg', 0),\n",
       " ('030007.jpg', '030008.jpg', 1),\n",
       " ('030007.jpg', '180006.jpg', 0),\n",
       " ('030007.jpg', '030005.jpg', 1),\n",
       " ('030007.jpg', '110002.jpg', 0),\n",
       " ('030007.jpg', '030004.jpg', 1),\n",
       " ('030007.jpg', '180006.jpg', 0),\n",
       " ('030009.jpg', '030008.jpg', 1),\n",
       " ('030009.jpg', '140006.jpg', 0),\n",
       " ('030009.jpg', '030005.jpg', 1),\n",
       " ('030009.jpg', '430001.jpg', 0),\n",
       " ('030009.jpg', '030004.jpg', 1),\n",
       " ('030009.jpg', '050004.jpg', 0),\n",
       " ('030008.jpg', '030005.jpg', 1),\n",
       " ('030008.jpg', '050005.jpg', 0),\n",
       " ('030008.jpg', '030004.jpg', 1),\n",
       " ('030008.jpg', '390009.jpg', 0),\n",
       " ('030005.jpg', '030004.jpg', 1),\n",
       " ('030005.jpg', '110007.jpg', 0),\n",
       " ('040003.jpg', '040004.jpg', 1),\n",
       " ('040003.jpg', '460002.jpg', 0),\n",
       " ('040003.jpg', '040008.jpg', 1),\n",
       " ('040003.jpg', '090001.jpg', 0),\n",
       " ('040003.jpg', '040006.jpg', 1),\n",
       " ('040003.jpg', '450007.jpg', 0),\n",
       " ('040003.jpg', '040005.jpg', 1),\n",
       " ('040003.jpg', '220002.jpg', 0),\n",
       " ('040003.jpg', '040007.jpg', 1),\n",
       " ('040003.jpg', '390005.jpg', 0),\n",
       " ('040003.jpg', '040009.jpg', 1),\n",
       " ('040003.jpg', '330007.jpg', 0),\n",
       " ('040003.jpg', '040001.jpg', 1),\n",
       " ('040003.jpg', '420007.jpg', 0),\n",
       " ('040003.jpg', '040002.jpg', 1),\n",
       " ('040003.jpg', '010001.jpg', 0),\n",
       " ('040004.jpg', '040008.jpg', 1),\n",
       " ('040004.jpg', '370003.jpg', 0),\n",
       " ('040004.jpg', '040006.jpg', 1),\n",
       " ('040004.jpg', '020008.jpg', 0),\n",
       " ('040004.jpg', '040005.jpg', 1),\n",
       " ('040004.jpg', '320005.jpg', 0),\n",
       " ('040004.jpg', '040007.jpg', 1),\n",
       " ('040004.jpg', '370003.jpg', 0),\n",
       " ('040004.jpg', '040009.jpg', 1),\n",
       " ('040004.jpg', '080008.jpg', 0),\n",
       " ('040004.jpg', '040001.jpg', 1),\n",
       " ('040004.jpg', '430005.jpg', 0),\n",
       " ('040004.jpg', '040002.jpg', 1),\n",
       " ('040004.jpg', '120008.jpg', 0),\n",
       " ('040008.jpg', '040006.jpg', 1),\n",
       " ('040008.jpg', '230005.jpg', 0),\n",
       " ('040008.jpg', '040005.jpg', 1),\n",
       " ('040008.jpg', '280006.jpg', 0),\n",
       " ('040008.jpg', '040007.jpg', 1),\n",
       " ('040008.jpg', '020003.jpg', 0),\n",
       " ('040008.jpg', '040009.jpg', 1),\n",
       " ('040008.jpg', '280006.jpg', 0),\n",
       " ('040008.jpg', '040001.jpg', 1),\n",
       " ('040008.jpg', '210003.jpg', 0),\n",
       " ('040008.jpg', '040002.jpg', 1),\n",
       " ('040008.jpg', '220002.jpg', 0),\n",
       " ('040006.jpg', '040005.jpg', 1),\n",
       " ('040006.jpg', '140006.jpg', 0),\n",
       " ('040006.jpg', '040007.jpg', 1),\n",
       " ('040006.jpg', '250007.jpg', 0),\n",
       " ('040006.jpg', '040009.jpg', 1),\n",
       " ('040006.jpg', '150005.jpg', 0),\n",
       " ('040006.jpg', '040001.jpg', 1),\n",
       " ('040006.jpg', '350007.jpg', 0),\n",
       " ('040006.jpg', '040002.jpg', 1),\n",
       " ('040006.jpg', '380003.jpg', 0),\n",
       " ('040005.jpg', '040007.jpg', 1),\n",
       " ('040005.jpg', '280001.jpg', 0),\n",
       " ('040005.jpg', '040009.jpg', 1),\n",
       " ('040005.jpg', '180004.jpg', 0),\n",
       " ('040005.jpg', '040001.jpg', 1),\n",
       " ('040005.jpg', '370006.jpg', 0),\n",
       " ('040005.jpg', '040002.jpg', 1),\n",
       " ('040005.jpg', '050009.jpg', 0),\n",
       " ('040007.jpg', '040009.jpg', 1),\n",
       " ('040007.jpg', '390003.jpg', 0),\n",
       " ('040007.jpg', '040001.jpg', 1),\n",
       " ('040007.jpg', '070006.jpg', 0),\n",
       " ('040007.jpg', '040002.jpg', 1),\n",
       " ('040007.jpg', '440003.jpg', 0),\n",
       " ('040009.jpg', '040001.jpg', 1),\n",
       " ('040009.jpg', '210007.jpg', 0),\n",
       " ('040009.jpg', '040002.jpg', 1),\n",
       " ('040009.jpg', '180004.jpg', 0),\n",
       " ('040001.jpg', '040002.jpg', 1),\n",
       " ('040001.jpg', '270003.jpg', 0),\n",
       " ('050003.jpg', '050009.jpg', 1),\n",
       " ('050003.jpg', '410004.jpg', 0),\n",
       " ('050003.jpg', '050008.jpg', 1),\n",
       " ('050003.jpg', '410002.jpg', 0),\n",
       " ('050003.jpg', '050002.jpg', 1),\n",
       " ('050003.jpg', '280005.jpg', 0),\n",
       " ('050003.jpg', '050001.jpg', 1),\n",
       " ('050003.jpg', '070007.jpg', 0),\n",
       " ('050003.jpg', '050005.jpg', 1),\n",
       " ('050003.jpg', '380006.jpg', 0),\n",
       " ('050003.jpg', '050004.jpg', 1),\n",
       " ('050003.jpg', '430003.jpg', 0),\n",
       " ('050003.jpg', '050007.jpg', 1),\n",
       " ('050003.jpg', '300008.jpg', 0),\n",
       " ('050003.jpg', '050006.jpg', 1),\n",
       " ('050003.jpg', '410008.jpg', 0),\n",
       " ('050009.jpg', '050008.jpg', 1),\n",
       " ('050009.jpg', '340008.jpg', 0),\n",
       " ('050009.jpg', '050002.jpg', 1),\n",
       " ('050009.jpg', '380004.jpg', 0),\n",
       " ('050009.jpg', '050001.jpg', 1),\n",
       " ('050009.jpg', '300006.jpg', 0),\n",
       " ('050009.jpg', '050005.jpg', 1),\n",
       " ('050009.jpg', '360005.jpg', 0),\n",
       " ('050009.jpg', '050004.jpg', 1),\n",
       " ('050009.jpg', '080001.jpg', 0),\n",
       " ('050009.jpg', '050007.jpg', 1),\n",
       " ('050009.jpg', '070005.jpg', 0),\n",
       " ('050009.jpg', '050006.jpg', 1),\n",
       " ('050009.jpg', '100005.jpg', 0),\n",
       " ('050008.jpg', '050002.jpg', 1),\n",
       " ('050008.jpg', '280003.jpg', 0),\n",
       " ('050008.jpg', '050001.jpg', 1),\n",
       " ('050008.jpg', '010007.jpg', 0),\n",
       " ('050008.jpg', '050005.jpg', 1),\n",
       " ('050008.jpg', '430004.jpg', 0),\n",
       " ('050008.jpg', '050004.jpg', 1),\n",
       " ('050008.jpg', '180004.jpg', 0),\n",
       " ('050008.jpg', '050007.jpg', 1),\n",
       " ('050008.jpg', '100001.jpg', 0),\n",
       " ('050008.jpg', '050006.jpg', 1),\n",
       " ('050008.jpg', '260004.jpg', 0),\n",
       " ('050002.jpg', '050001.jpg', 1),\n",
       " ('050002.jpg', '040007.jpg', 0),\n",
       " ('050002.jpg', '050005.jpg', 1),\n",
       " ('050002.jpg', '320003.jpg', 0),\n",
       " ('050002.jpg', '050004.jpg', 1),\n",
       " ('050002.jpg', '320004.jpg', 0),\n",
       " ('050002.jpg', '050007.jpg', 1),\n",
       " ('050002.jpg', '020009.jpg', 0),\n",
       " ('050002.jpg', '050006.jpg', 1),\n",
       " ('050002.jpg', '070003.jpg', 0),\n",
       " ('050001.jpg', '050005.jpg', 1),\n",
       " ('050001.jpg', '100003.jpg', 0),\n",
       " ('050001.jpg', '050004.jpg', 1),\n",
       " ('050001.jpg', '290008.jpg', 0),\n",
       " ('050001.jpg', '050007.jpg', 1),\n",
       " ('050001.jpg', '250003.jpg', 0),\n",
       " ('050001.jpg', '050006.jpg', 1),\n",
       " ('050001.jpg', '410004.jpg', 0),\n",
       " ('050005.jpg', '050004.jpg', 1),\n",
       " ('050005.jpg', '460002.jpg', 0),\n",
       " ('050005.jpg', '050007.jpg', 1),\n",
       " ('050005.jpg', '020002.jpg', 0),\n",
       " ('050005.jpg', '050006.jpg', 1),\n",
       " ('050005.jpg', '460002.jpg', 0),\n",
       " ('050004.jpg', '050007.jpg', 1),\n",
       " ('050004.jpg', '150006.jpg', 0),\n",
       " ('050004.jpg', '050006.jpg', 1),\n",
       " ('050004.jpg', '450003.jpg', 0),\n",
       " ('050007.jpg', '050006.jpg', 1),\n",
       " ('050007.jpg', '450005.jpg', 0),\n",
       " ('060004.jpg', '060006.jpg', 1),\n",
       " ('060004.jpg', '030005.jpg', 0),\n",
       " ('060004.jpg', '060002.jpg', 1),\n",
       " ('060004.jpg', '350007.jpg', 0),\n",
       " ('060004.jpg', '060001.jpg', 1),\n",
       " ('060004.jpg', '260004.jpg', 0),\n",
       " ('060004.jpg', '060005.jpg', 1),\n",
       " ('060004.jpg', '040009.jpg', 0),\n",
       " ('060004.jpg', '060007.jpg', 1),\n",
       " ('060004.jpg', '170008.jpg', 0),\n",
       " ('060004.jpg', '060009.jpg', 1),\n",
       " ('060004.jpg', '450004.jpg', 0),\n",
       " ('060004.jpg', '060003.jpg', 1),\n",
       " ('060004.jpg', '360002.jpg', 0),\n",
       " ('060004.jpg', '060008.jpg', 1),\n",
       " ('060004.jpg', '190001.jpg', 0),\n",
       " ('060006.jpg', '060002.jpg', 1),\n",
       " ('060006.jpg', '360007.jpg', 0),\n",
       " ('060006.jpg', '060001.jpg', 1),\n",
       " ('060006.jpg', '090009.jpg', 0),\n",
       " ('060006.jpg', '060005.jpg', 1),\n",
       " ('060006.jpg', '050002.jpg', 0),\n",
       " ('060006.jpg', '060007.jpg', 1),\n",
       " ('060006.jpg', '340007.jpg', 0),\n",
       " ('060006.jpg', '060009.jpg', 1),\n",
       " ('060006.jpg', '190005.jpg', 0),\n",
       " ('060006.jpg', '060003.jpg', 1),\n",
       " ('060006.jpg', '180001.jpg', 0),\n",
       " ('060006.jpg', '060008.jpg', 1),\n",
       " ('060006.jpg', '260007.jpg', 0),\n",
       " ('060002.jpg', '060001.jpg', 1),\n",
       " ('060002.jpg', '230008.jpg', 0),\n",
       " ('060002.jpg', '060005.jpg', 1),\n",
       " ('060002.jpg', '420004.jpg', 0),\n",
       " ('060002.jpg', '060007.jpg', 1),\n",
       " ('060002.jpg', '190006.jpg', 0),\n",
       " ('060002.jpg', '060009.jpg', 1),\n",
       " ('060002.jpg', '360001.jpg', 0),\n",
       " ('060002.jpg', '060003.jpg', 1),\n",
       " ('060002.jpg', '130005.jpg', 0),\n",
       " ('060002.jpg', '060008.jpg', 1),\n",
       " ('060002.jpg', '300005.jpg', 0),\n",
       " ('060001.jpg', '060005.jpg', 1),\n",
       " ('060001.jpg', '220003.jpg', 0),\n",
       " ('060001.jpg', '060007.jpg', 1),\n",
       " ('060001.jpg', '450005.jpg', 0),\n",
       " ('060001.jpg', '060009.jpg', 1),\n",
       " ('060001.jpg', '070007.jpg', 0),\n",
       " ('060001.jpg', '060003.jpg', 1),\n",
       " ('060001.jpg', '350005.jpg', 0),\n",
       " ('060001.jpg', '060008.jpg', 1),\n",
       " ('060001.jpg', '120001.jpg', 0),\n",
       " ('060005.jpg', '060007.jpg', 1),\n",
       " ('060005.jpg', '360005.jpg', 0),\n",
       " ('060005.jpg', '060009.jpg', 1),\n",
       " ('060005.jpg', '400008.jpg', 0),\n",
       " ('060005.jpg', '060003.jpg', 1),\n",
       " ('060005.jpg', '350006.jpg', 0),\n",
       " ('060005.jpg', '060008.jpg', 1),\n",
       " ('060005.jpg', '020005.jpg', 0),\n",
       " ('060007.jpg', '060009.jpg', 1),\n",
       " ('060007.jpg', '110009.jpg', 0),\n",
       " ('060007.jpg', '060003.jpg', 1),\n",
       " ('060007.jpg', '110001.jpg', 0),\n",
       " ('060007.jpg', '060008.jpg', 1),\n",
       " ('060007.jpg', '070003.jpg', 0),\n",
       " ('060009.jpg', '060003.jpg', 1),\n",
       " ('060009.jpg', '320008.jpg', 0),\n",
       " ('060009.jpg', '060008.jpg', 1),\n",
       " ('060009.jpg', '420004.jpg', 0),\n",
       " ('060003.jpg', '060008.jpg', 1),\n",
       " ('060003.jpg', '340005.jpg', 0),\n",
       " ('070007.jpg', '070004.jpg', 1),\n",
       " ('070007.jpg', '380007.jpg', 0),\n",
       " ('070007.jpg', '070002.jpg', 1),\n",
       " ('070007.jpg', '360005.jpg', 0),\n",
       " ('070007.jpg', '070005.jpg', 1),\n",
       " ('070007.jpg', '250009.jpg', 0),\n",
       " ('070007.jpg', '070003.jpg', 1),\n",
       " ('070007.jpg', '090001.jpg', 0),\n",
       " ('070007.jpg', '070006.jpg', 1),\n",
       " ('070007.jpg', '240005.jpg', 0),\n",
       " ('070007.jpg', '070008.jpg', 1),\n",
       " ('070007.jpg', '390007.jpg', 0),\n",
       " ('070007.jpg', '070001.jpg', 1),\n",
       " ('070007.jpg', '300006.jpg', 0),\n",
       " ('070007.jpg', '070009.jpg', 1),\n",
       " ('070007.jpg', '290009.jpg', 0),\n",
       " ('070004.jpg', '070002.jpg', 1),\n",
       " ('070004.jpg', '380002.jpg', 0),\n",
       " ('070004.jpg', '070005.jpg', 1),\n",
       " ('070004.jpg', '080007.jpg', 0),\n",
       " ('070004.jpg', '070003.jpg', 1),\n",
       " ('070004.jpg', '060006.jpg', 0),\n",
       " ('070004.jpg', '070006.jpg', 1),\n",
       " ('070004.jpg', '130003.jpg', 0),\n",
       " ('070004.jpg', '070008.jpg', 1),\n",
       " ('070004.jpg', '260003.jpg', 0),\n",
       " ('070004.jpg', '070001.jpg', 1),\n",
       " ('070004.jpg', '030008.jpg', 0),\n",
       " ('070004.jpg', '070009.jpg', 1),\n",
       " ('070004.jpg', '130005.jpg', 0),\n",
       " ('070002.jpg', '070005.jpg', 1),\n",
       " ('070002.jpg', '260009.jpg', 0),\n",
       " ('070002.jpg', '070003.jpg', 1),\n",
       " ('070002.jpg', '020009.jpg', 0),\n",
       " ('070002.jpg', '070006.jpg', 1),\n",
       " ('070002.jpg', '300006.jpg', 0),\n",
       " ('070002.jpg', '070008.jpg', 1),\n",
       " ('070002.jpg', '010005.jpg', 0),\n",
       " ('070002.jpg', '070001.jpg', 1),\n",
       " ('070002.jpg', '110001.jpg', 0),\n",
       " ('070002.jpg', '070009.jpg', 1),\n",
       " ('070002.jpg', '180008.jpg', 0),\n",
       " ('070005.jpg', '070003.jpg', 1),\n",
       " ('070005.jpg', '430003.jpg', 0),\n",
       " ('070005.jpg', '070006.jpg', 1),\n",
       " ('070005.jpg', '090003.jpg', 0),\n",
       " ('070005.jpg', '070008.jpg', 1),\n",
       " ('070005.jpg', '280005.jpg', 0),\n",
       " ('070005.jpg', '070001.jpg', 1),\n",
       " ('070005.jpg', '110005.jpg', 0),\n",
       " ('070005.jpg', '070009.jpg', 1),\n",
       " ('070005.jpg', '120007.jpg', 0),\n",
       " ('070003.jpg', '070006.jpg', 1),\n",
       " ('070003.jpg', '140003.jpg', 0),\n",
       " ('070003.jpg', '070008.jpg', 1),\n",
       " ('070003.jpg', '380004.jpg', 0),\n",
       " ('070003.jpg', '070001.jpg', 1),\n",
       " ('070003.jpg', '020001.jpg', 0),\n",
       " ('070003.jpg', '070009.jpg', 1),\n",
       " ('070003.jpg', '090003.jpg', 0),\n",
       " ('070006.jpg', '070008.jpg', 1),\n",
       " ('070006.jpg', '240006.jpg', 0),\n",
       " ('070006.jpg', '070001.jpg', 1),\n",
       " ('070006.jpg', '010002.jpg', 0),\n",
       " ('070006.jpg', '070009.jpg', 1),\n",
       " ('070006.jpg', '160002.jpg', 0),\n",
       " ('070008.jpg', '070001.jpg', 1),\n",
       " ('070008.jpg', '170004.jpg', 0),\n",
       " ('070008.jpg', '070009.jpg', 1),\n",
       " ('070008.jpg', '220007.jpg', 0),\n",
       " ('070001.jpg', '070009.jpg', 1),\n",
       " ('070001.jpg', '320003.jpg', 0),\n",
       " ('080009.jpg', '080001.jpg', 1),\n",
       " ('080009.jpg', '010005.jpg', 0),\n",
       " ('080009.jpg', '080004.jpg', 1),\n",
       " ('080009.jpg', '300001.jpg', 0),\n",
       " ('080009.jpg', '080002.jpg', 1),\n",
       " ('080009.jpg', '300002.jpg', 0),\n",
       " ('080009.jpg', '080007.jpg', 1),\n",
       " ('080009.jpg', '280002.jpg', 0),\n",
       " ('080009.jpg', '080003.jpg', 1),\n",
       " ('080009.jpg', '120007.jpg', 0),\n",
       " ('080009.jpg', '080006.jpg', 1),\n",
       " ('080009.jpg', '270002.jpg', 0),\n",
       " ('080009.jpg', '080005.jpg', 1),\n",
       " ('080009.jpg', '170004.jpg', 0),\n",
       " ('080009.jpg', '080008.jpg', 1),\n",
       " ('080009.jpg', '450002.jpg', 0),\n",
       " ('080001.jpg', '080004.jpg', 1),\n",
       " ('080001.jpg', '200007.jpg', 0),\n",
       " ('080001.jpg', '080002.jpg', 1),\n",
       " ('080001.jpg', '070001.jpg', 0),\n",
       " ('080001.jpg', '080007.jpg', 1),\n",
       " ('080001.jpg', '360001.jpg', 0),\n",
       " ('080001.jpg', '080003.jpg', 1),\n",
       " ('080001.jpg', '150005.jpg', 0),\n",
       " ('080001.jpg', '080006.jpg', 1),\n",
       " ('080001.jpg', '100005.jpg', 0),\n",
       " ('080001.jpg', '080005.jpg', 1),\n",
       " ('080001.jpg', '450002.jpg', 0),\n",
       " ('080001.jpg', '080008.jpg', 1),\n",
       " ('080001.jpg', '370008.jpg', 0),\n",
       " ('080004.jpg', '080002.jpg', 1),\n",
       " ('080004.jpg', '260001.jpg', 0),\n",
       " ('080004.jpg', '080007.jpg', 1),\n",
       " ('080004.jpg', '070003.jpg', 0),\n",
       " ('080004.jpg', '080003.jpg', 1),\n",
       " ('080004.jpg', '380003.jpg', 0),\n",
       " ('080004.jpg', '080006.jpg', 1),\n",
       " ('080004.jpg', '220008.jpg', 0),\n",
       " ('080004.jpg', '080005.jpg', 1),\n",
       " ('080004.jpg', '390007.jpg', 0),\n",
       " ('080004.jpg', '080008.jpg', 1),\n",
       " ('080004.jpg', '380004.jpg', 0),\n",
       " ('080002.jpg', '080007.jpg', 1),\n",
       " ('080002.jpg', '270003.jpg', 0),\n",
       " ('080002.jpg', '080003.jpg', 1),\n",
       " ('080002.jpg', '010004.jpg', 0),\n",
       " ('080002.jpg', '080006.jpg', 1),\n",
       " ('080002.jpg', '440007.jpg', 0),\n",
       " ('080002.jpg', '080005.jpg', 1),\n",
       " ('080002.jpg', '130006.jpg', 0),\n",
       " ('080002.jpg', '080008.jpg', 1),\n",
       " ('080002.jpg', '370005.jpg', 0),\n",
       " ('080007.jpg', '080003.jpg', 1),\n",
       " ('080007.jpg', '070009.jpg', 0),\n",
       " ('080007.jpg', '080006.jpg', 1),\n",
       " ('080007.jpg', '300004.jpg', 0),\n",
       " ('080007.jpg', '080005.jpg', 1),\n",
       " ('080007.jpg', '440006.jpg', 0),\n",
       " ('080007.jpg', '080008.jpg', 1),\n",
       " ('080007.jpg', '340004.jpg', 0),\n",
       " ('080003.jpg', '080006.jpg', 1),\n",
       " ('080003.jpg', '100007.jpg', 0),\n",
       " ('080003.jpg', '080005.jpg', 1),\n",
       " ('080003.jpg', '060008.jpg', 0),\n",
       " ('080003.jpg', '080008.jpg', 1),\n",
       " ('080003.jpg', '270005.jpg', 0),\n",
       " ('080006.jpg', '080005.jpg', 1),\n",
       " ('080006.jpg', '180002.jpg', 0),\n",
       " ('080006.jpg', '080008.jpg', 1),\n",
       " ('080006.jpg', '210003.jpg', 0),\n",
       " ('080005.jpg', '080008.jpg', 1),\n",
       " ('080005.jpg', '440005.jpg', 0),\n",
       " ('090005.jpg', '090006.jpg', 1),\n",
       " ('090005.jpg', '230001.jpg', 0),\n",
       " ('090005.jpg', '090004.jpg', 1),\n",
       " ('090005.jpg', '320008.jpg', 0),\n",
       " ('090005.jpg', '090009.jpg', 1),\n",
       " ('090005.jpg', '370002.jpg', 0),\n",
       " ('090005.jpg', '090003.jpg', 1),\n",
       " ('090005.jpg', '450001.jpg', 0),\n",
       " ('090005.jpg', '090007.jpg', 1),\n",
       " ('090005.jpg', '110006.jpg', 0),\n",
       " ('090005.jpg', '090002.jpg', 1),\n",
       " ('090005.jpg', '040003.jpg', 0),\n",
       " ('090005.jpg', '090001.jpg', 1),\n",
       " ('090005.jpg', '130001.jpg', 0),\n",
       " ('090005.jpg', '090008.jpg', 1),\n",
       " ('090005.jpg', '030009.jpg', 0),\n",
       " ('090006.jpg', '090004.jpg', 1),\n",
       " ('090006.jpg', '430005.jpg', 0),\n",
       " ('090006.jpg', '090009.jpg', 1),\n",
       " ('090006.jpg', '130005.jpg', 0),\n",
       " ('090006.jpg', '090003.jpg', 1),\n",
       " ('090006.jpg', '340009.jpg', 0),\n",
       " ('090006.jpg', '090007.jpg', 1),\n",
       " ('090006.jpg', '280002.jpg', 0),\n",
       " ('090006.jpg', '090002.jpg', 1),\n",
       " ('090006.jpg', '290005.jpg', 0),\n",
       " ('090006.jpg', '090001.jpg', 1),\n",
       " ('090006.jpg', '020001.jpg', 0),\n",
       " ('090006.jpg', '090008.jpg', 1),\n",
       " ('090006.jpg', '250002.jpg', 0),\n",
       " ('090004.jpg', '090009.jpg', 1),\n",
       " ('090004.jpg', '340006.jpg', 0),\n",
       " ('090004.jpg', '090003.jpg', 1),\n",
       " ('090004.jpg', '420008.jpg', 0),\n",
       " ('090004.jpg', '090007.jpg', 1),\n",
       " ('090004.jpg', '080005.jpg', 0),\n",
       " ('090004.jpg', '090002.jpg', 1),\n",
       " ('090004.jpg', '440007.jpg', 0),\n",
       " ('090004.jpg', '090001.jpg', 1),\n",
       " ('090004.jpg', '370009.jpg', 0),\n",
       " ('090004.jpg', '090008.jpg', 1),\n",
       " ('090004.jpg', '050006.jpg', 0),\n",
       " ('090009.jpg', '090003.jpg', 1),\n",
       " ('090009.jpg', '010003.jpg', 0),\n",
       " ('090009.jpg', '090007.jpg', 1),\n",
       " ('090009.jpg', '060001.jpg', 0),\n",
       " ('090009.jpg', '090002.jpg', 1),\n",
       " ('090009.jpg', '260006.jpg', 0),\n",
       " ('090009.jpg', '090001.jpg', 1),\n",
       " ('090009.jpg', '190002.jpg', 0),\n",
       " ('090009.jpg', '090008.jpg', 1),\n",
       " ('090009.jpg', '070001.jpg', 0),\n",
       " ('090003.jpg', '090007.jpg', 1),\n",
       " ('090003.jpg', '100008.jpg', 0),\n",
       " ('090003.jpg', '090002.jpg', 1),\n",
       " ('090003.jpg', '080007.jpg', 0),\n",
       " ('090003.jpg', '090001.jpg', 1),\n",
       " ('090003.jpg', '150008.jpg', 0),\n",
       " ('090003.jpg', '090008.jpg', 1),\n",
       " ('090003.jpg', '260002.jpg', 0),\n",
       " ('090007.jpg', '090002.jpg', 1),\n",
       " ('090007.jpg', '130001.jpg', 0),\n",
       " ('090007.jpg', '090001.jpg', 1),\n",
       " ('090007.jpg', '460002.jpg', 0),\n",
       " ('090007.jpg', '090008.jpg', 1),\n",
       " ('090007.jpg', '150002.jpg', 0),\n",
       " ('090002.jpg', '090001.jpg', 1),\n",
       " ('090002.jpg', '040006.jpg', 0),\n",
       " ('090002.jpg', '090008.jpg', 1),\n",
       " ('090002.jpg', '230003.jpg', 0),\n",
       " ('090001.jpg', '090008.jpg', 1),\n",
       " ('090001.jpg', '070008.jpg', 0),\n",
       " ('100003.jpg', '100006.jpg', 1),\n",
       " ('100003.jpg', '350005.jpg', 0),\n",
       " ('100003.jpg', '100002.jpg', 1),\n",
       " ('100003.jpg', '330004.jpg', 0),\n",
       " ('100003.jpg', '100009.jpg', 1),\n",
       " ('100003.jpg', '270004.jpg', 0),\n",
       " ('100003.jpg', '100004.jpg', 1),\n",
       " ('100003.jpg', '010007.jpg', 0),\n",
       " ('100003.jpg', '100001.jpg', 1),\n",
       " ('100003.jpg', '400002.jpg', 0),\n",
       " ('100003.jpg', '100007.jpg', 1),\n",
       " ('100003.jpg', '040005.jpg', 0),\n",
       " ('100003.jpg', '100008.jpg', 1),\n",
       " ('100003.jpg', '180003.jpg', 0),\n",
       " ('100003.jpg', '100005.jpg', 1),\n",
       " ('100003.jpg', '280008.jpg', 0),\n",
       " ('100006.jpg', '100002.jpg', 1),\n",
       " ('100006.jpg', '170007.jpg', 0),\n",
       " ('100006.jpg', '100009.jpg', 1),\n",
       " ('100006.jpg', '200007.jpg', 0),\n",
       " ('100006.jpg', '100004.jpg', 1),\n",
       " ('100006.jpg', '340004.jpg', 0),\n",
       " ('100006.jpg', '100001.jpg', 1),\n",
       " ('100006.jpg', '380002.jpg', 0),\n",
       " ('100006.jpg', '100007.jpg', 1),\n",
       " ('100006.jpg', '180006.jpg', 0),\n",
       " ('100006.jpg', '100008.jpg', 1),\n",
       " ('100006.jpg', '370006.jpg', 0),\n",
       " ('100006.jpg', '100005.jpg', 1),\n",
       " ('100006.jpg', '250007.jpg', 0),\n",
       " ('100002.jpg', '100009.jpg', 1),\n",
       " ('100002.jpg', '270003.jpg', 0),\n",
       " ('100002.jpg', '100004.jpg', 1),\n",
       " ('100002.jpg', '280009.jpg', 0),\n",
       " ('100002.jpg', '100001.jpg', 1),\n",
       " ('100002.jpg', '030008.jpg', 0),\n",
       " ('100002.jpg', '100007.jpg', 1),\n",
       " ('100002.jpg', '140008.jpg', 0),\n",
       " ('100002.jpg', '100008.jpg', 1),\n",
       " ('100002.jpg', '210001.jpg', 0),\n",
       " ('100002.jpg', '100005.jpg', 1),\n",
       " ('100002.jpg', '170006.jpg', 0),\n",
       " ('100009.jpg', '100004.jpg', 1),\n",
       " ('100009.jpg', '130008.jpg', 0),\n",
       " ('100009.jpg', '100001.jpg', 1),\n",
       " ('100009.jpg', '300003.jpg', 0),\n",
       " ('100009.jpg', '100007.jpg', 1),\n",
       " ('100009.jpg', '400005.jpg', 0),\n",
       " ('100009.jpg', '100008.jpg', 1),\n",
       " ('100009.jpg', '120007.jpg', 0),\n",
       " ('100009.jpg', '100005.jpg', 1),\n",
       " ('100009.jpg', '240005.jpg', 0),\n",
       " ('100004.jpg', '100001.jpg', 1),\n",
       " ('100004.jpg', '050001.jpg', 0),\n",
       " ('100004.jpg', '100007.jpg', 1),\n",
       " ('100004.jpg', '430004.jpg', 0),\n",
       " ('100004.jpg', '100008.jpg', 1),\n",
       " ('100004.jpg', '390008.jpg', 0),\n",
       " ('100004.jpg', '100005.jpg', 1),\n",
       " ('100004.jpg', '060008.jpg', 0),\n",
       " ('100001.jpg', '100007.jpg', 1),\n",
       " ('100001.jpg', '320006.jpg', 0),\n",
       " ('100001.jpg', '100008.jpg', 1),\n",
       " ('100001.jpg', '440009.jpg', 0),\n",
       " ('100001.jpg', '100005.jpg', 1),\n",
       " ('100001.jpg', '170005.jpg', 0),\n",
       " ('100007.jpg', '100008.jpg', 1),\n",
       " ('100007.jpg', '360006.jpg', 0),\n",
       " ('100007.jpg', '100005.jpg', 1),\n",
       " ('100007.jpg', '330003.jpg', 0),\n",
       " ('100008.jpg', '100005.jpg', 1),\n",
       " ('100008.jpg', '300001.jpg', 0),\n",
       " ('110007.jpg', '110004.jpg', 1),\n",
       " ('110007.jpg', '180006.jpg', 0),\n",
       " ('110007.jpg', '110002.jpg', 1),\n",
       " ('110007.jpg', '060009.jpg', 0),\n",
       " ('110007.jpg', '110008.jpg', 1),\n",
       " ('110007.jpg', '050008.jpg', 0),\n",
       " ('110007.jpg', '110009.jpg', 1),\n",
       " ('110007.jpg', '320004.jpg', 0),\n",
       " ('110007.jpg', '110005.jpg', 1),\n",
       " ('110007.jpg', '160007.jpg', 0),\n",
       " ('110007.jpg', '110003.jpg', 1),\n",
       " ('110007.jpg', '260004.jpg', 0),\n",
       " ('110007.jpg', '110006.jpg', 1),\n",
       " ('110007.jpg', '420008.jpg', 0),\n",
       " ('110007.jpg', '110001.jpg', 1),\n",
       " ('110007.jpg', '400002.jpg', 0),\n",
       " ('110004.jpg', '110002.jpg', 1),\n",
       " ('110004.jpg', '170009.jpg', 0),\n",
       " ('110004.jpg', '110008.jpg', 1),\n",
       " ('110004.jpg', '440009.jpg', 0),\n",
       " ('110004.jpg', '110009.jpg', 1),\n",
       " ('110004.jpg', '290004.jpg', 0),\n",
       " ('110004.jpg', '110005.jpg', 1),\n",
       " ('110004.jpg', '130006.jpg', 0),\n",
       " ('110004.jpg', '110003.jpg', 1),\n",
       " ('110004.jpg', '340007.jpg', 0),\n",
       " ('110004.jpg', '110006.jpg', 1),\n",
       " ('110004.jpg', '030009.jpg', 0),\n",
       " ('110004.jpg', '110001.jpg', 1),\n",
       " ('110004.jpg', '160006.jpg', 0),\n",
       " ('110002.jpg', '110008.jpg', 1),\n",
       " ('110002.jpg', '160005.jpg', 0),\n",
       " ('110002.jpg', '110009.jpg', 1),\n",
       " ('110002.jpg', '390005.jpg', 0),\n",
       " ('110002.jpg', '110005.jpg', 1),\n",
       " ('110002.jpg', '420001.jpg', 0),\n",
       " ('110002.jpg', '110003.jpg', 1),\n",
       " ('110002.jpg', '170009.jpg', 0),\n",
       " ('110002.jpg', '110006.jpg', 1),\n",
       " ('110002.jpg', '260005.jpg', 0),\n",
       " ('110002.jpg', '110001.jpg', 1),\n",
       " ('110002.jpg', '030006.jpg', 0),\n",
       " ('110008.jpg', '110009.jpg', 1),\n",
       " ('110008.jpg', '420001.jpg', 0),\n",
       " ('110008.jpg', '110005.jpg', 1),\n",
       " ('110008.jpg', '200004.jpg', 0),\n",
       " ('110008.jpg', '110003.jpg', 1),\n",
       " ('110008.jpg', '050007.jpg', 0),\n",
       " ('110008.jpg', '110006.jpg', 1),\n",
       " ('110008.jpg', '350001.jpg', 0),\n",
       " ('110008.jpg', '110001.jpg', 1),\n",
       " ('110008.jpg', '080008.jpg', 0),\n",
       " ('110009.jpg', '110005.jpg', 1),\n",
       " ('110009.jpg', '010002.jpg', 0),\n",
       " ('110009.jpg', '110003.jpg', 1),\n",
       " ('110009.jpg', '160009.jpg', 0),\n",
       " ('110009.jpg', '110006.jpg', 1),\n",
       " ('110009.jpg', '210009.jpg', 0),\n",
       " ('110009.jpg', '110001.jpg', 1),\n",
       " ('110009.jpg', '400006.jpg', 0),\n",
       " ('110005.jpg', '110003.jpg', 1),\n",
       " ('110005.jpg', '020004.jpg', 0),\n",
       " ('110005.jpg', '110006.jpg', 1),\n",
       " ('110005.jpg', '340005.jpg', 0),\n",
       " ('110005.jpg', '110001.jpg', 1),\n",
       " ('110005.jpg', '450005.jpg', 0),\n",
       " ('110003.jpg', '110006.jpg', 1),\n",
       " ('110003.jpg', '070001.jpg', 0),\n",
       " ('110003.jpg', '110001.jpg', 1),\n",
       " ('110003.jpg', '130006.jpg', 0),\n",
       " ('110006.jpg', '110001.jpg', 1),\n",
       " ('110006.jpg', '240004.jpg', 0),\n",
       " ('120009.jpg', '120003.jpg', 1),\n",
       " ('120009.jpg', '130009.jpg', 0),\n",
       " ('120009.jpg', '120007.jpg', 1),\n",
       " ('120009.jpg', '370001.jpg', 0),\n",
       " ('120009.jpg', '120005.jpg', 1),\n",
       " ('120009.jpg', '190006.jpg', 0),\n",
       " ('120009.jpg', '120002.jpg', 1),\n",
       " ('120009.jpg', '040003.jpg', 0),\n",
       " ('120009.jpg', '120004.jpg', 1),\n",
       " ('120009.jpg', '270008.jpg', 0),\n",
       " ('120009.jpg', '120006.jpg', 1),\n",
       " ('120009.jpg', '110003.jpg', 0),\n",
       " ('120009.jpg', '120001.jpg', 1),\n",
       " ('120009.jpg', '160006.jpg', 0),\n",
       " ('120009.jpg', '120008.jpg', 1),\n",
       " ('120009.jpg', '240009.jpg', 0),\n",
       " ('120003.jpg', '120007.jpg', 1),\n",
       " ('120003.jpg', '400001.jpg', 0),\n",
       " ('120003.jpg', '120005.jpg', 1),\n",
       " ('120003.jpg', '390007.jpg', 0),\n",
       " ('120003.jpg', '120002.jpg', 1),\n",
       " ('120003.jpg', '020009.jpg', 0),\n",
       " ('120003.jpg', '120004.jpg', 1),\n",
       " ('120003.jpg', '020004.jpg', 0),\n",
       " ('120003.jpg', '120006.jpg', 1),\n",
       " ('120003.jpg', '250005.jpg', 0),\n",
       " ('120003.jpg', '120001.jpg', 1),\n",
       " ('120003.jpg', '050006.jpg', 0),\n",
       " ('120003.jpg', '120008.jpg', 1),\n",
       " ('120003.jpg', '110005.jpg', 0),\n",
       " ('120007.jpg', '120005.jpg', 1),\n",
       " ('120007.jpg', '390005.jpg', 0),\n",
       " ('120007.jpg', '120002.jpg', 1),\n",
       " ('120007.jpg', '220003.jpg', 0),\n",
       " ('120007.jpg', '120004.jpg', 1),\n",
       " ('120007.jpg', '280005.jpg', 0),\n",
       " ('120007.jpg', '120006.jpg', 1),\n",
       " ('120007.jpg', '460007.jpg', 0),\n",
       " ('120007.jpg', '120001.jpg', 1),\n",
       " ('120007.jpg', '440007.jpg', 0),\n",
       " ('120007.jpg', '120008.jpg', 1),\n",
       " ('120007.jpg', '150002.jpg', 0),\n",
       " ('120005.jpg', '120002.jpg', 1),\n",
       " ('120005.jpg', '020003.jpg', 0),\n",
       " ('120005.jpg', '120004.jpg', 1),\n",
       " ('120005.jpg', '080004.jpg', 0),\n",
       " ('120005.jpg', '120006.jpg', 1),\n",
       " ('120005.jpg', '020006.jpg', 0),\n",
       " ('120005.jpg', '120001.jpg', 1),\n",
       " ('120005.jpg', '100001.jpg', 0),\n",
       " ('120005.jpg', '120008.jpg', 1),\n",
       " ('120005.jpg', '110005.jpg', 0),\n",
       " ('120002.jpg', '120004.jpg', 1),\n",
       " ('120002.jpg', '340002.jpg', 0),\n",
       " ('120002.jpg', '120006.jpg', 1),\n",
       " ('120002.jpg', '170004.jpg', 0),\n",
       " ('120002.jpg', '120001.jpg', 1),\n",
       " ('120002.jpg', '230008.jpg', 0),\n",
       " ('120002.jpg', '120008.jpg', 1),\n",
       " ('120002.jpg', '220009.jpg', 0),\n",
       " ('120004.jpg', '120006.jpg', 1),\n",
       " ('120004.jpg', '220004.jpg', 0),\n",
       " ('120004.jpg', '120001.jpg', 1),\n",
       " ('120004.jpg', '200005.jpg', 0),\n",
       " ('120004.jpg', '120008.jpg', 1),\n",
       " ('120004.jpg', '270006.jpg', 0),\n",
       " ('120006.jpg', '120001.jpg', 1),\n",
       " ('120006.jpg', '020005.jpg', 0),\n",
       " ('120006.jpg', '120008.jpg', 1),\n",
       " ('120006.jpg', '330001.jpg', 0),\n",
       " ('120001.jpg', '120008.jpg', 1),\n",
       " ('120001.jpg', '320006.jpg', 0),\n",
       " ('130001.jpg', '130003.jpg', 1),\n",
       " ('130001.jpg', '460005.jpg', 0),\n",
       " ('130001.jpg', '130008.jpg', 1),\n",
       " ('130001.jpg', '350003.jpg', 0),\n",
       " ('130001.jpg', '130007.jpg', 1),\n",
       " ('130001.jpg', '180002.jpg', 0),\n",
       " ('130001.jpg', '130006.jpg', 1),\n",
       " ('130001.jpg', '040009.jpg', 0),\n",
       " ('130001.jpg', '130002.jpg', 1),\n",
       " ('130001.jpg', '300004.jpg', 0),\n",
       " ('130001.jpg', '130009.jpg', 1),\n",
       " ('130001.jpg', '140009.jpg', 0),\n",
       " ('130001.jpg', '130004.jpg', 1),\n",
       " ('130001.jpg', '270003.jpg', 0),\n",
       " ('130001.jpg', '130005.jpg', 1),\n",
       " ('130001.jpg', '070002.jpg', 0),\n",
       " ('130003.jpg', '130008.jpg', 1),\n",
       " ('130003.jpg', '450004.jpg', 0),\n",
       " ('130003.jpg', '130007.jpg', 1),\n",
       " ('130003.jpg', '250009.jpg', 0),\n",
       " ('130003.jpg', '130006.jpg', 1),\n",
       " ('130003.jpg', '350009.jpg', 0),\n",
       " ('130003.jpg', '130002.jpg', 1),\n",
       " ('130003.jpg', '040009.jpg', 0),\n",
       " ('130003.jpg', '130009.jpg', 1),\n",
       " ('130003.jpg', '370008.jpg', 0),\n",
       " ('130003.jpg', '130004.jpg', 1),\n",
       " ('130003.jpg', '390002.jpg', 0),\n",
       " ('130003.jpg', '130005.jpg', 1),\n",
       " ('130003.jpg', '220003.jpg', 0),\n",
       " ('130008.jpg', '130007.jpg', 1),\n",
       " ('130008.jpg', '460004.jpg', 0),\n",
       " ('130008.jpg', '130006.jpg', 1),\n",
       " ('130008.jpg', '100003.jpg', 0),\n",
       " ('130008.jpg', '130002.jpg', 1),\n",
       " ('130008.jpg', '100007.jpg', 0),\n",
       " ('130008.jpg', '130009.jpg', 1),\n",
       " ('130008.jpg', '350001.jpg', 0),\n",
       " ('130008.jpg', '130004.jpg', 1),\n",
       " ('130008.jpg', '270005.jpg', 0),\n",
       " ('130008.jpg', '130005.jpg', 1),\n",
       " ('130008.jpg', '050007.jpg', 0),\n",
       " ('130007.jpg', '130006.jpg', 1),\n",
       " ('130007.jpg', '200009.jpg', 0),\n",
       " ('130007.jpg', '130002.jpg', 1),\n",
       " ('130007.jpg', '100005.jpg', 0),\n",
       " ('130007.jpg', '130009.jpg', 1),\n",
       " ('130007.jpg', '230008.jpg', 0),\n",
       " ('130007.jpg', '130004.jpg', 1),\n",
       " ('130007.jpg', '310009.jpg', 0),\n",
       " ('130007.jpg', '130005.jpg', 1),\n",
       " ('130007.jpg', '410008.jpg', 0),\n",
       " ('130006.jpg', '130002.jpg', 1),\n",
       " ('130006.jpg', '060008.jpg', 0),\n",
       " ('130006.jpg', '130009.jpg', 1),\n",
       " ('130006.jpg', '140006.jpg', 0),\n",
       " ('130006.jpg', '130004.jpg', 1),\n",
       " ('130006.jpg', '340008.jpg', 0),\n",
       " ('130006.jpg', '130005.jpg', 1),\n",
       " ('130006.jpg', '110009.jpg', 0),\n",
       " ('130002.jpg', '130009.jpg', 1),\n",
       " ('130002.jpg', '340008.jpg', 0),\n",
       " ('130002.jpg', '130004.jpg', 1),\n",
       " ('130002.jpg', '060006.jpg', 0),\n",
       " ('130002.jpg', '130005.jpg', 1),\n",
       " ('130002.jpg', '300005.jpg', 0),\n",
       " ('130009.jpg', '130004.jpg', 1),\n",
       " ('130009.jpg', '040009.jpg', 0),\n",
       " ('130009.jpg', '130005.jpg', 1),\n",
       " ('130009.jpg', '390009.jpg', 0),\n",
       " ('130004.jpg', '130005.jpg', 1),\n",
       " ('130004.jpg', '030003.jpg', 0),\n",
       " ('140005.jpg', '140002.jpg', 1),\n",
       " ('140005.jpg', '240004.jpg', 0),\n",
       " ('140005.jpg', '140006.jpg', 1),\n",
       " ('140005.jpg', '350001.jpg', 0),\n",
       " ('140005.jpg', '140001.jpg', 1),\n",
       " ('140005.jpg', '290007.jpg', 0),\n",
       " ('140005.jpg', '140004.jpg', 1),\n",
       " ('140005.jpg', '190001.jpg', 0),\n",
       " ('140005.jpg', '140008.jpg', 1),\n",
       " ('140005.jpg', '080008.jpg', 0),\n",
       " ('140005.jpg', '140007.jpg', 1),\n",
       " ('140005.jpg', '350007.jpg', 0),\n",
       " ('140005.jpg', '140003.jpg', 1),\n",
       " ('140005.jpg', '050009.jpg', 0),\n",
       " ('140005.jpg', '140009.jpg', 1),\n",
       " ('140005.jpg', '350008.jpg', 0),\n",
       " ('140002.jpg', '140006.jpg', 1),\n",
       " ('140002.jpg', '170002.jpg', 0),\n",
       " ('140002.jpg', '140001.jpg', 1),\n",
       " ('140002.jpg', '390007.jpg', 0),\n",
       " ('140002.jpg', '140004.jpg', 1),\n",
       " ('140002.jpg', '400005.jpg', 0),\n",
       " ('140002.jpg', '140008.jpg', 1),\n",
       " ('140002.jpg', '390008.jpg', 0),\n",
       " ('140002.jpg', '140007.jpg', 1),\n",
       " ('140002.jpg', '280007.jpg', 0),\n",
       " ('140002.jpg', '140003.jpg', 1),\n",
       " ('140002.jpg', '010006.jpg', 0),\n",
       " ('140002.jpg', '140009.jpg', 1),\n",
       " ('140002.jpg', '110006.jpg', 0),\n",
       " ('140006.jpg', '140001.jpg', 1),\n",
       " ('140006.jpg', '080004.jpg', 0),\n",
       " ('140006.jpg', '140004.jpg', 1),\n",
       " ('140006.jpg', '070001.jpg', 0),\n",
       " ('140006.jpg', '140008.jpg', 1),\n",
       " ('140006.jpg', '440008.jpg', 0),\n",
       " ('140006.jpg', '140007.jpg', 1),\n",
       " ('140006.jpg', '280007.jpg', 0),\n",
       " ('140006.jpg', '140003.jpg', 1),\n",
       " ('140006.jpg', '420006.jpg', 0),\n",
       " ('140006.jpg', '140009.jpg', 1),\n",
       " ('140006.jpg', '280001.jpg', 0),\n",
       " ('140001.jpg', '140004.jpg', 1),\n",
       " ('140001.jpg', '150007.jpg', 0),\n",
       " ('140001.jpg', '140008.jpg', 1),\n",
       " ('140001.jpg', '380008.jpg', 0),\n",
       " ('140001.jpg', '140007.jpg', 1),\n",
       " ('140001.jpg', '190009.jpg', 0),\n",
       " ('140001.jpg', '140003.jpg', 1),\n",
       " ('140001.jpg', '440006.jpg', 0),\n",
       " ('140001.jpg', '140009.jpg', 1),\n",
       " ('140001.jpg', '400008.jpg', 0),\n",
       " ('140004.jpg', '140008.jpg', 1),\n",
       " ('140004.jpg', '070008.jpg', 0),\n",
       " ('140004.jpg', '140007.jpg', 1),\n",
       " ('140004.jpg', '110003.jpg', 0),\n",
       " ('140004.jpg', '140003.jpg', 1),\n",
       " ('140004.jpg', '090007.jpg', 0),\n",
       " ('140004.jpg', '140009.jpg', 1),\n",
       " ('140004.jpg', '380002.jpg', 0),\n",
       " ('140008.jpg', '140007.jpg', 1),\n",
       " ('140008.jpg', '430006.jpg', 0),\n",
       " ('140008.jpg', '140003.jpg', 1),\n",
       " ('140008.jpg', '380007.jpg', 0),\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [3]:\n",
    "def get_holiday_triples(image_dir):\n",
    "    image_groups = {}\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        base_name = image_name[0:-4]\n",
    "        group_name = base_name[0:4]\n",
    "        if group_name in image_groups:\n",
    "            image_groups[group_name].append(image_name)\n",
    "        else:\n",
    "            image_groups[group_name] = [image_name]\n",
    "    num_sims = 0\n",
    "    image_triples = []\n",
    "    group_list = sorted(list(image_groups.keys()))\n",
    "    for i, g in enumerate(group_list):\n",
    "        if num_sims % 100 == 0:\n",
    "            print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\"\n",
    "                  .format(num_sims, num_sims, 2*num_sims))\n",
    "        images_in_group = image_groups[g]\n",
    "        sim_pairs_it = itertools.combinations(images_in_group, 2)\n",
    "        # for each similar pair, generate a corresponding different pair\n",
    "        for ref_image, sim_image in sim_pairs_it:\n",
    "            image_triples.append((ref_image, sim_image, 1))\n",
    "            num_sims += 1\n",
    "            while True:\n",
    "                j = np.random.randint(low=0, high=len(group_list), size=1)[0]\n",
    "                if j != i:\n",
    "                    break\n",
    "            dif_image_candidates = image_groups[group_list[j]]\n",
    "            k = np.random.randint(low=0, high=len(dif_image_candidates), size=1)[0]\n",
    "            dif_image = dif_image_candidates[k]\n",
    "            image_triples.append((ref_image, dif_image, 0))\n",
    "    print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\"\n",
    "          .format(num_sims, num_sims, 2*num_sims))\n",
    "    return image_triples   \n",
    "\n",
    "def load_vectors(vector_file):\n",
    "    vec_dict = {}\n",
    "    fvec = open(vector_file, \"r\")\n",
    "    for line in fvec:\n",
    "        image_name, image_vec = line.strip().split(\"\\t\")\n",
    "        vec = np.array([float(v) for v in image_vec.split(\",\")])\n",
    "        vec_dict[image_name] = vec\n",
    "    fvec.close()\n",
    "    return vec_dict\n",
    "\n",
    "def train_test_split(triples, splits):\n",
    "    assert sum(splits) == 1.0\n",
    "    split_pts = np.cumsum(np.array([0.] + splits))\n",
    "    indices = np.random.permutation(np.arange(len(triples)))\n",
    "    shuffled_triples = [triples[i] for i in indices]\n",
    "    data_splits = []\n",
    "    for sid in range(len(splits)):\n",
    "        start = int(split_pts[sid] * len(triples))\n",
    "        end = int(split_pts[sid + 1] * len(triples))\n",
    "        data_splits.append(shuffled_triples[start:end])\n",
    "    return data_splits\n",
    "\n",
    "def batch_to_vectors(batch, vec_size, vec_dict):\n",
    "    X1 = np.zeros((len(batch), vec_size))\n",
    "    X2 = np.zeros((len(batch), vec_size))\n",
    "    Y = np.zeros((len(batch), 2))\n",
    "    for tid in range(len(batch)):\n",
    "        X1[tid] = vec_dict[batch[tid][0]]\n",
    "        X2[tid] = vec_dict[batch[tid][1]]\n",
    "        Y[tid] = [1, 0] if batch[tid][2] == 0 else [0, 1]\n",
    "    return ([X1, X2], Y)\n",
    "    \n",
    "def data_generator(triples, vec_size, vec_dict, batch_size=32):\n",
    "    while True:\n",
    "        # shuffle once per batch\n",
    "        indices = np.random.permutation(np.arange(len(triples)))\n",
    "        num_batches = len(triples) // batch_size\n",
    "        for bid in range(num_batches):\n",
    "            batch_indices = indices[bid * batch_size : (bid + 1) * batch_size]\n",
    "            batch = [triples[i] for i in batch_indices]\n",
    "            yield batch_to_vectors(batch, vec_size, vec_dict)\n",
    "\n",
    "def evaluate_model(model_file, test_gen):\n",
    "    model_name = os.path.basename(model_file)\n",
    "    model = load_model(model_file)\n",
    "    print(\"=== Evaluating model: {:s} ===\".format(model_name))\n",
    "    ytrue, ypred = [], []\n",
    "    num_test_steps = len(test_triples) // BATCH_SIZE\n",
    "    for i in range(num_test_steps):\n",
    "        (X1, X2), Y = test_gen.__next__()\n",
    "        Y_ = model.predict([X1, X2])\n",
    "        ytrue.extend(np.argmax(Y, axis=1).tolist())\n",
    "        ypred.extend(np.argmax(Y_, axis=1).tolist())\n",
    "    accuracy = accuracy_score(ytrue, ypred)\n",
    "    print(\"\\nAccuracy: {:.3f}\".format(accuracy))\n",
    "    print(\"\\nConfusion Matrix\")\n",
    "    print(confusion_matrix(ytrue, ypred))\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(classification_report(ytrue, ypred))\n",
    "    return accuracy\n",
    "\n",
    "def get_model_file(data_dir, vector_name, merge_mode, borf):\n",
    "    return os.path.join(data_dir, \"models\", \"A_A_{:s}-{:s}-{:s}_1000_Nadam.h5\"\n",
    "                        .format(vector_name, merge_mode, borf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 900 pos + 900 neg = 1800 total image triples\n",
      "Generated 1656 pos + 1656 neg = 3312 total image triples\n"
     ]
    }
   ],
   "source": [
    "# Declare and Extract Common Data\n",
    "# In [4]:\n",
    "VECTORIZERS = [\"InceptionV3\", \"ResNet\"]\n",
    "# VECTORIZERS = [\"VGG16\", \"VGG19\", \"InceptionV3\", \"ResNet\"]\n",
    "MERGE_MODES = [\"Concat\", \"Dot\", \"AbsDiff\", \"Euclidean\"]\n",
    "scores = np.zeros((len(VECTORIZERS), len(MERGE_MODES)))\n",
    "# In [5]:\n",
    "image_triples = get_holiday_triples(IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2318 331 663\n"
     ]
    }
   ],
   "source": [
    "# In [6]:\n",
    "train_triples, val_triples, test_triples = train_test_split(image_triples, \n",
    "                                                            splits=[0.7, 0.1, 0.2])\n",
    "print(len(train_triples), len(val_triples), len(test_triples))\n",
    "\n",
    "# InceptionV3 Vectors\n",
    "# In [7]:\n",
    "VECTOR_SIZE = 2048\n",
    "VECTOR_FILE = os.path.join(DATA_DIR,\"weights\" , \"accton-inception-vectors.tsv\")\n",
    "# In [8]:\n",
    "vec_dict = load_vectors(VECTOR_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 1.5952 - acc: 0.4891 - val_loss: 0.6883 - val_acc: 0.5531\n",
      "Epoch 2/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.6980 - acc: 0.5317 - val_loss: 0.6913 - val_acc: 0.5531\n",
      "Epoch 3/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.6832 - acc: 0.5586 - val_loss: 0.6557 - val_acc: 0.6500\n",
      "Epoch 4/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.6627 - acc: 0.5964 - val_loss: 0.6976 - val_acc: 0.5000\n",
      "Epoch 5/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.6083 - acc: 0.6662 - val_loss: 0.5245 - val_acc: 0.7750\n",
      "Epoch 6/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.5144 - acc: 0.7461 - val_loss: 0.3478 - val_acc: 0.8438\n",
      "Epoch 7/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.3907 - acc: 0.8199 - val_loss: 0.2961 - val_acc: 0.9125\n",
      "Epoch 8/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.2743 - acc: 0.8898 - val_loss: 0.3036 - val_acc: 0.8656\n",
      "Epoch 9/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.2368 - acc: 0.9058 - val_loss: 0.1023 - val_acc: 0.9781\n",
      "Epoch 10/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.1934 - acc: 0.9293 - val_loss: 0.0857 - val_acc: 0.9781\n",
      "Epoch 11/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.2072 - acc: 0.9201 - val_loss: 0.1278 - val_acc: 0.9594\n",
      "Epoch 12/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.1616 - acc: 0.9366 - val_loss: 0.1046 - val_acc: 0.9563\n",
      "Epoch 13/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.1799 - acc: 0.9280 - val_loss: 0.4933 - val_acc: 0.7937\n",
      "Epoch 14/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.1811 - acc: 0.9271 - val_loss: 0.0740 - val_acc: 0.9719\n",
      "Epoch 15/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.1128 - acc: 0.9540 - val_loss: 0.0497 - val_acc: 0.9844\n",
      "Epoch 16/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.1273 - acc: 0.9501 - val_loss: 0.0509 - val_acc: 0.9781\n",
      "Epoch 17/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.1241 - acc: 0.9479 - val_loss: 0.0711 - val_acc: 0.9750\n",
      "Epoch 18/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.1041 - acc: 0.9609 - val_loss: 0.0683 - val_acc: 0.9844\n",
      "Epoch 19/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.1088 - acc: 0.9605 - val_loss: 0.0521 - val_acc: 0.9812\n",
      "Epoch 20/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0884 - acc: 0.9661 - val_loss: 0.0403 - val_acc: 0.9781\n",
      "Epoch 21/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0930 - acc: 0.9679 - val_loss: 0.0831 - val_acc: 0.9656\n",
      "Epoch 22/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0833 - acc: 0.9683 - val_loss: 0.0386 - val_acc: 0.9906\n",
      "Epoch 23/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0675 - acc: 0.9757 - val_loss: 0.0289 - val_acc: 0.9875\n",
      "Epoch 24/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0963 - acc: 0.9627 - val_loss: 0.0431 - val_acc: 0.9844\n",
      "Epoch 25/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1188 - acc: 0.9575 - val_loss: 0.1686 - val_acc: 0.9469\n",
      "Epoch 26/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0822 - acc: 0.9705 - val_loss: 0.0646 - val_acc: 0.9844\n",
      "Epoch 27/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0890 - acc: 0.9688 - val_loss: 0.0672 - val_acc: 0.9844\n",
      "Epoch 28/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0968 - acc: 0.9670 - val_loss: 0.0323 - val_acc: 0.9938\n",
      "Epoch 29/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0743 - acc: 0.9757 - val_loss: 0.0545 - val_acc: 0.9750\n",
      "Epoch 30/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0786 - acc: 0.9735 - val_loss: 0.0262 - val_acc: 0.9938\n",
      "Epoch 31/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0563 - acc: 0.9809 - val_loss: 0.0241 - val_acc: 0.9906\n",
      "Epoch 32/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0531 - acc: 0.9813 - val_loss: 0.0515 - val_acc: 0.9812\n",
      "Epoch 33/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0925 - acc: 0.9674 - val_loss: 0.0691 - val_acc: 0.9781\n",
      "Epoch 34/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0663 - acc: 0.9796 - val_loss: 0.0179 - val_acc: 0.9969\n",
      "Epoch 35/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0795 - acc: 0.9714 - val_loss: 0.0581 - val_acc: 0.9812\n",
      "Epoch 36/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0646 - acc: 0.9787 - val_loss: 0.0338 - val_acc: 0.9875\n",
      "Epoch 37/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0862 - acc: 0.9709 - val_loss: 0.0859 - val_acc: 0.9656\n",
      "Epoch 38/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0790 - acc: 0.9705 - val_loss: 0.0206 - val_acc: 0.9938\n",
      "Epoch 39/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0489 - acc: 0.9844 - val_loss: 0.0374 - val_acc: 0.9906\n",
      "Epoch 40/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.1104 - acc: 0.9579 - val_loss: 0.0466 - val_acc: 0.9844\n",
      "Epoch 41/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.1181 - acc: 0.9666 - val_loss: 0.0303 - val_acc: 0.9875\n",
      "Epoch 42/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0584 - acc: 0.9787 - val_loss: 0.0139 - val_acc: 1.0000\n",
      "Epoch 43/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0676 - acc: 0.9748 - val_loss: 0.0498 - val_acc: 0.9781\n",
      "Epoch 44/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0496 - acc: 0.9870 - val_loss: 0.0142 - val_acc: 1.0000\n",
      "Epoch 45/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0683 - acc: 0.9805 - val_loss: 0.0306 - val_acc: 0.9906\n",
      "Epoch 46/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0587 - acc: 0.9809 - val_loss: 0.0185 - val_acc: 0.9938\n",
      "Epoch 47/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0459 - acc: 0.9861 - val_loss: 0.0134 - val_acc: 0.9969\n",
      "Epoch 48/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0236 - acc: 0.9922 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 49/1000\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.0381 - acc: 0.9896 - val_loss: 0.0221 - val_acc: 0.9906\n",
      "Epoch 50/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0646 - acc: 0.9792 - val_loss: 0.0171 - val_acc: 0.9938\n",
      "Epoch 51/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0341 - acc: 0.9874 - val_loss: 0.0152 - val_acc: 0.9938\n",
      "Epoch 52/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0490 - acc: 0.9870 - val_loss: 0.0171 - val_acc: 0.9969\n",
      "Epoch 53/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0682 - acc: 0.9787 - val_loss: 0.0325 - val_acc: 0.9844\n",
      "Epoch 54/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0304 - acc: 0.9918 - val_loss: 0.0219 - val_acc: 0.9938\n",
      "Epoch 55/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0386 - acc: 0.9874 - val_loss: 0.0555 - val_acc: 0.9781\n",
      "Epoch 56/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0436 - acc: 0.9835 - val_loss: 0.0357 - val_acc: 0.9812\n",
      "Epoch 57/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0525 - acc: 0.9822 - val_loss: 0.0892 - val_acc: 0.9750\n",
      "Epoch 58/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0733 - acc: 0.9770 - val_loss: 0.0492 - val_acc: 0.9812\n",
      "Epoch 59/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0436 - acc: 0.9865 - val_loss: 0.0163 - val_acc: 1.0000\n",
      "Epoch 60/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0589 - acc: 0.9822 - val_loss: 0.0083 - val_acc: 0.9938\n",
      "Epoch 61/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0584 - acc: 0.9787 - val_loss: 0.0166 - val_acc: 0.9969\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0329 - acc: 0.9883 - val_loss: 0.0265 - val_acc: 0.9969\n",
      "Epoch 63/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0335 - acc: 0.9896 - val_loss: 0.0127 - val_acc: 0.9938\n",
      "Epoch 64/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0341 - acc: 0.9883 - val_loss: 0.0122 - val_acc: 0.9938\n",
      "Epoch 65/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0764 - acc: 0.9740 - val_loss: 0.0557 - val_acc: 0.9812\n",
      "Epoch 66/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0853 - acc: 0.9731 - val_loss: 0.0423 - val_acc: 0.9844\n",
      "Epoch 67/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0382 - acc: 0.9883 - val_loss: 0.0729 - val_acc: 0.9750\n",
      "Epoch 68/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.1037 - acc: 0.9696 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 69/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0488 - acc: 0.9839 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "Epoch 70/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0345 - acc: 0.9865 - val_loss: 0.0255 - val_acc: 0.9906\n",
      "Epoch 71/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0485 - acc: 0.9852 - val_loss: 0.0199 - val_acc: 0.9938\n",
      "Epoch 72/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0621 - acc: 0.9787 - val_loss: 0.0218 - val_acc: 0.9969\n",
      "Epoch 73/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0433 - acc: 0.9861 - val_loss: 0.0528 - val_acc: 0.9719\n",
      "Epoch 74/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0409 - acc: 0.9861 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 75/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0332 - acc: 0.9896 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 76/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0393 - acc: 0.9887 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 77/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0308 - acc: 0.9891 - val_loss: 0.0233 - val_acc: 0.9906\n",
      "Epoch 78/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0458 - acc: 0.9848 - val_loss: 0.0296 - val_acc: 0.9875\n",
      "Epoch 79/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0262 - acc: 0.9913 - val_loss: 0.0090 - val_acc: 0.9938\n",
      "Epoch 80/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0267 - acc: 0.9918 - val_loss: 0.0166 - val_acc: 0.9969\n",
      "Epoch 81/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0526 - acc: 0.9848 - val_loss: 0.0256 - val_acc: 0.9938\n",
      "Epoch 82/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0469 - acc: 0.9835 - val_loss: 0.0237 - val_acc: 0.9875\n",
      "Epoch 83/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0335 - acc: 0.9900 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 84/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0357 - acc: 0.9896 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 85/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0490 - acc: 0.9844 - val_loss: 0.0149 - val_acc: 0.9969\n",
      "Epoch 86/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0246 - acc: 0.9944 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 87/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0226 - acc: 0.9935 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 88/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0669 - acc: 0.9796 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 89/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0524 - acc: 0.9826 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 90/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0447 - acc: 0.9870 - val_loss: 0.0192 - val_acc: 0.9969\n",
      "Epoch 91/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0406 - acc: 0.9874 - val_loss: 0.0154 - val_acc: 0.9969\n",
      "Epoch 92/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0281 - acc: 0.9918 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 93/1000\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.0180 - acc: 0.9952 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 94/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0143 - acc: 0.9948 - val_loss: 0.0243 - val_acc: 0.9906\n",
      "Epoch 95/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0409 - acc: 0.9878 - val_loss: 0.0250 - val_acc: 0.9938\n",
      "Epoch 96/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0503 - acc: 0.9874 - val_loss: 0.0136 - val_acc: 0.9969\n",
      "Epoch 97/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0204 - acc: 0.9948 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 98/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0341 - acc: 0.9913 - val_loss: 0.0325 - val_acc: 0.9906\n",
      "Epoch 99/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0290 - acc: 0.9918 - val_loss: 0.0190 - val_acc: 0.9906\n",
      "Epoch 100/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0380 - acc: 0.9896 - val_loss: 0.0150 - val_acc: 0.9938\n",
      "Epoch 101/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0222 - acc: 0.9931 - val_loss: 0.0200 - val_acc: 0.9906\n",
      "Epoch 102/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0395 - acc: 0.9887 - val_loss: 0.0124 - val_acc: 0.9938\n",
      "Epoch 103/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0554 - acc: 0.9822 - val_loss: 0.0105 - val_acc: 0.9969\n",
      "Epoch 104/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0515 - acc: 0.9857 - val_loss: 0.0255 - val_acc: 0.9906\n",
      "Epoch 105/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0284 - acc: 0.9918 - val_loss: 0.0329 - val_acc: 0.9938\n",
      "Epoch 106/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0293 - acc: 0.9922 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 107/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0226 - acc: 0.9939 - val_loss: 0.0183 - val_acc: 0.9906\n",
      "Epoch 108/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0444 - acc: 0.9848 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 109/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0500 - acc: 0.9826 - val_loss: 0.0161 - val_acc: 0.9969\n",
      "Epoch 110/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0311 - acc: 0.9909 - val_loss: 0.0202 - val_acc: 0.9938\n",
      "Epoch 111/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0280 - acc: 0.9944 - val_loss: 0.0177 - val_acc: 0.9969\n",
      "Epoch 112/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0264 - acc: 0.9944 - val_loss: 0.0159 - val_acc: 0.9938\n",
      "Epoch 113/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0410 - acc: 0.9857 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 114/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0460 - acc: 0.9857 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 115/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0234 - acc: 0.9922 - val_loss: 0.0328 - val_acc: 0.9938\n",
      "Epoch 116/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0293 - acc: 0.9922 - val_loss: 0.0134 - val_acc: 0.9938\n",
      "Epoch 117/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0375 - acc: 0.9891 - val_loss: 0.0377 - val_acc: 0.9875\n",
      "Epoch 118/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0327 - acc: 0.9900 - val_loss: 0.0144 - val_acc: 0.9969\n",
      "Epoch 119/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0356 - acc: 0.9913 - val_loss: 0.0176 - val_acc: 0.9938\n",
      "Epoch 120/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0330 - acc: 0.9896 - val_loss: 0.0456 - val_acc: 0.9781\n",
      "Epoch 121/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0233 - acc: 0.9918 - val_loss: 0.0153 - val_acc: 0.9969\n",
      "Epoch 122/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0319 - acc: 0.9909 - val_loss: 0.0363 - val_acc: 0.9844\n",
      "Epoch 123/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0383 - acc: 0.9887 - val_loss: 0.0083 - val_acc: 0.9969\n",
      "Epoch 124/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0278 - acc: 0.9926 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 125/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0166 - acc: 0.9948 - val_loss: 0.0097 - val_acc: 0.9969\n",
      "Epoch 126/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0314 - acc: 0.9922 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 127/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0277 - acc: 0.9931 - val_loss: 0.0163 - val_acc: 0.9906\n",
      "Epoch 128/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0224 - acc: 0.9935 - val_loss: 0.0257 - val_acc: 0.9969\n",
      "Epoch 129/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0279 - acc: 0.9922 - val_loss: 0.1038 - val_acc: 0.9812\n",
      "Epoch 130/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0279 - acc: 0.9922 - val_loss: 0.0320 - val_acc: 0.9844\n",
      "Epoch 131/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0423 - acc: 0.9905 - val_loss: 0.0323 - val_acc: 0.9906\n",
      "Epoch 132/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0577 - acc: 0.9861 - val_loss: 0.0173 - val_acc: 0.9969\n",
      "Epoch 133/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0246 - acc: 0.9935 - val_loss: 0.0279 - val_acc: 0.9938\n",
      "Epoch 134/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0404 - acc: 0.9896 - val_loss: 0.0184 - val_acc: 0.9969\n",
      "Epoch 135/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0249 - acc: 0.9931 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 136/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0137 - acc: 0.9961 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 137/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.0149 - acc: 0.9965 - val_loss: 0.0103 - val_acc: 0.9969\n",
      "Epoch 138/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0180 - acc: 0.9948 - val_loss: 0.0122 - val_acc: 0.9906\n",
      "Epoch 139/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0292 - acc: 0.9922 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 140/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0245 - acc: 0.9918 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 141/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0482 - acc: 0.9852 - val_loss: 0.0394 - val_acc: 0.9906\n",
      "Epoch 142/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0448 - acc: 0.9870 - val_loss: 0.0158 - val_acc: 0.9906\n",
      "Epoch 143/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0326 - acc: 0.9905 - val_loss: 0.0132 - val_acc: 0.9969\n",
      "Epoch 144/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0283 - acc: 0.9909 - val_loss: 0.0268 - val_acc: 0.9812\n",
      "Epoch 145/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0090 - acc: 0.9978 - val_loss: 0.0114 - val_acc: 0.9969\n",
      "Epoch 146/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0190 - acc: 0.9922 - val_loss: 0.0186 - val_acc: 0.9969\n",
      "Epoch 147/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0223 - acc: 0.9944 - val_loss: 0.0099 - val_acc: 0.9969\n",
      "Epoch 148/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0128 - acc: 0.9970 - val_loss: 0.0145 - val_acc: 0.9938\n",
      "Epoch 149/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0243 - acc: 0.9926 - val_loss: 0.0296 - val_acc: 0.9938\n",
      "Epoch 150/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0333 - acc: 0.9887 - val_loss: 0.0113 - val_acc: 0.9969\n",
      "Epoch 151/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0303 - acc: 0.9909 - val_loss: 0.0280 - val_acc: 0.9938\n",
      "Epoch 152/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0393 - acc: 0.9870 - val_loss: 0.0236 - val_acc: 0.9906\n",
      "Epoch 153/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0208 - acc: 0.9961 - val_loss: 0.0139 - val_acc: 0.9938\n",
      "Epoch 154/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0223 - acc: 0.9931 - val_loss: 0.0511 - val_acc: 0.9719\n",
      "Epoch 155/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0374 - acc: 0.9900 - val_loss: 0.0392 - val_acc: 0.9844\n",
      "Epoch 156/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0245 - acc: 0.9931 - val_loss: 0.0566 - val_acc: 0.9844\n",
      "Epoch 157/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0207 - acc: 0.9939 - val_loss: 0.0378 - val_acc: 0.9875\n",
      "Epoch 158/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0269 - acc: 0.9926 - val_loss: 0.0235 - val_acc: 0.9938\n",
      "Epoch 159/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0279 - acc: 0.9922 - val_loss: 0.0198 - val_acc: 0.9938\n",
      "Epoch 160/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0380 - acc: 0.9857 - val_loss: 0.0135 - val_acc: 0.9969\n",
      "Epoch 161/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0197 - acc: 0.9931 - val_loss: 0.0177 - val_acc: 0.9938\n",
      "Epoch 162/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0225 - acc: 0.9944 - val_loss: 0.0107 - val_acc: 0.9969\n",
      "Epoch 163/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0195 - acc: 0.9948 - val_loss: 0.0219 - val_acc: 0.9938\n",
      "Epoch 164/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0087 - val_acc: 0.9969\n",
      "Epoch 165/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0247 - acc: 0.9931 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 166/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0317 - acc: 0.9896 - val_loss: 0.0115 - val_acc: 0.9969\n",
      "Epoch 167/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0238 - acc: 0.9922 - val_loss: 0.0070 - val_acc: 0.9969\n",
      "Epoch 168/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0471 - acc: 0.9857 - val_loss: 0.0111 - val_acc: 0.9969\n",
      "Epoch 169/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0185 - acc: 0.9944 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 170/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0264 - acc: 0.9939 - val_loss: 0.0267 - val_acc: 0.9906\n",
      "Epoch 171/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0276 - acc: 0.9926 - val_loss: 0.0118 - val_acc: 0.9969\n",
      "Epoch 172/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0478 - acc: 0.9870 - val_loss: 0.0450 - val_acc: 0.9812\n",
      "Epoch 173/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0254 - acc: 0.9926 - val_loss: 0.0065 - val_acc: 0.9969\n",
      "Epoch 174/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0196 - acc: 0.9952 - val_loss: 0.0600 - val_acc: 0.9812\n",
      "Epoch 175/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0091 - acc: 0.9987 - val_loss: 0.0128 - val_acc: 0.9969\n",
      "Epoch 176/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0308 - acc: 0.9918 - val_loss: 0.0133 - val_acc: 0.9938\n",
      "Epoch 177/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0173 - acc: 0.9957 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 178/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0148 - acc: 0.9970 - val_loss: 0.0303 - val_acc: 0.9906\n",
      "Epoch 179/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0146 - acc: 0.9961 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 180/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0126 - acc: 0.9970 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 181/1000\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.0245 - acc: 0.9944 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 182/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0135 - acc: 0.9961 - val_loss: 0.0055 - val_acc: 0.9969\n",
      "Epoch 183/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0329 - acc: 0.9935 - val_loss: 0.0200 - val_acc: 0.9969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0288 - acc: 0.9918 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 185/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0106 - acc: 0.9961 - val_loss: 0.0381 - val_acc: 0.9812\n",
      "Epoch 186/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0183 - acc: 0.9970 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 187/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0197 - acc: 0.9926 - val_loss: 0.0129 - val_acc: 0.9906\n",
      "Epoch 188/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0469 - acc: 0.9844 - val_loss: 0.0083 - val_acc: 0.9969\n",
      "Epoch 189/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0099 - acc: 0.9974 - val_loss: 0.0188 - val_acc: 0.9938\n",
      "Epoch 190/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0196 - acc: 0.9939 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 191/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0217 - acc: 0.9939 - val_loss: 0.0150 - val_acc: 0.9938\n",
      "Epoch 192/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0538 - acc: 0.9861 - val_loss: 0.0146 - val_acc: 0.9969\n",
      "Epoch 193/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0263 - acc: 0.9931 - val_loss: 0.0069 - val_acc: 0.9969\n",
      "Epoch 194/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0319 - acc: 0.9887 - val_loss: 0.0164 - val_acc: 0.9938\n",
      "Epoch 195/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0251 - acc: 0.9909 - val_loss: 0.0193 - val_acc: 0.9938\n",
      "Epoch 196/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0259 - acc: 0.9944 - val_loss: 0.0184 - val_acc: 0.9969\n",
      "Epoch 197/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0307 - acc: 0.9944 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 198/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0279 - acc: 0.9918 - val_loss: 0.0559 - val_acc: 0.9875\n",
      "Epoch 199/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0552 - acc: 0.9857 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 200/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0327 - acc: 0.9918 - val_loss: 0.0207 - val_acc: 0.9938\n",
      "Epoch 201/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0310 - acc: 0.9883 - val_loss: 0.0255 - val_acc: 0.9875\n",
      "Epoch 202/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0201 - acc: 0.9948 - val_loss: 0.0112 - val_acc: 0.9938\n",
      "Epoch 203/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0279 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9969\n",
      "Epoch 204/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0264 - acc: 0.9913 - val_loss: 0.0105 - val_acc: 0.9938\n",
      "Epoch 205/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0429 - acc: 0.9891 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 206/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0240 - acc: 0.9926 - val_loss: 0.0334 - val_acc: 0.9875\n",
      "Epoch 207/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.0227 - val_acc: 0.9875\n",
      "Epoch 208/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0242 - acc: 0.9939 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 209/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0118 - acc: 0.9974 - val_loss: 0.0117 - val_acc: 0.9938\n",
      "Epoch 210/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0117 - acc: 0.9957 - val_loss: 0.0052 - val_acc: 0.9969\n",
      "Epoch 211/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0308 - acc: 0.9931 - val_loss: 0.0374 - val_acc: 0.9844\n",
      "Epoch 212/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0097 - acc: 0.9983 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 213/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0072 - acc: 0.9987 - val_loss: 0.0159 - val_acc: 0.9969\n",
      "Epoch 214/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0107 - acc: 0.9983 - val_loss: 0.0169 - val_acc: 0.9906\n",
      "Epoch 215/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0115 - acc: 0.9965 - val_loss: 0.0101 - val_acc: 0.9938\n",
      "Epoch 216/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.0044 - val_acc: 0.9969\n",
      "Epoch 217/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0192 - acc: 0.9944 - val_loss: 0.0067 - val_acc: 0.9938\n",
      "Epoch 218/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0519 - acc: 0.9857 - val_loss: 0.0224 - val_acc: 0.9875\n",
      "Epoch 219/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0276 - acc: 0.9900 - val_loss: 0.0053 - val_acc: 0.9969\n",
      "Epoch 220/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0155 - acc: 0.9965 - val_loss: 0.0097 - val_acc: 0.9969\n",
      "Epoch 221/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0226 - acc: 0.9939 - val_loss: 0.0080 - val_acc: 0.9969\n",
      "Epoch 222/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0268 - acc: 0.9948 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 223/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0239 - acc: 0.9931 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 224/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0266 - acc: 0.9922 - val_loss: 0.0133 - val_acc: 0.9938\n",
      "Epoch 225/1000\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.0153 - acc: 0.9957 - val_loss: 0.0085 - val_acc: 0.9969\n",
      "Epoch 226/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0237 - acc: 0.9944 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 227/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0333 - acc: 0.9922 - val_loss: 0.0304 - val_acc: 0.9812\n",
      "Epoch 228/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0341 - acc: 0.9891 - val_loss: 0.0212 - val_acc: 0.9906\n",
      "Epoch 229/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0166 - acc: 0.9952 - val_loss: 0.0224 - val_acc: 0.9969\n",
      "Epoch 230/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0210 - acc: 0.9939 - val_loss: 0.0168 - val_acc: 0.9938\n",
      "Epoch 231/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0171 - acc: 0.9948 - val_loss: 0.0078 - val_acc: 0.9938\n",
      "Epoch 232/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0168 - acc: 0.9944 - val_loss: 0.0524 - val_acc: 0.9719\n",
      "Epoch 233/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0214 - acc: 0.9944 - val_loss: 0.0119 - val_acc: 0.9969\n",
      "Epoch 234/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0346 - acc: 0.9900 - val_loss: 0.0162 - val_acc: 0.9938\n",
      "Epoch 235/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0281 - acc: 0.9896 - val_loss: 0.0129 - val_acc: 0.9906\n",
      "Epoch 236/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0356 - acc: 0.9905 - val_loss: 0.0176 - val_acc: 0.9969\n",
      "Epoch 237/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0199 - acc: 0.9939 - val_loss: 0.0188 - val_acc: 0.9969\n",
      "Epoch 238/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0128 - acc: 0.9952 - val_loss: 0.0250 - val_acc: 0.9875\n",
      "Epoch 239/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0193 - acc: 0.9944 - val_loss: 0.0372 - val_acc: 0.9812\n",
      "Epoch 240/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0346 - acc: 0.9913 - val_loss: 0.0189 - val_acc: 0.9938\n",
      "Epoch 241/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0096 - acc: 0.9970 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 242/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0098 - acc: 0.9987 - val_loss: 0.0137 - val_acc: 0.9969\n",
      "Epoch 243/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0122 - acc: 0.9970 - val_loss: 0.0459 - val_acc: 0.9812\n",
      "Epoch 244/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0231 - acc: 0.9935 - val_loss: 0.0080 - val_acc: 0.9938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0131 - acc: 0.9961 - val_loss: 0.0122 - val_acc: 0.9938\n",
      "Epoch 246/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0191 - acc: 0.9944 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 247/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0090 - val_acc: 0.9969\n",
      "Epoch 248/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0201 - acc: 0.9961 - val_loss: 0.0598 - val_acc: 0.9875\n",
      "Epoch 249/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0289 - acc: 0.9918 - val_loss: 0.0164 - val_acc: 0.9969\n",
      "Epoch 250/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0298 - acc: 0.9926 - val_loss: 0.0224 - val_acc: 0.9938\n",
      "Epoch 251/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0143 - acc: 0.9952 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 252/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0149 - acc: 0.9970 - val_loss: 0.0071 - val_acc: 0.9969\n",
      "Epoch 253/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0497 - acc: 0.9852 - val_loss: 0.0464 - val_acc: 0.9969\n",
      "Epoch 254/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0495 - acc: 0.9861 - val_loss: 0.0385 - val_acc: 0.9812\n",
      "Epoch 255/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0334 - acc: 0.9913 - val_loss: 0.0326 - val_acc: 0.9938\n",
      "Epoch 256/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0179 - acc: 0.9939 - val_loss: 0.0249 - val_acc: 0.9938\n",
      "Epoch 257/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0243 - acc: 0.9939 - val_loss: 0.0407 - val_acc: 0.9781\n",
      "Epoch 258/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0315 - acc: 0.9922 - val_loss: 0.0193 - val_acc: 0.9844\n",
      "Epoch 259/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0255 - acc: 0.9948 - val_loss: 0.0249 - val_acc: 0.9969\n",
      "Epoch 260/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0099 - acc: 0.9974 - val_loss: 0.0213 - val_acc: 0.9938\n",
      "Epoch 261/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0178 - acc: 0.9970 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 262/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0214 - acc: 0.9948 - val_loss: 0.0336 - val_acc: 0.9781\n",
      "Epoch 263/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0128 - acc: 0.9970 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 264/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0128 - acc: 0.9957 - val_loss: 0.0198 - val_acc: 0.9875\n",
      "Epoch 265/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0079 - acc: 0.9970 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 266/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0239 - acc: 0.9970 - val_loss: 0.0373 - val_acc: 0.9969\n",
      "Epoch 267/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0102 - acc: 0.9978 - val_loss: 0.0220 - val_acc: 0.9969\n",
      "Epoch 268/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0147 - acc: 0.9965 - val_loss: 0.0133 - val_acc: 0.9938\n",
      "Epoch 269/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0093 - val_acc: 0.9969\n",
      "Epoch 270/1000\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.0096 - acc: 0.9983 - val_loss: 0.0205 - val_acc: 0.9906\n",
      "Epoch 271/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0435 - val_acc: 0.9875\n",
      "Epoch 272/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0170 - acc: 0.9965 - val_loss: 0.0225 - val_acc: 0.9969\n",
      "Epoch 273/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0175 - acc: 0.9957 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 274/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0247 - acc: 0.9948 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 275/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0158 - acc: 0.9965 - val_loss: 0.0066 - val_acc: 0.9938\n",
      "Epoch 276/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0163 - acc: 0.9948 - val_loss: 0.0096 - val_acc: 0.9969\n",
      "Epoch 277/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0190 - acc: 0.9944 - val_loss: 0.0198 - val_acc: 0.9938\n",
      "Epoch 278/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0099 - acc: 0.9961 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 279/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0183 - acc: 0.9965 - val_loss: 0.0129 - val_acc: 0.9969\n",
      "Epoch 280/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0212 - acc: 0.9952 - val_loss: 0.0240 - val_acc: 0.9969\n",
      "Epoch 281/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0277 - val_acc: 0.9906\n",
      "Epoch 282/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0115 - acc: 0.9957 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 283/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0086 - acc: 0.9961 - val_loss: 0.0427 - val_acc: 0.9875\n",
      "Epoch 284/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0210 - acc: 0.9952 - val_loss: 0.0293 - val_acc: 0.9812\n",
      "Epoch 285/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0197 - acc: 0.9948 - val_loss: 0.0133 - val_acc: 0.9938\n",
      "Epoch 286/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0200 - val_acc: 0.9906\n",
      "Epoch 287/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0136 - acc: 0.9978 - val_loss: 0.0068 - val_acc: 0.9969\n",
      "Epoch 288/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0216 - val_acc: 0.9938\n",
      "Epoch 289/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0155 - acc: 0.9957 - val_loss: 0.0296 - val_acc: 0.9938\n",
      "Epoch 290/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0190 - acc: 0.9961 - val_loss: 0.0439 - val_acc: 0.9906\n",
      "Epoch 291/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0194 - acc: 0.9944 - val_loss: 0.0142 - val_acc: 0.9969\n",
      "Epoch 292/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0280 - acc: 0.9931 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 293/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0259 - acc: 0.9926 - val_loss: 0.0103 - val_acc: 0.9969\n",
      "Epoch 294/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0347 - acc: 0.9926 - val_loss: 0.0157 - val_acc: 0.9875\n",
      "Epoch 295/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0201 - acc: 0.9952 - val_loss: 0.0116 - val_acc: 0.9938\n",
      "Epoch 296/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0198 - acc: 0.9948 - val_loss: 0.0230 - val_acc: 0.9906\n",
      "Epoch 297/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0213 - acc: 0.9957 - val_loss: 0.0187 - val_acc: 0.9969\n",
      "Epoch 298/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0168 - acc: 0.9957 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 299/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0094 - acc: 0.9983 - val_loss: 0.0317 - val_acc: 0.9938\n",
      "Epoch 300/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0207 - acc: 0.9922 - val_loss: 0.0317 - val_acc: 0.9938\n",
      "Epoch 301/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0370 - acc: 0.9926 - val_loss: 0.0125 - val_acc: 0.9938\n",
      "Epoch 302/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0103 - acc: 0.9978 - val_loss: 0.0124 - val_acc: 0.9969\n",
      "Epoch 303/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0201 - val_acc: 0.9969\n",
      "Epoch 304/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0125 - acc: 0.9970 - val_loss: 0.0116 - val_acc: 0.9969\n",
      "Epoch 305/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0084 - acc: 0.9987 - val_loss: 0.0291 - val_acc: 0.9875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0065 - acc: 0.9987 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 307/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0059 - acc: 0.9978 - val_loss: 0.0270 - val_acc: 0.9938\n",
      "Epoch 308/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0260 - acc: 0.9922 - val_loss: 0.0105 - val_acc: 0.9938\n",
      "Epoch 309/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0267 - acc: 0.9952 - val_loss: 0.0322 - val_acc: 0.9906\n",
      "Epoch 310/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0197 - acc: 0.9965 - val_loss: 0.0109 - val_acc: 0.9938\n",
      "Epoch 311/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0221 - acc: 0.9944 - val_loss: 0.0241 - val_acc: 0.9938\n",
      "Epoch 312/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0328 - acc: 0.9913 - val_loss: 0.0326 - val_acc: 0.9812\n",
      "Epoch 313/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0230 - acc: 0.9944 - val_loss: 0.0573 - val_acc: 0.9781\n",
      "Epoch 314/1000\n",
      "72/72 [==============================] - 3s 37ms/step - loss: 0.0090 - acc: 0.9965 - val_loss: 0.0069 - val_acc: 0.9969\n",
      "Epoch 315/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0124 - acc: 0.9970 - val_loss: 0.0344 - val_acc: 0.9906\n",
      "Epoch 316/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0234 - acc: 0.9944 - val_loss: 0.0159 - val_acc: 0.9938\n",
      "Epoch 317/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.0210 - val_acc: 0.9969\n",
      "Epoch 318/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0040 - acc: 0.9983 - val_loss: 0.0301 - val_acc: 0.9969\n",
      "Epoch 319/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0075 - acc: 0.9983 - val_loss: 0.0291 - val_acc: 0.9938\n",
      "Epoch 320/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0085 - acc: 0.9987 - val_loss: 0.0409 - val_acc: 0.9906\n",
      "Epoch 321/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0171 - acc: 0.9970 - val_loss: 0.0091 - val_acc: 0.9969\n",
      "Epoch 322/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0064 - acc: 0.9991 - val_loss: 0.0169 - val_acc: 0.9938\n",
      "Epoch 323/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0150 - acc: 0.9970 - val_loss: 0.0267 - val_acc: 0.9938\n",
      "Epoch 324/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0201 - acc: 0.9957 - val_loss: 0.0388 - val_acc: 0.9938\n",
      "Epoch 325/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0149 - acc: 0.9970 - val_loss: 0.0282 - val_acc: 0.9969\n",
      "Epoch 326/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0198 - acc: 0.9931 - val_loss: 0.1690 - val_acc: 0.9563\n",
      "Epoch 327/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0269 - acc: 0.9913 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 328/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0164 - acc: 0.9961 - val_loss: 0.0220 - val_acc: 0.9906\n",
      "Epoch 329/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0348 - acc: 0.9926 - val_loss: 0.0424 - val_acc: 0.9812\n",
      "Epoch 330/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0214 - acc: 0.9952 - val_loss: 0.0314 - val_acc: 0.9906\n",
      "Epoch 331/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0139 - acc: 0.9970 - val_loss: 0.0163 - val_acc: 0.9969\n",
      "Epoch 332/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0249 - acc: 0.9922 - val_loss: 0.0526 - val_acc: 0.9844\n",
      "Epoch 333/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0079 - acc: 0.9970 - val_loss: 0.0233 - val_acc: 0.9906\n",
      "Epoch 334/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0105 - acc: 0.9983 - val_loss: 0.0448 - val_acc: 0.9875\n",
      "Epoch 335/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0041 - acc: 0.9996 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 336/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0133 - acc: 0.9970 - val_loss: 0.0208 - val_acc: 0.9938\n",
      "Epoch 337/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0126 - acc: 0.9970 - val_loss: 0.0139 - val_acc: 0.9938\n",
      "Epoch 338/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0307 - acc: 0.9935 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 339/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0274 - acc: 0.9909 - val_loss: 0.0112 - val_acc: 0.9969\n",
      "Epoch 340/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0446 - acc: 0.9887 - val_loss: 0.0608 - val_acc: 0.9750\n",
      "Epoch 341/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0362 - acc: 0.9878 - val_loss: 0.0361 - val_acc: 0.9875\n",
      "Epoch 342/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0248 - acc: 0.9957 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 343/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0110 - acc: 0.9970 - val_loss: 0.0120 - val_acc: 0.9969\n",
      "Epoch 344/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0115 - acc: 0.9974 - val_loss: 0.0093 - val_acc: 0.9969\n",
      "Epoch 345/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9969\n",
      "Epoch 346/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0057 - acc: 0.9987 - val_loss: 8.4407e-04 - val_acc: 1.0000\n",
      "Epoch 347/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0122 - acc: 0.9961 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 348/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0084 - acc: 0.9987 - val_loss: 0.0069 - val_acc: 0.9969\n",
      "Epoch 349/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0068 - acc: 0.9991 - val_loss: 0.0056 - val_acc: 0.9969\n",
      "Epoch 350/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0034 - val_acc: 0.9969\n",
      "Epoch 351/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0221 - acc: 0.9939 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 352/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0254 - acc: 0.9948 - val_loss: 0.0228 - val_acc: 0.9906\n",
      "Epoch 353/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0246 - acc: 0.9944 - val_loss: 0.0126 - val_acc: 0.9938\n",
      "Epoch 354/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0153 - acc: 0.9952 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 355/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0036 - acc: 0.9983 - val_loss: 0.0077 - val_acc: 0.9969\n",
      "Epoch 356/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0086 - acc: 0.9991 - val_loss: 0.0082 - val_acc: 0.9969\n",
      "Epoch 357/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0276 - acc: 0.9944 - val_loss: 0.0272 - val_acc: 0.9969\n",
      "Epoch 358/1000\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.0193 - acc: 0.9939 - val_loss: 0.0278 - val_acc: 0.9875\n",
      "Epoch 359/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0212 - acc: 0.9926 - val_loss: 0.0285 - val_acc: 0.9906\n",
      "Epoch 360/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0157 - acc: 0.9983 - val_loss: 0.0197 - val_acc: 0.9875\n",
      "Epoch 361/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 362/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0153 - acc: 0.9965 - val_loss: 0.0096 - val_acc: 0.9938\n",
      "Epoch 363/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0123 - acc: 0.9965 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 364/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0096 - acc: 0.9983 - val_loss: 0.0678 - val_acc: 0.9875\n",
      "Epoch 365/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 366/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0180 - acc: 0.9952 - val_loss: 0.0084 - val_acc: 0.9938\n",
      "Epoch 367/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0066 - acc: 0.9987 - val_loss: 0.0077 - val_acc: 0.9969\n",
      "Epoch 368/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0056 - val_acc: 0.9969\n",
      "Epoch 369/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0117 - val_acc: 0.9938\n",
      "Epoch 370/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0073 - val_acc: 0.9969\n",
      "Epoch 371/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0074 - acc: 0.9991 - val_loss: 0.0070 - val_acc: 0.9969\n",
      "Epoch 372/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0128 - val_acc: 0.9938\n",
      "Epoch 373/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0086 - acc: 0.9991 - val_loss: 0.0208 - val_acc: 0.9938\n",
      "Epoch 374/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0067 - acc: 0.9991 - val_loss: 0.0209 - val_acc: 0.9938\n",
      "Epoch 375/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0078 - acc: 0.9987 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 376/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0319 - val_acc: 0.9938\n",
      "Epoch 377/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0212 - acc: 0.9957 - val_loss: 0.0392 - val_acc: 0.9750\n",
      "Epoch 378/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0335 - acc: 0.9952 - val_loss: 0.0507 - val_acc: 0.9938\n",
      "Epoch 379/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0220 - acc: 0.9939 - val_loss: 0.0147 - val_acc: 1.0000\n",
      "Epoch 380/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0431 - acc: 0.9905 - val_loss: 0.0492 - val_acc: 0.9906\n",
      "Epoch 381/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0284 - acc: 0.9931 - val_loss: 0.0236 - val_acc: 0.9969\n",
      "Epoch 382/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0212 - acc: 0.9891 - val_loss: 0.0161 - val_acc: 0.9938\n",
      "Epoch 383/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0253 - acc: 0.9926 - val_loss: 0.0197 - val_acc: 0.9938\n",
      "Epoch 384/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0173 - acc: 0.9965 - val_loss: 0.0292 - val_acc: 0.9906\n",
      "Epoch 385/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0468 - acc: 0.9891 - val_loss: 0.0236 - val_acc: 1.0000\n",
      "Epoch 386/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0116 - acc: 0.9970 - val_loss: 0.0702 - val_acc: 0.9875\n",
      "Epoch 387/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0172 - acc: 0.9961 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 388/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 389/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0149 - acc: 0.9965 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 390/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0102 - acc: 0.9983 - val_loss: 0.0158 - val_acc: 0.9938\n",
      "Epoch 391/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0200 - acc: 0.9961 - val_loss: 0.0121 - val_acc: 0.9969\n",
      "Epoch 392/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0163 - acc: 0.9957 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 393/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0093 - acc: 0.9987 - val_loss: 0.0620 - val_acc: 0.9844\n",
      "Epoch 394/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0136 - acc: 0.9957 - val_loss: 0.0466 - val_acc: 0.9875\n",
      "Epoch 395/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0326 - acc: 0.9922 - val_loss: 0.0475 - val_acc: 0.9844\n",
      "Epoch 396/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0145 - acc: 0.9965 - val_loss: 0.1059 - val_acc: 0.9781\n",
      "Epoch 397/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0153 - acc: 0.9965 - val_loss: 0.0110 - val_acc: 0.9938\n",
      "Epoch 398/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0349 - val_acc: 0.9875\n",
      "Epoch 399/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0077 - acc: 0.9978 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 400/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0083 - acc: 0.9987 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 401/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 402/1000\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.0122 - acc: 0.9965 - val_loss: 0.0190 - val_acc: 0.9938\n",
      "Epoch 403/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0219 - acc: 0.9970 - val_loss: 0.0330 - val_acc: 0.9938\n",
      "Epoch 404/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0064 - val_acc: 0.9969\n",
      "Epoch 405/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0063 - acc: 0.9987 - val_loss: 0.0109 - val_acc: 0.9969\n",
      "Epoch 406/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0140 - val_acc: 0.9969\n",
      "Epoch 407/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 0.0079 - val_acc: 0.9969\n",
      "Epoch 408/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0056 - acc: 0.9996 - val_loss: 0.0239 - val_acc: 0.9969\n",
      "Epoch 409/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0358 - acc: 0.9926 - val_loss: 0.0416 - val_acc: 0.9875\n",
      "Epoch 410/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0563 - acc: 0.9870 - val_loss: 0.0312 - val_acc: 0.9969\n",
      "Epoch 411/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0407 - acc: 0.9926 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 412/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0223 - acc: 0.9939 - val_loss: 0.0115 - val_acc: 0.9938\n",
      "Epoch 413/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0374 - acc: 0.9887 - val_loss: 0.0138 - val_acc: 0.9969\n",
      "Epoch 414/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0304 - acc: 0.9935 - val_loss: 0.0320 - val_acc: 0.9938\n",
      "Epoch 415/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0204 - acc: 0.9952 - val_loss: 0.0280 - val_acc: 0.9938\n",
      "Epoch 416/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0098 - acc: 0.9983 - val_loss: 0.0089 - val_acc: 0.9969\n",
      "Epoch 417/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0129 - acc: 0.9952 - val_loss: 0.0624 - val_acc: 0.9875\n",
      "Epoch 418/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0152 - acc: 0.9965 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 419/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0200 - acc: 0.9952 - val_loss: 0.0812 - val_acc: 0.9500\n",
      "Epoch 420/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0159 - acc: 0.9961 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 421/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0233 - acc: 0.9935 - val_loss: 0.0201 - val_acc: 0.9938\n",
      "Epoch 422/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 423/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 424/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 425/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0376 - val_acc: 0.9906\n",
      "Epoch 426/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0130 - acc: 0.9970 - val_loss: 0.0271 - val_acc: 0.9938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 427/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0167 - val_acc: 0.9938\n",
      "Epoch 428/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0049 - acc: 0.9983 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 429/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0184 - acc: 0.9957 - val_loss: 0.0468 - val_acc: 0.9812\n",
      "Epoch 430/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0091 - acc: 0.9978 - val_loss: 0.0129 - val_acc: 0.9969\n",
      "Epoch 431/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0200 - acc: 0.9965 - val_loss: 0.0113 - val_acc: 0.9938\n",
      "Epoch 432/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0101 - val_acc: 0.9969\n",
      "Epoch 433/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0090 - acc: 0.9987 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 434/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0131 - acc: 0.9970 - val_loss: 0.0107 - val_acc: 0.9938\n",
      "Epoch 435/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0054 - acc: 0.9978 - val_loss: 0.1232 - val_acc: 0.9688\n",
      "Epoch 436/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0155 - acc: 0.9957 - val_loss: 0.0284 - val_acc: 0.9875\n",
      "Epoch 437/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0150 - acc: 0.9965 - val_loss: 0.0350 - val_acc: 0.9812\n",
      "Epoch 438/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0054 - acc: 0.9991 - val_loss: 0.0536 - val_acc: 0.9906\n",
      "Epoch 439/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0155 - acc: 0.9948 - val_loss: 0.0430 - val_acc: 0.9875\n",
      "Epoch 440/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0117 - acc: 0.9970 - val_loss: 0.0352 - val_acc: 0.9844\n",
      "Epoch 441/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0058 - val_acc: 0.9969\n",
      "Epoch 442/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0239 - acc: 0.9965 - val_loss: 0.0151 - val_acc: 0.9938\n",
      "Epoch 443/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0083 - acc: 0.9961 - val_loss: 0.0166 - val_acc: 0.9938\n",
      "Epoch 444/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0121 - acc: 0.9974 - val_loss: 0.0135 - val_acc: 0.9969\n",
      "Epoch 445/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0098 - acc: 0.9974 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 446/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 447/1000\n",
      "72/72 [==============================] - 3s 37ms/step - loss: 0.0193 - acc: 0.9952 - val_loss: 0.0117 - val_acc: 0.9969\n",
      "Epoch 448/1000\n",
      "72/72 [==============================] - 2s 33ms/step - loss: 0.0087 - acc: 0.9974 - val_loss: 7.4589e-04 - val_acc: 1.0000\n",
      "Epoch 449/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0095 - acc: 0.9983 - val_loss: 0.0260 - val_acc: 0.9906\n",
      "Epoch 450/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0183 - acc: 0.9965 - val_loss: 0.0229 - val_acc: 0.9938\n",
      "Epoch 451/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0143 - acc: 0.9970 - val_loss: 0.0172 - val_acc: 0.9969\n",
      "Epoch 452/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0097 - acc: 0.9983 - val_loss: 0.0712 - val_acc: 0.9781\n",
      "Epoch 453/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0096 - acc: 0.9983 - val_loss: 0.0289 - val_acc: 0.9938\n",
      "Epoch 454/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0084 - acc: 0.9991 - val_loss: 0.0178 - val_acc: 0.9969\n",
      "Epoch 455/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0044 - acc: 0.9983 - val_loss: 0.0170 - val_acc: 0.9938\n",
      "Epoch 456/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0397 - val_acc: 0.9844\n",
      "Epoch 457/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0150 - acc: 0.9974 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 458/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0252 - acc: 0.9944 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 459/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0089 - acc: 0.9983 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 460/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0055 - acc: 0.9974 - val_loss: 0.0314 - val_acc: 0.9844\n",
      "Epoch 461/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0110 - acc: 0.9961 - val_loss: 0.0275 - val_acc: 0.9906\n",
      "Epoch 462/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0380 - acc: 0.9922 - val_loss: 0.0180 - val_acc: 0.9938\n",
      "Epoch 463/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0252 - acc: 0.9939 - val_loss: 0.0136 - val_acc: 0.9906\n",
      "Epoch 464/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0105 - acc: 0.9970 - val_loss: 0.0091 - val_acc: 0.9969\n",
      "Epoch 465/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0740 - val_acc: 0.9875\n",
      "Epoch 466/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0171 - acc: 0.9935 - val_loss: 0.0065 - val_acc: 0.9969\n",
      "Epoch 467/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0234 - acc: 0.9957 - val_loss: 0.0089 - val_acc: 0.9969\n",
      "Epoch 468/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0167 - acc: 0.9961 - val_loss: 0.0056 - val_acc: 0.9969\n",
      "Epoch 469/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0100 - acc: 0.9965 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 470/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0229 - acc: 0.9957 - val_loss: 0.0341 - val_acc: 0.9875\n",
      "Epoch 471/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0119 - acc: 0.9978 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 472/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0098 - acc: 0.9978 - val_loss: 0.0180 - val_acc: 0.9906\n",
      "Epoch 473/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0118 - acc: 0.9987 - val_loss: 0.0714 - val_acc: 0.9719\n",
      "Epoch 474/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0149 - acc: 0.9957 - val_loss: 0.0147 - val_acc: 0.9938\n",
      "Epoch 475/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0125 - acc: 0.9974 - val_loss: 0.0189 - val_acc: 0.9938\n",
      "Epoch 476/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0159 - acc: 0.9974 - val_loss: 0.0054 - val_acc: 0.9969\n",
      "Epoch 477/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0223 - acc: 0.9961 - val_loss: 0.0357 - val_acc: 0.9906\n",
      "Epoch 478/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0161 - acc: 0.9961 - val_loss: 0.0455 - val_acc: 0.9906\n",
      "Epoch 479/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0228 - acc: 0.9952 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 480/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0157 - acc: 0.9965 - val_loss: 0.0119 - val_acc: 0.9938\n",
      "Epoch 481/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0226 - acc: 0.9952 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 482/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0209 - acc: 0.9961 - val_loss: 0.0510 - val_acc: 0.9781\n",
      "Epoch 483/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0205 - acc: 0.9952 - val_loss: 0.0203 - val_acc: 0.9906\n",
      "Epoch 484/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0083 - acc: 0.9983 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 485/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0111 - val_acc: 0.9938\n",
      "Epoch 486/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0307 - val_acc: 0.9938\n",
      "Epoch 487/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0137 - acc: 0.9961 - val_loss: 0.0085 - val_acc: 0.9969\n",
      "Epoch 488/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.0390 - val_acc: 0.9875\n",
      "Epoch 489/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0218 - val_acc: 0.9906\n",
      "Epoch 490/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0077 - acc: 0.9978 - val_loss: 0.1162 - val_acc: 0.9719\n",
      "Epoch 491/1000\n",
      "72/72 [==============================] - 2s 34ms/step - loss: 0.0236 - acc: 0.9944 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 492/1000\n",
      "72/72 [==============================] - 2s 34ms/step - loss: 0.0104 - acc: 0.9957 - val_loss: 0.0458 - val_acc: 0.9938\n",
      "Epoch 493/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0281 - acc: 0.9926 - val_loss: 0.0071 - val_acc: 0.9969\n",
      "Epoch 494/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0111 - acc: 0.9978 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 495/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0147 - acc: 0.9965 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 496/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0045 - acc: 0.9983 - val_loss: 0.0344 - val_acc: 0.9875\n",
      "Epoch 497/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 0.0052 - val_acc: 0.9969\n",
      "Epoch 498/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0074 - acc: 0.9987 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 499/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 500/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0106 - acc: 0.9970 - val_loss: 0.0123 - val_acc: 0.9938\n",
      "Epoch 501/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0265 - val_acc: 0.9938\n",
      "Epoch 502/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.0190 - val_acc: 0.9969\n",
      "Epoch 503/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0135 - acc: 0.9952 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 504/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0166 - acc: 0.9965 - val_loss: 0.0180 - val_acc: 0.9969\n",
      "Epoch 505/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0223 - acc: 0.9957 - val_loss: 0.0153 - val_acc: 0.9969\n",
      "Epoch 506/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0117 - acc: 0.9978 - val_loss: 0.0087 - val_acc: 0.9969\n",
      "Epoch 507/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0262 - acc: 0.9922 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 508/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0194 - acc: 0.9961 - val_loss: 0.0140 - val_acc: 1.0000\n",
      "Epoch 509/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0114 - acc: 0.9970 - val_loss: 0.0092 - val_acc: 0.9969\n",
      "Epoch 510/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0135 - val_acc: 0.9969\n",
      "Epoch 511/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0142 - acc: 0.9974 - val_loss: 0.0210 - val_acc: 0.9969\n",
      "Epoch 512/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0202 - acc: 0.9948 - val_loss: 0.0126 - val_acc: 0.9938\n",
      "Epoch 513/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0121 - val_acc: 0.9938\n",
      "Epoch 514/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0047 - val_acc: 0.9969\n",
      "Epoch 515/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0119 - acc: 0.9974 - val_loss: 0.0708 - val_acc: 0.9875\n",
      "Epoch 516/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0297 - acc: 0.9935 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 517/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0209 - acc: 0.9957 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 518/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0088 - val_acc: 0.9969\n",
      "Epoch 519/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0134 - acc: 0.9978 - val_loss: 0.0045 - val_acc: 0.9969\n",
      "Epoch 520/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0073 - acc: 0.9991 - val_loss: 0.0174 - val_acc: 0.9906\n",
      "Epoch 521/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0046 - acc: 0.9996 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 522/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0073 - val_acc: 0.9969\n",
      "Epoch 523/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 4.5009e-04 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 0.9938\n",
      "Epoch 524/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0122 - val_acc: 0.9938\n",
      "Epoch 525/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0085 - acc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9969\n",
      "Epoch 526/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0099 - val_acc: 0.9938\n",
      "Epoch 527/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0040 - acc: 0.9991 - val_loss: 0.0059 - val_acc: 0.9969\n",
      "Epoch 528/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0213 - acc: 0.9965 - val_loss: 0.0188 - val_acc: 0.9969\n",
      "Epoch 529/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0261 - acc: 0.9948 - val_loss: 0.0487 - val_acc: 0.9844\n",
      "Epoch 530/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0198 - acc: 0.9948 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 531/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0137 - acc: 0.9970 - val_loss: 0.0079 - val_acc: 0.9969\n",
      "Epoch 532/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0433 - acc: 0.9931 - val_loss: 0.0337 - val_acc: 0.9906\n",
      "Epoch 533/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0190 - val_acc: 0.9938\n",
      "Epoch 534/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0150 - acc: 0.9961 - val_loss: 0.0194 - val_acc: 0.9969\n",
      "Epoch 535/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 536/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.0101 - acc: 0.9961 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 537/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0336 - acc: 0.9926 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 538/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0232 - acc: 0.9952 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 539/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0212 - acc: 0.9961 - val_loss: 0.0221 - val_acc: 0.9969\n",
      "Epoch 540/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0447 - val_acc: 0.9938\n",
      "Epoch 541/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0065 - acc: 0.9983 - val_loss: 0.0132 - val_acc: 0.9969\n",
      "Epoch 542/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 7.2228e-04 - val_acc: 1.0000\n",
      "Epoch 543/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 544/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0286 - acc: 0.9926 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 545/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0083 - acc: 0.9983 - val_loss: 0.0588 - val_acc: 0.9781\n",
      "Epoch 546/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0097 - acc: 0.9983 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 547/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0082 - acc: 0.9970 - val_loss: 0.0052 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 548/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0130 - acc: 0.9978 - val_loss: 0.0696 - val_acc: 0.9750\n",
      "Epoch 549/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0038 - val_acc: 0.9969\n",
      "Epoch 550/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 9.7549e-04 - val_acc: 1.0000\n",
      "Epoch 551/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.0086 - val_acc: 0.9969\n",
      "Epoch 552/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0135 - acc: 0.9970 - val_loss: 0.0346 - val_acc: 0.9906\n",
      "Epoch 553/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0047 - acc: 0.9983 - val_loss: 9.2307e-04 - val_acc: 1.0000\n",
      "Epoch 554/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 555/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0058 - val_acc: 0.9969\n",
      "Epoch 556/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0143 - acc: 0.9978 - val_loss: 0.0084 - val_acc: 0.9969\n",
      "Epoch 557/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0054 - val_acc: 0.9969\n",
      "Epoch 558/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0086 - acc: 0.9987 - val_loss: 0.0078 - val_acc: 0.9969\n",
      "Epoch 559/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0074 - val_acc: 0.9969\n",
      "Epoch 560/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0075 - acc: 0.9991 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 561/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0138 - val_acc: 0.9938\n",
      "Epoch 562/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0074 - acc: 0.9983 - val_loss: 0.0056 - val_acc: 0.9969\n",
      "Epoch 563/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0171 - val_acc: 0.9938\n",
      "Epoch 564/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0042 - acc: 0.9991 - val_loss: 0.0079 - val_acc: 0.9969\n",
      "Epoch 565/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0249 - val_acc: 0.9812\n",
      "Epoch 566/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0105 - acc: 0.9965 - val_loss: 0.0080 - val_acc: 0.9969\n",
      "Epoch 567/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0164 - acc: 0.9952 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 568/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 569/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0130 - acc: 0.9957 - val_loss: 0.0152 - val_acc: 0.9938\n",
      "Epoch 570/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0443 - acc: 0.9905 - val_loss: 0.0247 - val_acc: 0.9906\n",
      "Epoch 571/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0391 - acc: 0.9896 - val_loss: 0.0169 - val_acc: 0.9906\n",
      "Epoch 572/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0172 - acc: 0.9944 - val_loss: 0.0080 - val_acc: 0.9969\n",
      "Epoch 573/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0135 - acc: 0.9974 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 574/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0091 - acc: 0.9987 - val_loss: 0.0494 - val_acc: 0.9844\n",
      "Epoch 575/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0079 - acc: 0.9987 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 576/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0085 - acc: 0.9991 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 577/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0116 - acc: 0.9974 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 578/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0229 - acc: 0.9961 - val_loss: 0.0439 - val_acc: 0.9781\n",
      "Epoch 579/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 0.9875\n",
      "Epoch 580/1000\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.0149 - acc: 0.9974 - val_loss: 0.0135 - val_acc: 0.9969\n",
      "Epoch 581/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0348 - acc: 0.9918 - val_loss: 0.0108 - val_acc: 0.9906\n",
      "Epoch 582/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0118 - acc: 0.9974 - val_loss: 0.0062 - val_acc: 0.9969\n",
      "Epoch 583/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 584/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0135 - acc: 0.9974 - val_loss: 0.0182 - val_acc: 0.9875\n",
      "Epoch 585/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0129 - val_acc: 0.9906\n",
      "Epoch 586/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0141 - acc: 0.9974 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 587/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0138 - val_acc: 0.9969\n",
      "Epoch 588/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0104 - acc: 0.9987 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 589/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0145 - acc: 0.9970 - val_loss: 0.0134 - val_acc: 0.9938\n",
      "Epoch 590/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0200 - acc: 0.9957 - val_loss: 0.0080 - val_acc: 0.9969\n",
      "Epoch 591/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0093 - acc: 0.9987 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 592/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0251 - acc: 0.9952 - val_loss: 0.0477 - val_acc: 0.9875\n",
      "Epoch 593/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0158 - acc: 0.9957 - val_loss: 0.0293 - val_acc: 0.9906\n",
      "Epoch 594/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0114 - acc: 0.9978 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 595/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0231 - acc: 0.9961 - val_loss: 0.0224 - val_acc: 0.9938\n",
      "Epoch 596/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0290 - acc: 0.9918 - val_loss: 0.0772 - val_acc: 0.9812\n",
      "Epoch 597/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0317 - acc: 0.9905 - val_loss: 0.0100 - val_acc: 0.9969\n",
      "Epoch 598/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0227 - acc: 0.9931 - val_loss: 0.0226 - val_acc: 0.9938\n",
      "Epoch 599/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0109 - acc: 0.9974 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 600/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0150 - acc: 0.9965 - val_loss: 0.0089 - val_acc: 0.9969\n",
      "Epoch 601/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0127 - acc: 0.9974 - val_loss: 0.0110 - val_acc: 0.9969\n",
      "Epoch 602/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0151 - acc: 0.9961 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 603/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 604/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0044 - val_acc: 0.9969\n",
      "Epoch 605/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 606/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0041 - acc: 0.9996 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 607/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0053 - acc: 0.9996 - val_loss: 0.0069 - val_acc: 0.9969\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0115 - acc: 0.9961 - val_loss: 0.0066 - val_acc: 0.9969\n",
      "Epoch 609/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0139 - acc: 0.9978 - val_loss: 0.0144 - val_acc: 0.9938\n",
      "Epoch 610/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0219 - acc: 0.9965 - val_loss: 0.0125 - val_acc: 0.9969\n",
      "Epoch 611/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0162 - acc: 0.9965 - val_loss: 0.0141 - val_acc: 0.9938\n",
      "Epoch 612/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0269 - acc: 0.9944 - val_loss: 0.0362 - val_acc: 0.9906\n",
      "Epoch 613/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0164 - acc: 0.9970 - val_loss: 0.0865 - val_acc: 0.9812\n",
      "Epoch 614/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0143 - acc: 0.9961 - val_loss: 0.0149 - val_acc: 0.9938\n",
      "Epoch 615/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0230 - acc: 0.9931 - val_loss: 0.0747 - val_acc: 0.9781\n",
      "Epoch 616/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0128 - acc: 0.9952 - val_loss: 0.0150 - val_acc: 0.9969\n",
      "Epoch 617/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0181 - acc: 0.9965 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 618/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0085 - acc: 0.9978 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 619/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0092 - acc: 0.9978 - val_loss: 0.0307 - val_acc: 0.9938\n",
      "Epoch 620/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0076 - acc: 0.9987 - val_loss: 0.0161 - val_acc: 0.9969\n",
      "Epoch 621/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0221 - acc: 0.9948 - val_loss: 0.0357 - val_acc: 0.9938\n",
      "Epoch 622/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0153 - acc: 0.9948 - val_loss: 0.1157 - val_acc: 0.9750\n",
      "Epoch 623/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0173 - val_acc: 0.9906\n",
      "Epoch 624/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0273 - acc: 0.9939 - val_loss: 0.0269 - val_acc: 0.9969\n",
      "Epoch 625/1000\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.0152 - acc: 0.9974 - val_loss: 0.0676 - val_acc: 0.9812\n",
      "Epoch 626/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0186 - acc: 0.9948 - val_loss: 0.0157 - val_acc: 0.9969\n",
      "Epoch 627/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0182 - val_acc: 0.9969\n",
      "Epoch 628/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0709 - val_acc: 0.9844\n",
      "Epoch 629/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0348 - val_acc: 0.9875\n",
      "Epoch 630/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0164 - val_acc: 0.9969\n",
      "Epoch 631/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 632/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0074 - acc: 0.9983 - val_loss: 0.0314 - val_acc: 0.9938\n",
      "Epoch 633/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0075 - acc: 0.9978 - val_loss: 0.0385 - val_acc: 0.9875\n",
      "Epoch 634/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 635/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0068 - acc: 0.9987 - val_loss: 0.0127 - val_acc: 0.9969\n",
      "Epoch 636/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0133 - val_acc: 0.9969\n",
      "Epoch 637/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0161 - acc: 0.9970 - val_loss: 0.0177 - val_acc: 0.9969\n",
      "Epoch 638/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0085 - acc: 0.9983 - val_loss: 0.0189 - val_acc: 0.9938\n",
      "Epoch 639/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0069 - acc: 0.9987 - val_loss: 0.0112 - val_acc: 0.9969\n",
      "Epoch 640/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0215 - val_acc: 0.9938\n",
      "Epoch 641/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0157 - val_acc: 0.9969\n",
      "Epoch 642/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0114 - acc: 0.9987 - val_loss: 0.0145 - val_acc: 0.9969\n",
      "Epoch 643/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0131 - val_acc: 0.9969\n",
      "Epoch 644/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0092 - acc: 0.9987 - val_loss: 0.0094 - val_acc: 0.9938\n",
      "Epoch 645/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 5.6953e-04 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9969\n",
      "Epoch 646/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0282 - acc: 0.9948 - val_loss: 0.0124 - val_acc: 0.9938\n",
      "Epoch 647/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0091 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 648/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0162 - acc: 0.9948 - val_loss: 0.0164 - val_acc: 0.9938\n",
      "Epoch 649/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0145 - acc: 0.9974 - val_loss: 0.0407 - val_acc: 0.9875\n",
      "Epoch 650/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 651/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0041 - acc: 0.9983 - val_loss: 0.1486 - val_acc: 0.9688\n",
      "Epoch 652/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0163 - acc: 0.9974 - val_loss: 0.0433 - val_acc: 0.9938\n",
      "Epoch 653/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0052 - acc: 0.9991 - val_loss: 0.0198 - val_acc: 0.9969\n",
      "Epoch 654/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0114 - acc: 0.9974 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 655/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 0.0094 - val_acc: 0.9969\n",
      "Epoch 656/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0271 - acc: 0.9948 - val_loss: 7.2676e-04 - val_acc: 1.0000\n",
      "Epoch 657/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0220 - acc: 0.9957 - val_loss: 0.0163 - val_acc: 0.9969\n",
      "Epoch 658/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0195 - acc: 0.9952 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 659/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0124 - acc: 0.9961 - val_loss: 0.0066 - val_acc: 0.9969\n",
      "Epoch 660/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0192 - acc: 0.9970 - val_loss: 0.0242 - val_acc: 0.9969\n",
      "Epoch 661/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0157 - acc: 0.9974 - val_loss: 0.0194 - val_acc: 0.9969\n",
      "Epoch 662/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0191 - acc: 0.9961 - val_loss: 0.0237 - val_acc: 0.9969\n",
      "Epoch 663/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0629 - acc: 0.9887 - val_loss: 0.0825 - val_acc: 0.9938\n",
      "Epoch 664/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0324 - acc: 0.9891 - val_loss: 0.0243 - val_acc: 0.9938\n",
      "Epoch 665/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0102 - acc: 0.9983 - val_loss: 0.0450 - val_acc: 0.9906\n",
      "Epoch 666/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0259 - acc: 0.9935 - val_loss: 0.0461 - val_acc: 0.9906\n",
      "Epoch 667/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0094 - acc: 0.9974 - val_loss: 0.0254 - val_acc: 0.9906\n",
      "Epoch 668/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0113 - acc: 0.9978 - val_loss: 0.0654 - val_acc: 0.9938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669/1000\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.0133 - acc: 0.9970 - val_loss: 0.0194 - val_acc: 0.9938\n",
      "Epoch 670/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0174 - acc: 0.9957 - val_loss: 0.0219 - val_acc: 0.9938\n",
      "Epoch 671/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0201 - acc: 0.9970 - val_loss: 0.0195 - val_acc: 0.9938\n",
      "Epoch 672/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0120 - acc: 0.9974 - val_loss: 0.0100 - val_acc: 0.9969\n",
      "Epoch 673/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0051 - acc: 0.9991 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 674/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 675/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0122 - acc: 0.9978 - val_loss: 0.0571 - val_acc: 0.9844\n",
      "Epoch 676/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0168 - acc: 0.9974 - val_loss: 0.0187 - val_acc: 0.9969\n",
      "Epoch 677/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0102 - acc: 0.9978 - val_loss: 0.0260 - val_acc: 0.9969\n",
      "Epoch 678/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.0147 - val_acc: 0.9969\n",
      "Epoch 679/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0051 - acc: 0.9991 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 680/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0102 - acc: 0.9978 - val_loss: 0.0191 - val_acc: 0.9938\n",
      "Epoch 681/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0639 - val_acc: 0.9938\n",
      "Epoch 682/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0058 - acc: 0.9974 - val_loss: 0.0220 - val_acc: 0.9969\n",
      "Epoch 683/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0171 - acc: 0.9974 - val_loss: 0.0275 - val_acc: 0.9969\n",
      "Epoch 684/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 685/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0192 - acc: 0.9948 - val_loss: 0.0223 - val_acc: 0.9969\n",
      "Epoch 686/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0052 - val_acc: 0.9969\n",
      "Epoch 687/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0083 - acc: 0.9987 - val_loss: 0.1073 - val_acc: 0.9719\n",
      "Epoch 688/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0110 - val_acc: 0.9938\n",
      "Epoch 689/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 7.2130e-04 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9969\n",
      "Epoch 690/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 691/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0210 - val_acc: 0.9969\n",
      "Epoch 692/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0029 - acc: 0.9987 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 693/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 3.2419e-04 - acc: 1.0000 - val_loss: 0.0290 - val_acc: 0.9906\n",
      "Epoch 694/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0086 - acc: 0.9983 - val_loss: 0.0257 - val_acc: 0.9938\n",
      "Epoch 695/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0065 - acc: 0.9987 - val_loss: 0.0130 - val_acc: 0.9969\n",
      "Epoch 696/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0023 - acc: 0.9987 - val_loss: 0.0332 - val_acc: 0.9906\n",
      "Epoch 697/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0123 - acc: 0.9978 - val_loss: 0.0651 - val_acc: 0.9875\n",
      "Epoch 698/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0139 - acc: 0.9978 - val_loss: 0.0222 - val_acc: 0.9969\n",
      "Epoch 699/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0041 - acc: 0.9991 - val_loss: 0.0436 - val_acc: 0.9906\n",
      "Epoch 700/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 701/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0076 - acc: 0.9987 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 702/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0263 - acc: 0.9944 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 703/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0323 - acc: 0.9918 - val_loss: 0.0143 - val_acc: 0.9938\n",
      "Epoch 704/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0251 - acc: 0.9939 - val_loss: 0.0312 - val_acc: 0.9844\n",
      "Epoch 705/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0280 - acc: 0.9944 - val_loss: 0.0480 - val_acc: 0.9812\n",
      "Epoch 706/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0205 - acc: 0.9957 - val_loss: 0.0114 - val_acc: 0.9969\n",
      "Epoch 707/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0113 - acc: 0.9983 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 708/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0172 - acc: 0.9970 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 709/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0105 - acc: 0.9991 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 710/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0109 - acc: 0.9974 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 711/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0080 - acc: 0.9978 - val_loss: 0.0322 - val_acc: 0.9844\n",
      "Epoch 712/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0256 - acc: 0.9957 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 713/1000\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.0117 - acc: 0.9970 - val_loss: 0.0103 - val_acc: 0.9969\n",
      "Epoch 714/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0155 - acc: 0.9970 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 715/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 716/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0155 - acc: 0.9970 - val_loss: 0.0489 - val_acc: 0.9938\n",
      "Epoch 717/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0165 - acc: 0.9974 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 718/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 719/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 720/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0134 - val_acc: 0.9969\n",
      "Epoch 721/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 6.1160e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9969\n",
      "Epoch 722/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0023 - acc: 0.9987 - val_loss: 0.0623 - val_acc: 0.9875\n",
      "Epoch 723/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 724/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0135 - acc: 0.9965 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 725/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0464 - val_acc: 0.9875\n",
      "Epoch 726/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0255 - acc: 0.9961 - val_loss: 0.0509 - val_acc: 0.9812\n",
      "Epoch 727/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0189 - acc: 0.9961 - val_loss: 0.0075 - val_acc: 0.9969\n",
      "Epoch 728/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0136 - acc: 0.9983 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 729/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0135 - val_acc: 0.9969\n",
      "Epoch 730/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0086 - acc: 0.9970 - val_loss: 0.0132 - val_acc: 0.9938\n",
      "Epoch 731/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0129 - acc: 0.9978 - val_loss: 0.0251 - val_acc: 0.9969\n",
      "Epoch 732/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0069 - acc: 0.9974 - val_loss: 0.0083 - val_acc: 0.9969\n",
      "Epoch 733/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 6.3823e-04 - val_acc: 1.0000\n",
      "Epoch 734/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0042 - acc: 0.9996 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 735/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0441 - val_acc: 0.9781\n",
      "Epoch 736/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0124 - acc: 0.9965 - val_loss: 0.0052 - val_acc: 0.9969\n",
      "Epoch 737/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0457 - acc: 0.9922 - val_loss: 0.0584 - val_acc: 0.9844\n",
      "Epoch 738/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0391 - acc: 0.9896 - val_loss: 0.0208 - val_acc: 0.9938\n",
      "Epoch 739/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0195 - acc: 0.9939 - val_loss: 0.0298 - val_acc: 0.9938\n",
      "Epoch 740/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0052 - acc: 0.9991 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 741/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0091 - acc: 0.9965 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 742/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0123 - acc: 0.9987 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 743/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0108 - acc: 0.9983 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 744/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0085 - acc: 0.9987 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 745/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0100 - acc: 0.9987 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 746/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9969\n",
      "Epoch 747/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0046 - acc: 0.9996 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 748/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 749/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 5.2981e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 750/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0080 - acc: 0.9987 - val_loss: 0.0093 - val_acc: 0.9969\n",
      "Epoch 751/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0132 - acc: 0.9974 - val_loss: 0.0078 - val_acc: 0.9969\n",
      "Epoch 752/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0087 - acc: 0.9983 - val_loss: 0.0107 - val_acc: 0.9969\n",
      "Epoch 753/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0157 - acc: 0.9961 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 754/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0195 - acc: 0.9948 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 755/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0258 - acc: 0.9944 - val_loss: 0.0164 - val_acc: 0.9906\n",
      "Epoch 756/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 0.9969\n",
      "Epoch 757/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.0056 - val_acc: 0.9969\n",
      "Epoch 758/1000\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0095 - val_acc: 0.9969\n",
      "Epoch 759/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0189 - val_acc: 0.9938\n",
      "Epoch 760/1000\n",
      "72/72 [==============================] - 2s 32ms/step - loss: 0.0100 - acc: 0.9983 - val_loss: 0.0208 - val_acc: 0.9938\n",
      "Epoch 761/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0089 - acc: 0.9983 - val_loss: 0.0101 - val_acc: 0.9969\n",
      "Epoch 762/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0049 - acc: 0.9991 - val_loss: 0.0097 - val_acc: 0.9969\n",
      "Epoch 763/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0049 - acc: 0.9996 - val_loss: 0.0425 - val_acc: 0.9875\n",
      "Epoch 764/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0069 - acc: 0.9996 - val_loss: 0.0771 - val_acc: 0.9812\n",
      "Epoch 765/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0123 - acc: 0.9970 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 766/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 767/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0136 - acc: 0.9965 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 768/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0160 - acc: 0.9957 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 769/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0205 - acc: 0.9944 - val_loss: 0.0378 - val_acc: 0.9938\n",
      "Epoch 770/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0233 - acc: 0.9939 - val_loss: 0.0404 - val_acc: 0.9938\n",
      "Epoch 771/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0271 - acc: 0.9939 - val_loss: 0.0262 - val_acc: 0.9938\n",
      "Epoch 772/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0428 - acc: 0.9874 - val_loss: 0.0143 - val_acc: 0.9938\n",
      "Epoch 773/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0194 - acc: 0.9957 - val_loss: 0.1783 - val_acc: 0.9688\n",
      "Epoch 774/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0152 - acc: 0.9978 - val_loss: 0.0123 - val_acc: 0.9969\n",
      "Epoch 775/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0217 - acc: 0.9961 - val_loss: 0.0397 - val_acc: 0.9906\n",
      "Epoch 776/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0157 - acc: 0.9970 - val_loss: 0.0184 - val_acc: 0.9938\n",
      "Epoch 777/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0183 - acc: 0.9965 - val_loss: 0.0157 - val_acc: 0.9938\n",
      "Epoch 778/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0061 - acc: 0.9987 - val_loss: 0.0263 - val_acc: 0.9906\n",
      "Epoch 779/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0128 - acc: 0.9965 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 780/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0191 - acc: 0.9952 - val_loss: 0.0847 - val_acc: 0.9875\n",
      "Epoch 781/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0147 - acc: 0.9957 - val_loss: 0.0399 - val_acc: 0.9938\n",
      "Epoch 782/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0336 - val_acc: 0.9875\n",
      "Epoch 783/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0123 - val_acc: 0.9906\n",
      "Epoch 784/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 785/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0084 - acc: 0.9983 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 786/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0282 - acc: 0.9957 - val_loss: 0.0330 - val_acc: 0.9875\n",
      "Epoch 787/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0165 - acc: 0.9961 - val_loss: 0.0131 - val_acc: 0.9969\n",
      "Epoch 788/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0062 - acc: 0.9991 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 789/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0184 - acc: 0.9978 - val_loss: 0.0050 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 790/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0088 - acc: 0.9991 - val_loss: 0.0274 - val_acc: 0.9969\n",
      "Epoch 791/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0203 - acc: 0.9965 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 792/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0116 - acc: 0.9974 - val_loss: 0.0119 - val_acc: 0.9969\n",
      "Epoch 793/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0101 - acc: 0.9974 - val_loss: 0.0056 - val_acc: 0.9969\n",
      "Epoch 794/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0149 - acc: 0.9961 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 795/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0104 - acc: 0.9978 - val_loss: 0.0543 - val_acc: 0.9906\n",
      "Epoch 796/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0105 - acc: 0.9978 - val_loss: 0.1367 - val_acc: 0.9844\n",
      "Epoch 797/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0171 - acc: 0.9970 - val_loss: 0.0835 - val_acc: 0.9750\n",
      "Epoch 798/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0127 - acc: 0.9978 - val_loss: 0.0644 - val_acc: 0.9875\n",
      "Epoch 799/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0168 - acc: 0.9957 - val_loss: 0.0999 - val_acc: 0.9719\n",
      "Epoch 800/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0131 - acc: 0.9952 - val_loss: 0.1389 - val_acc: 0.9875\n",
      "Epoch 801/1000\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.0144 - acc: 0.9974 - val_loss: 0.0219 - val_acc: 0.9938\n",
      "Epoch 802/1000\n",
      "72/72 [==============================] - 2s 32ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0145 - val_acc: 0.9938\n",
      "Epoch 803/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0118 - val_acc: 0.9938\n",
      "Epoch 804/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0161 - acc: 0.9952 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 805/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0163 - acc: 0.9970 - val_loss: 0.0205 - val_acc: 0.9875\n",
      "Epoch 806/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0225 - acc: 0.9965 - val_loss: 0.0086 - val_acc: 0.9969\n",
      "Epoch 807/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0089 - acc: 0.9978 - val_loss: 0.0188 - val_acc: 0.9906\n",
      "Epoch 808/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0286 - acc: 0.9944 - val_loss: 0.0411 - val_acc: 0.9906\n",
      "Epoch 809/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0164 - acc: 0.9970 - val_loss: 0.0434 - val_acc: 0.9906\n",
      "Epoch 810/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0227 - val_acc: 0.9938\n",
      "Epoch 811/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0060 - acc: 0.9987 - val_loss: 0.0295 - val_acc: 0.9938\n",
      "Epoch 812/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0170 - acc: 0.9935 - val_loss: 0.0121 - val_acc: 0.9969\n",
      "Epoch 813/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0163 - val_acc: 0.9969\n",
      "Epoch 814/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 0.0100 - val_acc: 0.9938\n",
      "Epoch 815/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0062 - acc: 0.9978 - val_loss: 0.0627 - val_acc: 0.9750\n",
      "Epoch 816/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0298 - acc: 0.9957 - val_loss: 0.0491 - val_acc: 0.9844\n",
      "Epoch 817/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0478 - val_acc: 0.9844\n",
      "Epoch 818/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 819/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 820/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0083 - acc: 0.9983 - val_loss: 0.0075 - val_acc: 0.9969\n",
      "Epoch 821/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 822/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 5.5181e-04 - val_acc: 1.0000\n",
      "Epoch 823/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.3099e-04 - acc: 1.0000 - val_loss: 3.9259e-04 - val_acc: 1.0000\n",
      "Epoch 824/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 825/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 6.4501e-04 - acc: 0.9996 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 826/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0051 - acc: 0.9996 - val_loss: 0.0260 - val_acc: 0.9906\n",
      "Epoch 827/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0163 - acc: 0.9974 - val_loss: 0.0151 - val_acc: 0.9906\n",
      "Epoch 828/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0049 - acc: 0.9996 - val_loss: 0.0293 - val_acc: 0.9938\n",
      "Epoch 829/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0247 - val_acc: 0.9969\n",
      "Epoch 830/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 831/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0075 - val_acc: 0.9969\n",
      "Epoch 832/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0503 - acc: 0.9887 - val_loss: 0.0525 - val_acc: 0.9844\n",
      "Epoch 833/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 834/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0208 - acc: 0.9952 - val_loss: 0.0267 - val_acc: 0.9844\n",
      "Epoch 835/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0241 - acc: 0.9931 - val_loss: 0.0632 - val_acc: 0.9781\n",
      "Epoch 836/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0141 - acc: 0.9974 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 837/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0127 - acc: 0.9974 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 838/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0108 - val_acc: 0.9938\n",
      "Epoch 839/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0065 - val_acc: 0.9969\n",
      "Epoch 840/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0073 - acc: 0.9983 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 841/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0114 - acc: 0.9965 - val_loss: 0.0260 - val_acc: 0.9938\n",
      "Epoch 842/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0088 - val_acc: 0.9938\n",
      "Epoch 843/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 4.3041e-04 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 844/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0174 - acc: 0.9978 - val_loss: 3.0705e-04 - val_acc: 1.0000\n",
      "Epoch 845/1000\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.0122 - acc: 0.9983 - val_loss: 0.0094 - val_acc: 0.9906\n",
      "Epoch 846/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0066 - acc: 0.9983 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 847/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0085 - acc: 0.9970 - val_loss: 0.0179 - val_acc: 0.9906\n",
      "Epoch 848/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0106 - acc: 0.9978 - val_loss: 0.0419 - val_acc: 0.9875\n",
      "Epoch 849/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0159 - acc: 0.9983 - val_loss: 0.0222 - val_acc: 0.9969\n",
      "Epoch 850/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0326 - acc: 0.9952 - val_loss: 0.0120 - val_acc: 0.9969\n",
      "Epoch 851/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0106 - val_acc: 0.9969\n",
      "Epoch 852/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0080 - acc: 0.9983 - val_loss: 0.0058 - val_acc: 0.9969\n",
      "Epoch 853/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0174 - acc: 0.9965 - val_loss: 0.0089 - val_acc: 0.9969\n",
      "Epoch 854/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0210 - acc: 0.9952 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 855/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 856/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0123 - acc: 0.9970 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 857/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 858/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 859/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0094 - acc: 0.9978 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 860/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 861/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0131 - acc: 0.9978 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 862/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0049 - acc: 0.9996 - val_loss: 0.1090 - val_acc: 0.9906\n",
      "Epoch 863/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0052 - val_acc: 0.9969\n",
      "Epoch 864/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0069 - acc: 0.9987 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 865/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0085 - acc: 0.9991 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 866/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.3739e-04 - val_acc: 1.0000\n",
      "Epoch 867/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0150 - acc: 0.9965 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 868/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0119 - acc: 0.9978 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 869/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 9.8176e-04 - val_acc: 1.0000\n",
      "Epoch 870/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0041 - acc: 0.9996 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 871/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 872/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0158 - acc: 0.9961 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 873/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0110 - acc: 0.9978 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 874/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0076 - acc: 0.9991 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 875/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0138 - val_acc: 0.9906\n",
      "Epoch 876/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0075 - acc: 0.9983 - val_loss: 0.0140 - val_acc: 0.9969\n",
      "Epoch 877/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9969\n",
      "Epoch 878/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 3.1826e-04 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9969\n",
      "Epoch 879/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0100 - acc: 0.9970 - val_loss: 0.0058 - val_acc: 0.9969\n",
      "Epoch 880/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0125 - acc: 0.9974 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 881/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0171 - acc: 0.9961 - val_loss: 0.0314 - val_acc: 0.9906\n",
      "Epoch 882/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0139 - acc: 0.9974 - val_loss: 0.0375 - val_acc: 0.9875\n",
      "Epoch 883/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0047 - val_acc: 0.9969\n",
      "Epoch 884/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0076 - acc: 0.9983 - val_loss: 0.0272 - val_acc: 0.9875\n",
      "Epoch 885/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0148 - acc: 0.9965 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 886/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 887/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 888/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0037 - acc: 0.9996 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 889/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.0284 - acc: 0.9935 - val_loss: 0.0114 - val_acc: 0.9969\n",
      "Epoch 890/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0303 - acc: 0.9939 - val_loss: 0.0082 - val_acc: 0.9969\n",
      "Epoch 891/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0125 - acc: 0.9965 - val_loss: 0.0285 - val_acc: 0.9875\n",
      "Epoch 892/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0279 - acc: 0.9935 - val_loss: 0.0171 - val_acc: 0.9906\n",
      "Epoch 893/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0183 - acc: 0.9965 - val_loss: 0.0742 - val_acc: 0.9781\n",
      "Epoch 894/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0384 - acc: 0.9887 - val_loss: 0.0423 - val_acc: 0.9969\n",
      "Epoch 895/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0328 - acc: 0.9931 - val_loss: 0.0090 - val_acc: 0.9969\n",
      "Epoch 896/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0376 - acc: 0.9913 - val_loss: 0.0377 - val_acc: 0.9969\n",
      "Epoch 897/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0225 - acc: 0.9965 - val_loss: 0.0199 - val_acc: 0.9969\n",
      "Epoch 898/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0060 - acc: 0.9978 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 899/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0086 - acc: 0.9987 - val_loss: 8.4108e-04 - val_acc: 1.0000\n",
      "Epoch 900/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0095 - acc: 0.9978 - val_loss: 0.0397 - val_acc: 0.9906\n",
      "Epoch 901/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0155 - acc: 0.9965 - val_loss: 0.1393 - val_acc: 0.9844\n",
      "Epoch 902/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0041 - acc: 0.9991 - val_loss: 0.0134 - val_acc: 0.9938\n",
      "Epoch 903/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.0049 - val_acc: 0.9969\n",
      "Epoch 904/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0081 - acc: 0.9978 - val_loss: 0.0119 - val_acc: 0.9938\n",
      "Epoch 905/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0155 - acc: 0.9957 - val_loss: 0.0116 - val_acc: 0.9969\n",
      "Epoch 906/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0096 - acc: 0.9983 - val_loss: 0.0132 - val_acc: 0.9969\n",
      "Epoch 907/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0292 - val_acc: 0.9906\n",
      "Epoch 908/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0237 - acc: 0.9961 - val_loss: 0.0170 - val_acc: 0.9969\n",
      "Epoch 909/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0055 - acc: 0.9974 - val_loss: 0.0425 - val_acc: 0.9906\n",
      "Epoch 910/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0350 - val_acc: 0.9969\n",
      "Epoch 911/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0155 - acc: 0.9965 - val_loss: 0.0559 - val_acc: 0.9906\n",
      "Epoch 912/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0226 - acc: 0.9961 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 913/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0094 - acc: 0.9983 - val_loss: 0.0496 - val_acc: 0.9906\n",
      "Epoch 914/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0073 - acc: 0.9970 - val_loss: 0.0209 - val_acc: 0.9969\n",
      "Epoch 915/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0495 - val_acc: 0.9938\n",
      "Epoch 916/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 917/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 918/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0063 - acc: 0.9987 - val_loss: 0.0314 - val_acc: 0.9969\n",
      "Epoch 919/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0037 - acc: 0.9996 - val_loss: 0.0368 - val_acc: 0.9969\n",
      "Epoch 920/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0071 - acc: 0.9974 - val_loss: 0.0358 - val_acc: 0.9969\n",
      "Epoch 921/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0511 - val_acc: 0.9906\n",
      "Epoch 922/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0234 - acc: 0.9961 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 923/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0106 - acc: 0.9987 - val_loss: 0.0100 - val_acc: 0.9938\n",
      "Epoch 924/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 925/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.0177 - val_acc: 0.9938\n",
      "Epoch 926/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0096 - acc: 0.9987 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 927/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0041 - acc: 0.9996 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 928/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0043 - val_acc: 0.9969\n",
      "Epoch 929/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0121 - acc: 0.9991 - val_loss: 0.0217 - val_acc: 0.9906\n",
      "Epoch 930/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0132 - acc: 0.9983 - val_loss: 0.0334 - val_acc: 0.9969\n",
      "Epoch 931/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0275 - acc: 0.9961 - val_loss: 0.0434 - val_acc: 0.9938\n",
      "Epoch 932/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0490 - val_acc: 0.9938\n",
      "Epoch 933/1000\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.0118 - acc: 0.9983 - val_loss: 0.0355 - val_acc: 0.9938\n",
      "Epoch 934/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0326 - val_acc: 0.9906\n",
      "Epoch 935/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 0.9969\n",
      "Epoch 936/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0188 - acc: 0.9974 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 937/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0059 - acc: 0.9987 - val_loss: 0.0031 - val_acc: 0.9969\n",
      "Epoch 938/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0106 - acc: 0.9991 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 939/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0264 - acc: 0.9957 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 940/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0166 - acc: 0.9957 - val_loss: 0.0419 - val_acc: 0.9969\n",
      "Epoch 941/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0134 - acc: 0.9978 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 942/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 943/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0104 - acc: 0.9983 - val_loss: 0.0097 - val_acc: 0.9969\n",
      "Epoch 944/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0133 - acc: 0.9965 - val_loss: 0.1675 - val_acc: 0.9688\n",
      "Epoch 945/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0126 - acc: 0.9957 - val_loss: 0.0277 - val_acc: 0.9969\n",
      "Epoch 946/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0105 - acc: 0.9965 - val_loss: 0.0510 - val_acc: 0.9875\n",
      "Epoch 947/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0251 - acc: 0.9948 - val_loss: 0.0553 - val_acc: 0.9906\n",
      "Epoch 948/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0122 - acc: 0.9974 - val_loss: 0.0283 - val_acc: 0.9969\n",
      "Epoch 949/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0175 - acc: 0.9939 - val_loss: 0.0346 - val_acc: 0.9969\n",
      "Epoch 950/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0117 - acc: 0.9974 - val_loss: 0.0750 - val_acc: 0.9938\n",
      "Epoch 951/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 8.7925e-04 - acc: 1.0000 - val_loss: 0.0687 - val_acc: 0.9938\n",
      "Epoch 952/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0564 - val_acc: 0.9938\n",
      "Epoch 953/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0083 - acc: 0.9970 - val_loss: 0.0261 - val_acc: 0.9969\n",
      "Epoch 954/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0119 - acc: 0.9983 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 955/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0125 - acc: 0.9974 - val_loss: 0.0472 - val_acc: 0.9938\n",
      "Epoch 956/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.1077 - val_acc: 0.9906\n",
      "Epoch 957/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0265 - val_acc: 0.9969\n",
      "Epoch 958/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0075 - acc: 0.9991 - val_loss: 0.0346 - val_acc: 0.9969\n",
      "Epoch 959/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 960/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0315 - val_acc: 0.9969\n",
      "Epoch 961/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0118 - acc: 0.9974 - val_loss: 0.0397 - val_acc: 0.9875\n",
      "Epoch 962/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0077 - acc: 0.9978 - val_loss: 0.0871 - val_acc: 0.9812\n",
      "Epoch 963/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 964/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0159 - acc: 0.9978 - val_loss: 0.0124 - val_acc: 0.9938\n",
      "Epoch 965/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0106 - acc: 0.9961 - val_loss: 0.0289 - val_acc: 0.9906\n",
      "Epoch 966/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0214 - acc: 0.9952 - val_loss: 0.1188 - val_acc: 0.9625\n",
      "Epoch 967/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0258 - acc: 0.9922 - val_loss: 0.0206 - val_acc: 0.9875\n",
      "Epoch 968/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.0803 - val_acc: 0.9938\n",
      "Epoch 969/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0345 - val_acc: 0.9969\n",
      "Epoch 970/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0047 - acc: 0.9978 - val_loss: 0.0590 - val_acc: 0.9938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 971/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0297 - val_acc: 0.9969\n",
      "Epoch 972/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0055 - acc: 0.9996 - val_loss: 0.0661 - val_acc: 0.9938\n",
      "Epoch 973/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0102 - acc: 0.9978 - val_loss: 0.0141 - val_acc: 0.9906\n",
      "Epoch 974/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0290 - acc: 0.9952 - val_loss: 0.0954 - val_acc: 0.9688\n",
      "Epoch 975/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0419 - acc: 0.9935 - val_loss: 0.1506 - val_acc: 0.9281\n",
      "Epoch 976/1000\n",
      "72/72 [==============================] - 3s 37ms/step - loss: 0.0139 - acc: 0.9965 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 977/1000\n",
      "72/72 [==============================] - 2s 31ms/step - loss: 0.0190 - acc: 0.9961 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 978/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 979/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0053 - acc: 0.9991 - val_loss: 0.0390 - val_acc: 0.9938\n",
      "Epoch 980/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0101 - acc: 0.9983 - val_loss: 0.0068 - val_acc: 0.9969\n",
      "Epoch 981/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.0061 - val_acc: 0.9969\n",
      "Epoch 982/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0166 - acc: 0.9965 - val_loss: 0.0069 - val_acc: 0.9969\n",
      "Epoch 983/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0541 - val_acc: 0.9906\n",
      "Epoch 984/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0135 - acc: 0.9974 - val_loss: 0.0363 - val_acc: 0.9875\n",
      "Epoch 985/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.0180 - val_acc: 0.9969\n",
      "Epoch 986/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0169 - val_acc: 0.9969\n",
      "Epoch 987/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0109 - acc: 0.9978 - val_loss: 5.0521e-04 - val_acc: 1.0000\n",
      "Epoch 988/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0145 - acc: 0.9978 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 989/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0172 - val_acc: 0.9969\n",
      "Epoch 990/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0091 - acc: 0.9978 - val_loss: 0.0156 - val_acc: 0.9969\n",
      "Epoch 991/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 992/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0112 - val_acc: 0.9938\n",
      "Epoch 993/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0082 - acc: 0.9996 - val_loss: 0.0244 - val_acc: 0.9969\n",
      "Epoch 994/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0307 - acc: 0.9939 - val_loss: 0.0305 - val_acc: 0.9938\n",
      "Epoch 995/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0481 - val_acc: 0.9875\n",
      "Epoch 996/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0041 - acc: 0.9974 - val_loss: 0.0569 - val_acc: 0.9875\n",
      "Epoch 997/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0089 - acc: 0.9978 - val_loss: 0.0686 - val_acc: 0.9906\n",
      "Epoch 998/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0146 - acc: 0.9970 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 999/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0201 - acc: 0.9961 - val_loss: 0.0129 - val_acc: 0.9938\n",
      "Epoch 1000/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0090 - acc: 0.9983 - val_loss: 0.0185 - val_acc: 0.9906\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating model: A_A_inceptionv3-cat-final_1000_Nadam.h5 ===\n",
      "\n",
      "Accuracy: 0.988\n",
      "\n",
      "Confusion Matrix\n",
      "[[309   1]\n",
      " [  7 323]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       310\n",
      "          1       1.00      0.98      0.99       330\n",
      "\n",
      "avg / total       0.99      0.99      0.99       640\n",
      "\n",
      "=== Evaluating model: A_A_inceptionv3-cat-best_1000_Nadam.h5 ===\n",
      "\n",
      "Accuracy: 0.989\n",
      "\n",
      "Confusion Matrix\n",
      "[[306   5]\n",
      " [  2 327]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.99       311\n",
      "          1       0.98      0.99      0.99       329\n",
      "\n",
      "avg / total       0.99      0.99      0.99       640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input: Concatenate Vectors\n",
    "# In [9]:\n",
    "train_gen = data_generator(train_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "val_gen = data_generator(val_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "# In [10]:\n",
    "input_1 = Input(shape=(VECTOR_SIZE,))\n",
    "input_2 = Input(shape=(VECTOR_SIZE,))\n",
    "merged = Concatenate(axis=-1)([input_1, input_2]) ###\n",
    "\n",
    "fc1 = Dense(512, kernel_initializer=\"glorot_uniform\")(merged)\n",
    "fc1 = Dropout(0.2)(fc1)\n",
    "fc1 = Activation(\"relu\")(fc1)\n",
    "\n",
    "fc2 = Dense(128, kernel_initializer=\"glorot_uniform\")(fc1)\n",
    "fc2 = Dropout(0.2)(fc2)\n",
    "fc2 = Activation(\"relu\")(fc2)\n",
    "\n",
    "pred = Dense(2, kernel_initializer=\"glorot_uniform\")(fc2)\n",
    "pred = Activation(\"softmax\")(pred)\n",
    "\n",
    "# In [11]:\n",
    "model = Model(inputs=[input_1, input_2], outputs=pred)\n",
    "# model.summary()\n",
    "# In [12]:\n",
    "model.compile(optimizer=\"Nadam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# In [13]:\n",
    "best_model_name = get_model_file(DATA_DIR, \"inceptionv3\", \"cat\", \"best\")\n",
    "checkpoint = ModelCheckpoint(best_model_name, save_best_only=True)\n",
    "train_steps_per_epoch = len(train_triples) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(val_triples) // BATCH_SIZE\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps_per_epoch, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              validation_data=val_gen, validation_steps=val_steps_per_epoch,\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "# In [14]:\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# In [15]:\n",
    "final_model_name = get_model_file(DATA_DIR, \"inceptionv3\", \"cat\", \"final\")\n",
    "model.save(final_model_name)\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "final_accuracy = evaluate_model(final_model_name, test_gen)\n",
    "\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "best_accuracy = evaluate_model(best_model_name, test_gen)\n",
    "\n",
    "scores[0, 0] = best_accuracy if best_accuracy > final_accuracy else final_accuracy\n",
    "\n",
    "# Input: Elementwise Cosine Distance\n",
    "# In [16]:\n",
    "train_gen = data_generator(train_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "val_gen = data_generator(val_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,) (10,)\n",
      "(10,)\n",
      "Epoch 1/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.6050 - acc: 0.7131 - val_loss: 0.2486 - val_acc: 0.9375\n",
      "Epoch 2/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.2038 - acc: 0.9314 - val_loss: 0.1383 - val_acc: 0.9469\n",
      "Epoch 3/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0948 - acc: 0.9661 - val_loss: 0.0331 - val_acc: 0.9875\n",
      "Epoch 4/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0523 - acc: 0.9805 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 5/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0640 - acc: 0.9796 - val_loss: 0.0265 - val_acc: 0.9875\n",
      "Epoch 6/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0413 - acc: 0.9883 - val_loss: 0.0596 - val_acc: 0.9844\n",
      "Epoch 7/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0233 - acc: 0.9939 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 8/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0199 - acc: 0.9957 - val_loss: 0.0072 - val_acc: 0.9969\n",
      "Epoch 9/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0345 - acc: 0.9844 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 10/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0206 - acc: 0.9918 - val_loss: 0.0242 - val_acc: 0.9875\n",
      "Epoch 11/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0267 - acc: 0.9900 - val_loss: 0.0223 - val_acc: 0.9875\n",
      "Epoch 12/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0145 - acc: 0.9952 - val_loss: 4.3250e-04 - val_acc: 1.0000\n",
      "Epoch 13/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0312 - acc: 0.9922 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 14/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0228 - acc: 0.9922 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 15/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0166 - acc: 0.9931 - val_loss: 0.0106 - val_acc: 0.9969\n",
      "Epoch 16/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0160 - acc: 0.9944 - val_loss: 0.0079 - val_acc: 0.9969\n",
      "Epoch 17/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0134 - acc: 0.9961 - val_loss: 4.3480e-04 - val_acc: 1.0000\n",
      "Epoch 18/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0042 - acc: 0.9996 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 19/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0146 - val_acc: 0.9906\n",
      "Epoch 20/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0137 - acc: 0.9939 - val_loss: 0.0042 - val_acc: 0.9969\n",
      "Epoch 21/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0123 - acc: 0.9948 - val_loss: 0.0546 - val_acc: 0.9812\n",
      "Epoch 22/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0151 - acc: 0.9957 - val_loss: 2.7477e-04 - val_acc: 1.0000\n",
      "Epoch 23/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9938\n",
      "Epoch 24/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 25/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0157 - acc: 0.9952 - val_loss: 0.0094 - val_acc: 0.9938\n",
      "Epoch 26/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0079 - acc: 0.9970 - val_loss: 1.4920e-04 - val_acc: 1.0000\n",
      "Epoch 27/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0248 - acc: 0.9913 - val_loss: 0.0288 - val_acc: 0.9875\n",
      "Epoch 28/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0361 - acc: 0.9913 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 29/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0078 - acc: 0.9965 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 30/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0133 - acc: 0.9957 - val_loss: 0.1097 - val_acc: 0.9750\n",
      "Epoch 31/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0164 - acc: 0.9957 - val_loss: 0.0056 - val_acc: 0.9969\n",
      "Epoch 32/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0092 - acc: 0.9978 - val_loss: 0.0156 - val_acc: 0.9969\n",
      "Epoch 33/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0159 - acc: 0.9961 - val_loss: 0.0141 - val_acc: 0.9938\n",
      "Epoch 34/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0083 - acc: 0.9965 - val_loss: 0.0103 - val_acc: 0.9969\n",
      "Epoch 35/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0270 - acc: 0.9931 - val_loss: 0.0099 - val_acc: 0.9969\n",
      "Epoch 36/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 37/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 7.0805e-04 - val_acc: 1.0000\n",
      "Epoch 38/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 1.7383e-04 - val_acc: 1.0000\n",
      "Epoch 39/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 7.0964e-04 - acc: 1.0000 - val_loss: 2.1085e-04 - val_acc: 1.0000\n",
      "Epoch 40/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0078 - acc: 0.9974 - val_loss: 3.3284e-04 - val_acc: 1.0000\n",
      "Epoch 41/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.2105e-04 - val_acc: 1.0000\n",
      "Epoch 42/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.0395 - val_acc: 0.9906\n",
      "Epoch 43/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0034 - acc: 0.9983 - val_loss: 0.0045 - val_acc: 0.9969\n",
      "Epoch 44/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 7.1359e-04 - val_acc: 1.0000\n",
      "Epoch 45/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0152 - acc: 0.9978 - val_loss: 0.0302 - val_acc: 0.9906\n",
      "Epoch 46/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0176 - acc: 0.9952 - val_loss: 0.0611 - val_acc: 0.9875\n",
      "Epoch 47/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0163 - acc: 0.9948 - val_loss: 0.0086 - val_acc: 0.9969\n",
      "Epoch 48/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0098 - acc: 0.9987 - val_loss: 5.0001e-04 - val_acc: 1.0000\n",
      "Epoch 49/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0030 - acc: 0.9983 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 50/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.0286e-04 - acc: 1.0000 - val_loss: 2.3256e-04 - val_acc: 1.0000\n",
      "Epoch 51/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0128 - acc: 0.9944 - val_loss: 8.4182e-04 - val_acc: 1.0000\n",
      "Epoch 52/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0176 - acc: 0.9944 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 53/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0224 - acc: 0.9926 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 54/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0124 - acc: 0.9965 - val_loss: 0.0249 - val_acc: 0.9938\n",
      "Epoch 55/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 9.7084e-04 - val_acc: 1.0000\n",
      "Epoch 56/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 3.3163e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 57/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.7986e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 58/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0035 - acc: 0.9987 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 59/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0551 - val_acc: 0.9875\n",
      "Epoch 60/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0126 - acc: 0.9957 - val_loss: 3.9537e-04 - val_acc: 1.0000\n",
      "Epoch 61/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0153 - acc: 0.9948 - val_loss: 0.0148 - val_acc: 0.9969\n",
      "Epoch 62/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 63/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0132 - acc: 0.9957 - val_loss: 0.0215 - val_acc: 0.9938\n",
      "Epoch 64/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0292 - acc: 0.9926 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 65/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 66/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0034 - acc: 0.9987 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 67/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0128 - val_acc: 0.9969\n",
      "Epoch 68/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 2.9897e-04 - val_acc: 1.0000\n",
      "Epoch 69/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0070 - acc: 0.9987 - val_loss: 0.0074 - val_acc: 0.9938\n",
      "Epoch 70/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 9.5084e-04 - val_acc: 1.0000\n",
      "Epoch 71/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0042 - val_acc: 0.9969\n",
      "Epoch 72/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 0.0125 - val_acc: 0.9938\n",
      "Epoch 73/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 2.6756e-04 - acc: 1.0000 - val_loss: 5.9313e-04 - val_acc: 1.0000\n",
      "Epoch 74/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.6905e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 75/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0350 - val_acc: 0.9969\n",
      "Epoch 76/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0104 - acc: 0.9970 - val_loss: 0.0420 - val_acc: 0.9844\n",
      "Epoch 77/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0246 - acc: 0.9922 - val_loss: 0.0099 - val_acc: 0.9969\n",
      "Epoch 78/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 1.6822e-04 - val_acc: 1.0000\n",
      "Epoch 79/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0214 - acc: 0.9931 - val_loss: 0.0187 - val_acc: 0.9906\n",
      "Epoch 80/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0116 - val_acc: 0.9938\n",
      "Epoch 81/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0245 - acc: 0.9965 - val_loss: 5.1149e-04 - val_acc: 1.0000\n",
      "Epoch 82/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0059 - acc: 0.9978 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 83/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0133 - acc: 0.9978 - val_loss: 1.0615e-04 - val_acc: 1.0000\n",
      "Epoch 84/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0121 - acc: 0.9965 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 85/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 3.7332e-04 - val_acc: 1.0000\n",
      "Epoch 86/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0156 - acc: 0.9957 - val_loss: 1.7643e-04 - val_acc: 1.0000\n",
      "Epoch 87/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0111 - acc: 0.9957 - val_loss: 0.0105 - val_acc: 0.9969\n",
      "Epoch 88/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0027 - val_acc: 0.9969\n",
      "Epoch 89/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0075 - val_acc: 0.9938\n",
      "Epoch 90/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0067 - acc: 0.9974 - val_loss: 1.1396e-04 - val_acc: 1.0000\n",
      "Epoch 91/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 4.8419e-04 - acc: 1.0000 - val_loss: 2.7092e-05 - val_acc: 1.0000\n",
      "Epoch 92/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.9530e-04 - acc: 1.0000 - val_loss: 6.8360e-05 - val_acc: 1.0000\n",
      "Epoch 93/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 2.7775e-04 - acc: 1.0000 - val_loss: 4.1565e-04 - val_acc: 1.0000\n",
      "Epoch 94/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0202 - acc: 0.9952 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 95/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 3.4950e-04 - val_acc: 1.0000\n",
      "Epoch 96/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0052 - acc: 0.9978 - val_loss: 0.0099 - val_acc: 0.9969\n",
      "Epoch 97/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 1.2897e-04 - val_acc: 1.0000\n",
      "Epoch 98/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 7.6889e-04 - acc: 1.0000 - val_loss: 1.7416e-04 - val_acc: 1.0000\n",
      "Epoch 99/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 8.0437e-04 - val_acc: 1.0000\n",
      "Epoch 100/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.4350e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 101/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.0056e-04 - acc: 1.0000 - val_loss: 2.2206e-04 - val_acc: 1.0000\n",
      "Epoch 102/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0097 - acc: 0.9983 - val_loss: 3.8007e-04 - val_acc: 1.0000\n",
      "Epoch 103/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0161 - acc: 0.9944 - val_loss: 9.5129e-04 - val_acc: 1.0000\n",
      "Epoch 104/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0124 - val_acc: 0.9906\n",
      "Epoch 105/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0082 - acc: 0.9970 - val_loss: 0.0086 - val_acc: 0.9969\n",
      "Epoch 106/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 7.2617e-04 - val_acc: 1.0000\n",
      "Epoch 107/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 108/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0093 - acc: 0.9957 - val_loss: 2.9412e-04 - val_acc: 1.0000\n",
      "Epoch 109/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0101 - acc: 0.9978 - val_loss: 3.6772e-04 - val_acc: 1.0000\n",
      "Epoch 110/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9987 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 111/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 112/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0107 - acc: 0.9965 - val_loss: 8.2746e-04 - val_acc: 1.0000\n",
      "Epoch 113/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0051 - val_acc: 0.9969\n",
      "Epoch 114/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.0508e-04 - acc: 1.0000 - val_loss: 7.4112e-05 - val_acc: 1.0000\n",
      "Epoch 115/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.7353e-04 - acc: 1.0000 - val_loss: 6.3097e-05 - val_acc: 1.0000\n",
      "Epoch 116/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.7150e-04 - acc: 0.9996 - val_loss: 0.0050 - val_acc: 0.9969\n",
      "Epoch 117/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 4.1703e-04 - val_acc: 1.0000\n",
      "Epoch 118/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0060 - acc: 0.9978 - val_loss: 6.3070e-07 - val_acc: 1.0000\n",
      "Epoch 119/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0347 - acc: 0.9922 - val_loss: 0.0059 - val_acc: 0.9969\n",
      "Epoch 120/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0123 - acc: 0.9974 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 122/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0086 - acc: 0.9970 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 123/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 2.0269e-04 - val_acc: 1.0000\n",
      "Epoch 124/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0067 - acc: 0.9987 - val_loss: 7.3742e-04 - val_acc: 1.0000\n",
      "Epoch 125/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0092 - val_acc: 0.9938\n",
      "Epoch 126/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.9459e-04 - val_acc: 1.0000\n",
      "Epoch 127/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 4.7470e-05 - acc: 1.0000 - val_loss: 8.1202e-04 - val_acc: 1.0000\n",
      "Epoch 128/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.1909e-05 - acc: 1.0000 - val_loss: 4.5901e-04 - val_acc: 1.0000\n",
      "Epoch 129/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.0361 - val_acc: 0.9906\n",
      "Epoch 130/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0102 - acc: 0.9970 - val_loss: 9.5787e-04 - val_acc: 1.0000\n",
      "Epoch 131/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0113 - acc: 0.9970 - val_loss: 0.0109 - val_acc: 0.9969\n",
      "Epoch 132/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0099 - val_acc: 0.9969\n",
      "Epoch 133/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 134/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 135/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 6.1180e-04 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9969\n",
      "Epoch 136/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 0.1618 - val_acc: 0.9688\n",
      "Epoch 137/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0078 - acc: 0.9978 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 138/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0074 - acc: 0.9983 - val_loss: 0.0035 - val_acc: 0.9969\n",
      "Epoch 139/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0051 - acc: 0.9978 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 140/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0165 - acc: 0.9965 - val_loss: 5.0607e-04 - val_acc: 1.0000\n",
      "Epoch 141/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0266 - val_acc: 0.9906\n",
      "Epoch 142/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0076 - acc: 0.9970 - val_loss: 5.9494e-04 - val_acc: 1.0000\n",
      "Epoch 143/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 144/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 145/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0248 - val_acc: 0.9938\n",
      "Epoch 146/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 147/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 148/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 3.1257e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 149/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0109 - acc: 0.9983 - val_loss: 9.5971e-04 - val_acc: 1.0000\n",
      "Epoch 150/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 1.4142e-04 - val_acc: 1.0000\n",
      "Epoch 151/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 6.0291e-04 - acc: 0.9996 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 152/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 8.5926e-04 - acc: 1.0000 - val_loss: 1.7770e-05 - val_acc: 1.0000\n",
      "Epoch 153/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0138 - val_acc: 0.9906\n",
      "Epoch 154/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0096 - acc: 0.9983 - val_loss: 2.1757e-05 - val_acc: 1.0000\n",
      "Epoch 155/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 2.8194e-04 - acc: 1.0000 - val_loss: 3.1089e-06 - val_acc: 1.0000\n",
      "Epoch 156/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0051 - acc: 0.9974 - val_loss: 0.0267 - val_acc: 0.9969\n",
      "Epoch 157/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0116 - acc: 0.9974 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 158/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0029 - acc: 0.9987 - val_loss: 4.3704e-05 - val_acc: 1.0000\n",
      "Epoch 159/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0269 - acc: 0.9944 - val_loss: 0.0354 - val_acc: 0.9906\n",
      "Epoch 160/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0141 - acc: 0.9948 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 161/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0112 - acc: 0.9952 - val_loss: 0.0050 - val_acc: 0.9969\n",
      "Epoch 162/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0079 - val_acc: 0.9969\n",
      "Epoch 163/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.6501e-04 - acc: 0.9996 - val_loss: 0.0084 - val_acc: 0.9969\n",
      "Epoch 164/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0264 - val_acc: 0.9969\n",
      "Epoch 165/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0051 - acc: 0.9978 - val_loss: 8.1359e-04 - val_acc: 1.0000\n",
      "Epoch 166/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0066 - val_acc: 0.9969\n",
      "Epoch 167/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9938\n",
      "Epoch 168/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 169/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 3.9569e-04 - acc: 1.0000 - val_loss: 8.6404e-04 - val_acc: 1.0000\n",
      "Epoch 170/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.1404e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 171/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.5691e-04 - acc: 1.0000 - val_loss: 3.1601e-04 - val_acc: 1.0000\n",
      "Epoch 172/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.1354e-04 - acc: 1.0000 - val_loss: 2.1629e-04 - val_acc: 1.0000\n",
      "Epoch 173/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 174/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 8.0506e-04 - val_acc: 1.0000\n",
      "Epoch 175/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.3602e-05 - acc: 1.0000 - val_loss: 1.1860e-04 - val_acc: 1.0000\n",
      "Epoch 176/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.0616e-04 - acc: 0.9996 - val_loss: 3.3527e-05 - val_acc: 1.0000\n",
      "Epoch 177/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0554 - val_acc: 0.9938\n",
      "Epoch 178/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0227 - acc: 0.9948 - val_loss: 0.0273 - val_acc: 0.9906\n",
      "Epoch 179/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0121 - acc: 0.9965 - val_loss: 0.0275 - val_acc: 0.9938\n",
      "Epoch 180/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0038 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0174 - val_acc: 0.9906\n",
      "Epoch 182/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 183/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0036 - acc: 0.9974 - val_loss: 1.9127e-05 - val_acc: 1.0000\n",
      "Epoch 184/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 5.3601e-05 - val_acc: 1.0000\n",
      "Epoch 185/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0119 - acc: 0.9974 - val_loss: 0.0075 - val_acc: 0.9969\n",
      "Epoch 186/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 187/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 188/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.5814e-04 - acc: 0.9996 - val_loss: 0.1284 - val_acc: 0.9844\n",
      "Epoch 189/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0074 - acc: 0.9983 - val_loss: 0.0035 - val_acc: 0.9969\n",
      "Epoch 190/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0029 - val_acc: 0.9969\n",
      "Epoch 191/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.0938e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 192/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.6997e-04 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9906\n",
      "Epoch 193/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.4971e-04 - acc: 1.0000 - val_loss: 4.1294e-04 - val_acc: 1.0000\n",
      "Epoch 194/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0099 - acc: 0.9974 - val_loss: 0.0462 - val_acc: 0.9938\n",
      "Epoch 195/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 3.3366e-04 - val_acc: 1.0000\n",
      "Epoch 196/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 3.0346e-04 - val_acc: 1.0000\n",
      "Epoch 197/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0012 - acc: 0.9991 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 198/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 1.5125e-04 - val_acc: 1.0000\n",
      "Epoch 199/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 200/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 8.0773e-04 - acc: 0.9996 - val_loss: 1.4919e-04 - val_acc: 1.0000\n",
      "Epoch 201/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 0.0039 - val_acc: 0.9969\n",
      "Epoch 202/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0080 - acc: 0.9978 - val_loss: 3.1480e-04 - val_acc: 1.0000\n",
      "Epoch 203/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0088 - acc: 0.9965 - val_loss: 5.5574e-04 - val_acc: 1.0000\n",
      "Epoch 204/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0026 - acc: 0.9987 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 205/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0123 - acc: 0.9961 - val_loss: 1.1118e-04 - val_acc: 1.0000\n",
      "Epoch 206/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0036 - acc: 0.9983 - val_loss: 2.6553e-04 - val_acc: 1.0000\n",
      "Epoch 207/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 3.2874e-04 - val_acc: 1.0000\n",
      "Epoch 208/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 5.7497e-04 - acc: 1.0000 - val_loss: 6.2687e-04 - val_acc: 1.0000\n",
      "Epoch 209/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0019 - acc: 0.9987 - val_loss: 1.5256e-04 - val_acc: 1.0000\n",
      "Epoch 210/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0036 - acc: 0.9983 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 211/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.3231e-04 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9969\n",
      "Epoch 212/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 4.5494e-04 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 0.9969\n",
      "Epoch 213/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 7.0364e-05 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9969\n",
      "Epoch 214/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0120 - val_acc: 0.9938\n",
      "Epoch 215/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0072 - acc: 0.9991 - val_loss: 4.1220e-05 - val_acc: 1.0000\n",
      "Epoch 216/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 2.9117e-04 - val_acc: 1.0000\n",
      "Epoch 217/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 5.0177e-04 - val_acc: 1.0000\n",
      "Epoch 218/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0096 - acc: 0.9965 - val_loss: 1.5290e-04 - val_acc: 1.0000\n",
      "Epoch 219/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0138 - acc: 0.9961 - val_loss: 0.0433 - val_acc: 0.9875\n",
      "Epoch 220/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 0.0089 - val_acc: 0.9969\n",
      "Epoch 221/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0102 - val_acc: 0.9938\n",
      "Epoch 222/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 223/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 2.5252e-04 - val_acc: 1.0000\n",
      "Epoch 224/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0068 - acc: 0.9970 - val_loss: 4.4693e-04 - val_acc: 1.0000\n",
      "Epoch 225/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0046 - val_acc: 0.9969\n",
      "Epoch 226/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0046 - acc: 0.9978 - val_loss: 5.0742e-04 - val_acc: 1.0000\n",
      "Epoch 227/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0053 - acc: 0.9978 - val_loss: 3.4363e-04 - val_acc: 1.0000\n",
      "Epoch 228/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0084 - acc: 0.9987 - val_loss: 0.0139 - val_acc: 0.9969\n",
      "Epoch 229/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 9.0368e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 230/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 231/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0171 - val_acc: 0.9969\n",
      "Epoch 232/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 233/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0070 - val_acc: 0.9938\n",
      "Epoch 234/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.6480e-04 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 235/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0035 - val_acc: 0.9969\n",
      "Epoch 236/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.0942e-04 - acc: 1.0000 - val_loss: 6.4521e-04 - val_acc: 1.0000\n",
      "Epoch 237/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0549 - val_acc: 0.9938\n",
      "Epoch 238/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 239/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0430 - val_acc: 0.9875\n",
      "Epoch 240/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9987 - val_loss: 2.8152e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 6.3162e-04 - val_acc: 1.0000\n",
      "Epoch 242/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0071 - acc: 0.9991 - val_loss: 8.1652e-04 - val_acc: 1.0000\n",
      "Epoch 243/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0045 - acc: 0.9978 - val_loss: 0.0163 - val_acc: 0.9938\n",
      "Epoch 244/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0040 - acc: 0.9991 - val_loss: 2.6064e-05 - val_acc: 1.0000\n",
      "Epoch 245/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0092 - acc: 0.9965 - val_loss: 0.0073 - val_acc: 0.9969\n",
      "Epoch 246/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0063 - acc: 0.9978 - val_loss: 4.3367e-04 - val_acc: 1.0000\n",
      "Epoch 247/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0158 - val_acc: 0.9938\n",
      "Epoch 248/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0087 - acc: 0.9983 - val_loss: 1.2231e-04 - val_acc: 1.0000\n",
      "Epoch 249/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0077 - acc: 0.9978 - val_loss: 4.6402e-04 - val_acc: 1.0000\n",
      "Epoch 250/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4984e-04 - acc: 1.0000 - val_loss: 2.8448e-04 - val_acc: 1.0000\n",
      "Epoch 251/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 1.3323e-04 - val_acc: 1.0000\n",
      "Epoch 252/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9987 - val_loss: 0.0136 - val_acc: 0.9969\n",
      "Epoch 253/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 7.9603e-04 - acc: 0.9996 - val_loss: 7.1387e-04 - val_acc: 1.0000\n",
      "Epoch 254/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 6.6118e-04 - acc: 0.9996 - val_loss: 1.6681e-04 - val_acc: 1.0000\n",
      "Epoch 255/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 2.4696e-04 - val_acc: 1.0000\n",
      "Epoch 256/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9987 - val_loss: 6.7074e-04 - val_acc: 1.0000\n",
      "Epoch 257/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0050 - acc: 0.9978 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 258/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0094 - val_acc: 0.9969\n",
      "Epoch 259/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 3.5786e-04 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9969\n",
      "Epoch 260/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.0136 - val_acc: 0.9969\n",
      "Epoch 261/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 3.1155e-04 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9969\n",
      "Epoch 262/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0012 - acc: 0.9991 - val_loss: 1.1498e-05 - val_acc: 1.0000\n",
      "Epoch 263/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.7222e-05 - acc: 1.0000 - val_loss: 3.0514e-05 - val_acc: 1.0000\n",
      "Epoch 264/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0058 - acc: 0.9987 - val_loss: 1.3370e-04 - val_acc: 1.0000\n",
      "Epoch 265/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0070 - val_acc: 0.9938\n",
      "Epoch 266/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0745 - val_acc: 0.9906\n",
      "Epoch 267/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.4910e-04 - acc: 1.0000 - val_loss: 8.0467e-04 - val_acc: 1.0000\n",
      "Epoch 268/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.2093e-04 - acc: 1.0000 - val_loss: 9.7127e-04 - val_acc: 1.0000\n",
      "Epoch 269/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 5.1105e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 270/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0390 - val_acc: 0.9875\n",
      "Epoch 271/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0058 - val_acc: 0.9969\n",
      "Epoch 272/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 1.1974e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 273/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0022 - acc: 0.9987 - val_loss: 0.0060 - val_acc: 0.9938\n",
      "Epoch 274/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0029 - acc: 0.9987 - val_loss: 1.4185e-05 - val_acc: 1.0000\n",
      "Epoch 275/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 1.4956e-04 - val_acc: 1.0000\n",
      "Epoch 276/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 2.8706e-05 - val_acc: 1.0000\n",
      "Epoch 277/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0050 - acc: 0.9991 - val_loss: 1.7311e-05 - val_acc: 1.0000\n",
      "Epoch 278/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 9.3833e-04 - val_acc: 1.0000\n",
      "Epoch 279/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0097 - val_acc: 0.9969\n",
      "Epoch 280/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0099 - acc: 0.9978 - val_loss: 1.7834e-04 - val_acc: 1.0000\n",
      "Epoch 281/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0184 - acc: 0.9961 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 282/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0105 - acc: 0.9978 - val_loss: 9.1179e-04 - val_acc: 1.0000\n",
      "Epoch 283/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0028 - acc: 0.9987 - val_loss: 8.5913e-04 - val_acc: 1.0000\n",
      "Epoch 284/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.0925e-04 - acc: 0.9996 - val_loss: 1.1608e-04 - val_acc: 1.0000\n",
      "Epoch 285/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0749 - val_acc: 0.9938\n",
      "Epoch 286/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 9.6680e-04 - acc: 0.9996 - val_loss: 3.1295e-04 - val_acc: 1.0000\n",
      "Epoch 287/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0069 - acc: 0.9983 - val_loss: 0.0221 - val_acc: 0.9906\n",
      "Epoch 288/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0119 - val_acc: 0.9969\n",
      "Epoch 289/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0108 - acc: 0.9978 - val_loss: 7.4686e-04 - val_acc: 1.0000\n",
      "Epoch 290/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0012 - acc: 0.9991 - val_loss: 1.5535e-04 - val_acc: 1.0000\n",
      "Epoch 291/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 9.2531e-04 - val_acc: 1.0000\n",
      "Epoch 292/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 7.9372e-04 - val_acc: 1.0000\n",
      "Epoch 293/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0068 - acc: 0.9978 - val_loss: 1.7330e-05 - val_acc: 1.0000\n",
      "Epoch 294/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0088 - acc: 0.9974 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 295/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0085 - acc: 0.9983 - val_loss: 0.0047 - val_acc: 0.9969\n",
      "Epoch 296/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0036 - acc: 0.9996 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 297/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.9707e-04 - acc: 1.0000 - val_loss: 1.2284e-04 - val_acc: 1.0000\n",
      "Epoch 298/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0124 - val_acc: 0.9938\n",
      "Epoch 299/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0043 - val_acc: 0.9969\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0051 - acc: 0.9991 - val_loss: 6.2607e-04 - val_acc: 1.0000\n",
      "Epoch 301/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 4.3845e-04 - val_acc: 1.0000\n",
      "Epoch 302/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 3.1684e-04 - val_acc: 1.0000\n",
      "Epoch 303/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0051 - acc: 0.9978 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 304/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 7.6807e-04 - val_acc: 1.0000\n",
      "Epoch 305/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0041 - acc: 0.9996 - val_loss: 0.0041 - val_acc: 0.9969\n",
      "Epoch 306/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 2.1041e-04 - val_acc: 1.0000\n",
      "Epoch 307/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.3573e-04 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9969\n",
      "Epoch 308/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0082 - val_acc: 0.9969\n",
      "Epoch 309/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 7.2449e-04 - acc: 0.9996 - val_loss: 0.0282 - val_acc: 0.9938\n",
      "Epoch 310/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0070 - val_acc: 0.9969\n",
      "Epoch 311/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0076 - acc: 0.9996 - val_loss: 7.2104e-05 - val_acc: 1.0000\n",
      "Epoch 312/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.6382e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 313/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 2.1792e-04 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9969\n",
      "Epoch 314/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 6.1839e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 315/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0200 - acc: 0.9974 - val_loss: 1.1152e-04 - val_acc: 1.0000\n",
      "Epoch 316/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0193 - acc: 0.9974 - val_loss: 0.0068 - val_acc: 0.9938\n",
      "Epoch 317/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0082 - acc: 0.9983 - val_loss: 0.0112 - val_acc: 0.9969\n",
      "Epoch 318/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0131 - acc: 0.9978 - val_loss: 0.0080 - val_acc: 0.9969\n",
      "Epoch 319/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0027 - val_acc: 0.9969\n",
      "Epoch 320/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0036 - acc: 0.9983 - val_loss: 0.0147 - val_acc: 0.9938\n",
      "Epoch 321/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0072 - val_acc: 0.9969\n",
      "Epoch 322/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0092 - val_acc: 0.9938\n",
      "Epoch 323/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 3.6849e-04 - acc: 1.0000 - val_loss: 2.1401e-04 - val_acc: 1.0000\n",
      "Epoch 324/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0561 - val_acc: 0.9938\n",
      "Epoch 325/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 8.2248e-05 - val_acc: 1.0000\n",
      "Epoch 326/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.3958e-04 - acc: 1.0000 - val_loss: 9.9386e-04 - val_acc: 1.0000\n",
      "Epoch 327/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0064 - acc: 0.9987 - val_loss: 0.1099 - val_acc: 0.9844\n",
      "Epoch 328/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 9.4874e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 329/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0134 - val_acc: 0.9938\n",
      "Epoch 330/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.0135 - val_acc: 0.9969\n",
      "Epoch 331/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.7091e-04 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9969\n",
      "Epoch 332/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0049 - acc: 0.9996 - val_loss: 0.0191 - val_acc: 0.9938\n",
      "Epoch 333/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 1.5741e-04 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9969\n",
      "Epoch 334/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 6.6287e-04 - val_acc: 1.0000\n",
      "Epoch 335/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 2.0242e-04 - val_acc: 1.0000\n",
      "Epoch 336/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.3838e-04 - acc: 1.0000 - val_loss: 9.3744e-06 - val_acc: 1.0000\n",
      "Epoch 337/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 338/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.3508e-05 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 339/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0144 - acc: 0.9974 - val_loss: 0.0046 - val_acc: 0.9969\n",
      "Epoch 340/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0097 - acc: 0.9974 - val_loss: 8.7860e-05 - val_acc: 1.0000\n",
      "Epoch 341/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0038 - acc: 0.9983 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 342/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 343/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0088 - acc: 0.9983 - val_loss: 3.1271e-05 - val_acc: 1.0000\n",
      "Epoch 344/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 6.7281e-05 - val_acc: 1.0000\n",
      "Epoch 345/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9996 - val_loss: 4.7586e-04 - val_acc: 1.0000\n",
      "Epoch 346/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 347/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0277 - val_acc: 0.9938\n",
      "Epoch 348/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 7.1960e-04 - acc: 1.0000 - val_loss: 1.1961e-04 - val_acc: 1.0000\n",
      "Epoch 349/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 2.9823e-04 - val_acc: 1.0000\n",
      "Epoch 350/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 351/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 2.3237e-04 - val_acc: 1.0000\n",
      "Epoch 352/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0048 - acc: 0.9987 - val_loss: 2.9524e-06 - val_acc: 1.0000\n",
      "Epoch 353/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 4.5909e-04 - val_acc: 1.0000\n",
      "Epoch 354/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9987 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 355/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.9987 - val_loss: 0.0896 - val_acc: 0.9844\n",
      "Epoch 356/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 3.1426e-05 - val_acc: 1.0000\n",
      "Epoch 357/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 1.2357e-04 - val_acc: 1.0000\n",
      "Epoch 358/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0306 - val_acc: 0.9844\n",
      "Epoch 359/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0015 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 4.7959e-04 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9906\n",
      "Epoch 361/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 3.3026e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 362/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0048 - acc: 0.9987 - val_loss: 1.1317e-04 - val_acc: 1.0000\n",
      "Epoch 363/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.1503 - val_acc: 0.9688\n",
      "Epoch 364/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0116 - acc: 0.9978 - val_loss: 0.0226 - val_acc: 0.9938\n",
      "Epoch 365/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0091 - acc: 0.9978 - val_loss: 0.0053 - val_acc: 0.9938\n",
      "Epoch 366/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 5.6431e-04 - val_acc: 1.0000\n",
      "Epoch 367/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 368/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.1646e-04 - acc: 1.0000 - val_loss: 5.9207e-04 - val_acc: 1.0000\n",
      "Epoch 369/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.7263e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 370/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.4869e-04 - acc: 0.9996 - val_loss: 0.0064 - val_acc: 0.9969\n",
      "Epoch 371/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.6248e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 372/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.0625e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 373/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0029 - acc: 0.9996 - val_loss: 0.0052 - val_acc: 0.9969\n",
      "Epoch 374/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0035 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9969\n",
      "Epoch 375/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 1.3221e-04 - val_acc: 1.0000\n",
      "Epoch 376/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 377/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 1.9860e-04 - val_acc: 1.0000\n",
      "Epoch 378/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0077 - acc: 0.9983 - val_loss: 1.7331e-04 - val_acc: 1.0000\n",
      "Epoch 379/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 8.5212e-04 - acc: 0.9996 - val_loss: 6.4309e-04 - val_acc: 1.0000\n",
      "Epoch 380/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 381/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0049 - acc: 0.9996 - val_loss: 0.0070 - val_acc: 0.9938\n",
      "Epoch 382/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0083 - acc: 0.9983 - val_loss: 0.0264 - val_acc: 0.9938\n",
      "Epoch 383/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 3.4163e-04 - acc: 1.0000 - val_loss: 2.8702e-04 - val_acc: 1.0000\n",
      "Epoch 384/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 4.4166e-04 - acc: 1.0000 - val_loss: 2.6000e-04 - val_acc: 1.0000\n",
      "Epoch 385/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.7651e-04 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9969\n",
      "Epoch 386/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0101 - val_acc: 0.9969\n",
      "Epoch 387/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0604 - val_acc: 0.9875\n",
      "Epoch 388/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0529 - val_acc: 0.9906\n",
      "Epoch 389/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0125 - acc: 0.9983 - val_loss: 0.0093 - val_acc: 0.9938\n",
      "Epoch 390/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0047 - val_acc: 0.9969\n",
      "Epoch 391/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 4.9612e-04 - acc: 0.9996 - val_loss: 8.8095e-04 - val_acc: 1.0000\n",
      "Epoch 392/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0069 - acc: 0.9987 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 393/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0068 - acc: 0.9987 - val_loss: 0.0250 - val_acc: 0.9938\n",
      "Epoch 394/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 3.5745e-04 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9969\n",
      "Epoch 395/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 1.4184e-04 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 0.9938\n",
      "Epoch 396/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 9.0083e-05 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9969\n",
      "Epoch 397/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 6.0558e-05 - acc: 1.0000 - val_loss: 2.9380e-04 - val_acc: 1.0000\n",
      "Epoch 398/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0044 - acc: 0.9996 - val_loss: 0.0285 - val_acc: 0.9938\n",
      "Epoch 399/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.6696e-04 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9969\n",
      "Epoch 400/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 7.0002e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9969\n",
      "Epoch 401/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 402/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 6.7417e-05 - acc: 1.0000 - val_loss: 2.9016e-05 - val_acc: 1.0000\n",
      "Epoch 403/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.4848e-05 - acc: 1.0000 - val_loss: 1.1000e-05 - val_acc: 1.0000\n",
      "Epoch 404/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0030 - acc: 0.9987 - val_loss: 8.7099e-07 - val_acc: 1.0000\n",
      "Epoch 405/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0070 - acc: 0.9974 - val_loss: 6.3272e-05 - val_acc: 1.0000\n",
      "Epoch 406/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 407/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 9.3515e-05 - val_acc: 1.0000\n",
      "Epoch 408/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 4.8203e-04 - acc: 1.0000 - val_loss: 6.2406e-05 - val_acc: 1.0000\n",
      "Epoch 409/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 2.3908e-04 - val_acc: 1.0000\n",
      "Epoch 410/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.2899e-04 - acc: 1.0000 - val_loss: 1.3712e-05 - val_acc: 1.0000\n",
      "Epoch 411/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 3.7683e-04 - val_acc: 1.0000\n",
      "Epoch 412/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0034 - acc: 0.9983 - val_loss: 0.0026 - val_acc: 0.9969\n",
      "Epoch 413/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0033 - acc: 0.9987 - val_loss: 0.0162 - val_acc: 0.9938\n",
      "Epoch 414/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3664e-04 - acc: 1.0000 - val_loss: 3.4367e-04 - val_acc: 1.0000\n",
      "Epoch 415/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0181 - val_acc: 0.9938\n",
      "Epoch 416/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 9.9369e-04 - val_acc: 1.0000\n",
      "Epoch 417/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 418/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 419/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0484 - val_acc: 0.9906\n",
      "Epoch 420/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0160 - val_acc: 0.9969\n",
      "Epoch 421/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0059 - acc: 0.9987 - val_loss: 0.0108 - val_acc: 0.9938\n",
      "Epoch 422/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0056 - acc: 0.9996 - val_loss: 0.0049 - val_acc: 0.9969\n",
      "Epoch 423/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 7.4873e-04 - val_acc: 1.0000\n",
      "Epoch 424/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0845 - val_acc: 0.9875\n",
      "Epoch 425/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.1476e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9969\n",
      "Epoch 426/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 2.0528e-05 - val_acc: 1.0000\n",
      "Epoch 427/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0056 - val_acc: 0.9969\n",
      "Epoch 428/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9996 - val_loss: 0.0043 - val_acc: 0.9969\n",
      "Epoch 429/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0042 - acc: 0.9996 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 430/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 3.3606e-04 - acc: 1.0000 - val_loss: 8.7275e-04 - val_acc: 1.0000\n",
      "Epoch 431/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 5.6413e-04 - val_acc: 1.0000\n",
      "Epoch 432/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3051e-04 - acc: 1.0000 - val_loss: 2.4343e-04 - val_acc: 1.0000\n",
      "Epoch 433/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5909e-04 - acc: 1.0000 - val_loss: 6.4780e-05 - val_acc: 1.0000\n",
      "Epoch 434/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 3.2349e-04 - val_acc: 1.0000\n",
      "Epoch 435/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0049 - acc: 0.9991 - val_loss: 0.0973 - val_acc: 0.9906\n",
      "Epoch 436/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 1.0574e-05 - val_acc: 1.0000\n",
      "Epoch 437/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0084 - acc: 0.9978 - val_loss: 1.3070e-04 - val_acc: 1.0000\n",
      "Epoch 438/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0078 - acc: 0.9978 - val_loss: 4.4792e-04 - val_acc: 1.0000\n",
      "Epoch 439/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 8.5102e-05 - val_acc: 1.0000\n",
      "Epoch 440/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0070 - acc: 0.9991 - val_loss: 7.0276e-04 - val_acc: 1.0000\n",
      "Epoch 441/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.9837e-04 - acc: 1.0000 - val_loss: 1.1521e-04 - val_acc: 1.0000\n",
      "Epoch 442/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 4.6957e-04 - val_acc: 1.0000\n",
      "Epoch 443/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 2.8548e-04 - acc: 1.0000 - val_loss: 4.9176e-04 - val_acc: 1.0000\n",
      "Epoch 444/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 6.5050e-04 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9938\n",
      "Epoch 445/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.0208 - val_acc: 0.9969\n",
      "Epoch 446/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0050 - val_acc: 0.9969\n",
      "Epoch 447/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0076 - acc: 0.9978 - val_loss: 3.6454e-05 - val_acc: 1.0000\n",
      "Epoch 448/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 449/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0066 - acc: 0.9987 - val_loss: 0.0217 - val_acc: 0.9938\n",
      "Epoch 450/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0122 - val_acc: 0.9938\n",
      "Epoch 451/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 4.5663e-04 - acc: 1.0000 - val_loss: 8.1235e-04 - val_acc: 1.0000\n",
      "Epoch 452/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.2266e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 453/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 1.2162e-04 - val_acc: 1.0000\n",
      "Epoch 454/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.9709e-04 - acc: 1.0000 - val_loss: 9.9404e-04 - val_acc: 1.0000\n",
      "Epoch 455/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 9.0241e-05 - acc: 1.0000 - val_loss: 3.0085e-04 - val_acc: 1.0000\n",
      "Epoch 456/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 4.2085e-05 - acc: 1.0000 - val_loss: 2.4970e-04 - val_acc: 1.0000\n",
      "Epoch 457/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 3.3087e-04 - acc: 1.0000 - val_loss: 7.5190e-05 - val_acc: 1.0000\n",
      "Epoch 458/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0042 - acc: 0.9991 - val_loss: 1.0126e-05 - val_acc: 1.0000\n",
      "Epoch 459/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.0246 - val_acc: 0.9906\n",
      "Epoch 460/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 2.9711e-05 - val_acc: 1.0000\n",
      "Epoch 461/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0045 - acc: 0.9991 - val_loss: 4.0072e-05 - val_acc: 1.0000\n",
      "Epoch 462/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0040 - acc: 0.9996 - val_loss: 1.5134e-04 - val_acc: 1.0000\n",
      "Epoch 463/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 1.0017e-04 - val_acc: 1.0000\n",
      "Epoch 464/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.1617e-04 - acc: 0.9996 - val_loss: 1.6807e-05 - val_acc: 1.0000\n",
      "Epoch 465/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0072 - acc: 0.9983 - val_loss: 0.0070 - val_acc: 0.9969\n",
      "Epoch 466/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.0371 - val_acc: 0.9906\n",
      "Epoch 467/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 3.7666e-05 - val_acc: 1.0000\n",
      "Epoch 468/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 1.2543e-05 - val_acc: 1.0000\n",
      "Epoch 469/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0052 - acc: 0.9991 - val_loss: 0.0156 - val_acc: 0.9969\n",
      "Epoch 470/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 8.2656e-04 - acc: 0.9996 - val_loss: 1.3510e-04 - val_acc: 1.0000\n",
      "Epoch 471/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 2.0055e-04 - val_acc: 1.0000\n",
      "Epoch 472/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.9852e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 473/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1.4066e-04 - acc: 1.0000 - val_loss: 2.1502e-04 - val_acc: 1.0000\n",
      "Epoch 474/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.5349e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9969\n",
      "Epoch 475/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.7053e-04 - acc: 0.9996 - val_loss: 0.0212 - val_acc: 0.9938\n",
      "Epoch 476/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5110e-04 - acc: 1.0000 - val_loss: 6.5679e-05 - val_acc: 1.0000\n",
      "Epoch 477/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.6162e-04 - acc: 1.0000 - val_loss: 4.0087e-06 - val_acc: 1.0000\n",
      "Epoch 478/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 479/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0045 - acc: 0.9991 - val_loss: 2.2411e-04 - val_acc: 1.0000\n",
      "Epoch 480/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 2.1135e-04 - val_acc: 1.0000\n",
      "Epoch 481/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 482/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0061 - acc: 0.9987 - val_loss: 0.0145 - val_acc: 0.9938\n",
      "Epoch 483/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.8652e-04 - acc: 1.0000 - val_loss: 1.3734e-04 - val_acc: 1.0000\n",
      "Epoch 484/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 1.4688e-04 - val_acc: 1.0000\n",
      "Epoch 485/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 7.4994e-04 - val_acc: 1.0000\n",
      "Epoch 486/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0029 - acc: 0.9987 - val_loss: 1.1207e-04 - val_acc: 1.0000\n",
      "Epoch 487/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 4.8417e-04 - val_acc: 1.0000\n",
      "Epoch 488/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0228 - acc: 0.9974 - val_loss: 0.0052 - val_acc: 0.9969\n",
      "Epoch 489/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 4.0778e-05 - val_acc: 1.0000\n",
      "Epoch 490/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 9.4552e-04 - acc: 0.9996 - val_loss: 0.0068 - val_acc: 0.9969\n",
      "Epoch 491/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 3.7680e-04 - val_acc: 1.0000\n",
      "Epoch 492/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0121 - acc: 0.9983 - val_loss: 0.1356 - val_acc: 0.9875\n",
      "Epoch 493/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0490 - val_acc: 0.9938\n",
      "Epoch 494/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.6305e-04 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 0.9969\n",
      "Epoch 495/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 6.6993e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 496/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 4.7112e-05 - acc: 1.0000 - val_loss: 4.0908e-06 - val_acc: 1.0000\n",
      "Epoch 497/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0052 - acc: 0.9991 - val_loss: 0.0074 - val_acc: 0.9969\n",
      "Epoch 498/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0067 - val_acc: 0.9969\n",
      "Epoch 499/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0094 - acc: 0.9974 - val_loss: 6.6320e-04 - val_acc: 1.0000\n",
      "Epoch 500/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0064 - acc: 0.9991 - val_loss: 0.0194 - val_acc: 0.9969\n",
      "Epoch 501/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 6.5300e-04 - acc: 0.9996 - val_loss: 0.0050 - val_acc: 0.9969\n",
      "Epoch 502/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 3.4983e-04 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9969\n",
      "Epoch 503/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 8.8077e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 504/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0034 - val_acc: 0.9969\n",
      "Epoch 505/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.3216 - val_acc: 0.9688\n",
      "Epoch 506/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0061 - acc: 0.9978 - val_loss: 0.0795 - val_acc: 0.9906\n",
      "Epoch 507/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0189 - acc: 0.9965 - val_loss: 4.3793e-04 - val_acc: 1.0000\n",
      "Epoch 508/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 509/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 2.7531e-04 - acc: 1.0000 - val_loss: 5.1451e-04 - val_acc: 1.0000\n",
      "Epoch 510/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 7.2579e-04 - acc: 0.9996 - val_loss: 0.0044 - val_acc: 0.9969\n",
      "Epoch 511/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0065 - val_acc: 0.9969\n",
      "Epoch 512/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.0760e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9969\n",
      "Epoch 513/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 9.4085e-04 - val_acc: 1.0000\n",
      "Epoch 514/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0034 - acc: 0.9996 - val_loss: 2.1145e-05 - val_acc: 1.0000\n",
      "Epoch 515/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0112 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 0.9969\n",
      "Epoch 516/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 8.5141e-05 - val_acc: 1.0000\n",
      "Epoch 517/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0315 - val_acc: 0.9938\n",
      "Epoch 518/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 1.5706e-04 - val_acc: 1.0000\n",
      "Epoch 519/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0154 - val_acc: 0.9969\n",
      "Epoch 520/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 3.3993e-04 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9938\n",
      "Epoch 521/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0066 - acc: 0.9991 - val_loss: 4.3390e-04 - val_acc: 1.0000\n",
      "Epoch 522/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0036 - val_acc: 0.9969\n",
      "Epoch 523/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0057 - acc: 0.9987 - val_loss: 9.2613e-04 - val_acc: 1.0000\n",
      "Epoch 524/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 2.4572e-05 - val_acc: 1.0000\n",
      "Epoch 525/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 5.6968e-05 - acc: 1.0000 - val_loss: 5.2621e-05 - val_acc: 1.0000\n",
      "Epoch 526/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0117 - acc: 0.9978 - val_loss: 0.1053 - val_acc: 0.9812\n",
      "Epoch 527/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 528/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0298 - val_acc: 0.9969\n",
      "Epoch 529/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0280 - val_acc: 0.9969\n",
      "Epoch 530/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 2.2280e-05 - val_acc: 1.0000\n",
      "Epoch 531/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 8.7911e-06 - val_acc: 1.0000\n",
      "Epoch 532/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0094 - acc: 0.9965 - val_loss: 7.6648e-05 - val_acc: 1.0000\n",
      "Epoch 533/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0171 - acc: 0.9965 - val_loss: 9.6786e-04 - val_acc: 1.0000\n",
      "Epoch 534/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 535/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 2.4714e-04 - val_acc: 1.0000\n",
      "Epoch 536/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.9324e-04 - acc: 1.0000 - val_loss: 3.1289e-04 - val_acc: 1.0000\n",
      "Epoch 537/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.2638e-04 - acc: 1.0000 - val_loss: 1.1905e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 538/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.1635e-04 - acc: 1.0000 - val_loss: 7.0009e-05 - val_acc: 1.0000\n",
      "Epoch 539/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0257 - val_acc: 0.9969\n",
      "Epoch 540/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0674 - val_acc: 0.9906\n",
      "Epoch 541/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0413 - val_acc: 0.9906\n",
      "Epoch 542/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 543/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 5.7394e-04 - acc: 0.9996 - val_loss: 0.0043 - val_acc: 0.9969\n",
      "Epoch 544/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0109 - val_acc: 0.9906\n",
      "Epoch 545/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0089 - val_acc: 0.9938\n",
      "Epoch 546/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.0457e-04 - acc: 1.0000 - val_loss: 6.8411e-04 - val_acc: 1.0000\n",
      "Epoch 547/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4773e-04 - acc: 1.0000 - val_loss: 5.5771e-04 - val_acc: 1.0000\n",
      "Epoch 548/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.1160e-05 - acc: 1.0000 - val_loss: 4.8197e-04 - val_acc: 1.0000\n",
      "Epoch 549/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 5.5957e-05 - val_acc: 1.0000\n",
      "Epoch 550/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.0086e-05 - acc: 1.0000 - val_loss: 1.3911e-05 - val_acc: 1.0000\n",
      "Epoch 551/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0090 - acc: 0.9991 - val_loss: 0.0080 - val_acc: 0.9969\n",
      "Epoch 552/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 553/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0238 - val_acc: 0.9906\n",
      "Epoch 554/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 0.0527 - val_acc: 0.9781\n",
      "Epoch 555/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 1.0400e-04 - val_acc: 1.0000\n",
      "Epoch 556/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.5020e-05 - acc: 1.0000 - val_loss: 6.9399e-05 - val_acc: 1.0000\n",
      "Epoch 557/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0063 - acc: 0.9987 - val_loss: 1.9048e-04 - val_acc: 1.0000\n",
      "Epoch 558/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 2.2759e-04 - acc: 1.0000 - val_loss: 1.1184e-04 - val_acc: 1.0000\n",
      "Epoch 559/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 3.5176e-04 - val_acc: 1.0000\n",
      "Epoch 560/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0166 - val_acc: 0.9938\n",
      "Epoch 561/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0054 - val_acc: 0.9969\n",
      "Epoch 562/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.5218e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 563/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 9.0578e-05 - acc: 1.0000 - val_loss: 7.2766e-04 - val_acc: 1.0000\n",
      "Epoch 564/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 6.6871e-05 - acc: 1.0000 - val_loss: 3.1463e-04 - val_acc: 1.0000\n",
      "Epoch 565/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 6.8702e-05 - acc: 1.0000 - val_loss: 2.9517e-04 - val_acc: 1.0000\n",
      "Epoch 566/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0046 - acc: 0.9983 - val_loss: 2.9436e-04 - val_acc: 1.0000\n",
      "Epoch 567/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 568/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 6.7994e-04 - acc: 0.9996 - val_loss: 1.6791e-04 - val_acc: 1.0000\n",
      "Epoch 569/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 8.8520e-04 - val_acc: 1.0000\n",
      "Epoch 570/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 7.8448e-04 - acc: 0.9996 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 571/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.2842e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 572/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 1.3339e-04 - val_acc: 1.0000\n",
      "Epoch 573/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.4020e-04 - acc: 1.0000 - val_loss: 2.8642e-05 - val_acc: 1.0000\n",
      "Epoch 574/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.1423e-04 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9938\n",
      "Epoch 575/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 9.7537e-06 - val_acc: 1.0000\n",
      "Epoch 576/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 8.6326e-04 - acc: 0.9996 - val_loss: 0.0325 - val_acc: 0.9938\n",
      "Epoch 577/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 1.9310e-04 - acc: 1.0000 - val_loss: 7.7932e-05 - val_acc: 1.0000\n",
      "Epoch 578/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 6.3035e-05 - acc: 1.0000 - val_loss: 4.6649e-05 - val_acc: 1.0000\n",
      "Epoch 579/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 8.2116e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 0.9969\n",
      "Epoch 580/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 8.2794e-05 - acc: 1.0000 - val_loss: 5.3424e-05 - val_acc: 1.0000\n",
      "Epoch 581/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 4.7794e-05 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 0.9938\n",
      "Epoch 582/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 5.2974e-05 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9969\n",
      "Epoch 583/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 3.2714e-05 - val_acc: 1.0000\n",
      "Epoch 584/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0062 - acc: 0.9991 - val_loss: 1.9616e-04 - val_acc: 1.0000\n",
      "Epoch 585/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0061 - acc: 0.9991 - val_loss: 5.6387e-04 - val_acc: 1.0000\n",
      "Epoch 586/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0194 - val_acc: 0.9938\n",
      "Epoch 587/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0144 - acc: 0.9965 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 588/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0090 - acc: 0.9978 - val_loss: 1.7423e-04 - val_acc: 1.0000\n",
      "Epoch 589/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 8.0832e-06 - val_acc: 1.0000\n",
      "Epoch 590/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0279 - acc: 0.9970 - val_loss: 2.7828e-05 - val_acc: 1.0000\n",
      "Epoch 591/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0119 - acc: 0.9987 - val_loss: 7.2535e-04 - val_acc: 1.0000\n",
      "Epoch 592/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0100 - acc: 0.9978 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 593/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0080 - val_acc: 0.9969\n",
      "Epoch 594/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0355 - val_acc: 0.9938\n",
      "Epoch 595/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 596/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 3.5638e-04 - val_acc: 1.0000\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 2.0016e-04 - val_acc: 1.0000\n",
      "Epoch 598/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 599/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.8692e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 600/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0079 - val_acc: 0.9969\n",
      "Epoch 601/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 6.1071e-04 - val_acc: 1.0000\n",
      "Epoch 602/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 7.0680e-04 - acc: 0.9996 - val_loss: 1.4486e-04 - val_acc: 1.0000\n",
      "Epoch 603/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 1.2145e-04 - val_acc: 1.0000\n",
      "Epoch 604/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2145e-04 - acc: 1.0000 - val_loss: 1.9316e-04 - val_acc: 1.0000\n",
      "Epoch 605/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0064 - acc: 0.9991 - val_loss: 4.8753e-05 - val_acc: 1.0000\n",
      "Epoch 606/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0039 - acc: 0.9996 - val_loss: 2.7950e-04 - val_acc: 1.0000\n",
      "Epoch 607/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3198e-04 - acc: 1.0000 - val_loss: 1.1671e-04 - val_acc: 1.0000\n",
      "Epoch 608/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 2.3597e-04 - val_acc: 1.0000\n",
      "Epoch 609/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.3662e-04 - acc: 0.9996 - val_loss: 1.8518e-04 - val_acc: 1.0000\n",
      "Epoch 610/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.5812e-04 - acc: 1.0000 - val_loss: 4.9511e-05 - val_acc: 1.0000\n",
      "Epoch 611/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.2198e-04 - acc: 1.0000 - val_loss: 3.4443e-05 - val_acc: 1.0000\n",
      "Epoch 612/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 5.5298e-05 - val_acc: 1.0000\n",
      "Epoch 613/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 1.7087e-04 - val_acc: 1.0000\n",
      "Epoch 614/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0036 - acc: 0.9996 - val_loss: 2.0675e-06 - val_acc: 1.0000\n",
      "Epoch 615/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 1.4231e-04 - val_acc: 1.0000\n",
      "Epoch 616/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0073 - acc: 0.9978 - val_loss: 1.5583e-04 - val_acc: 1.0000\n",
      "Epoch 617/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0084 - acc: 0.9987 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 618/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.5439e-04 - acc: 1.0000 - val_loss: 5.2079e-04 - val_acc: 1.0000\n",
      "Epoch 619/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.2407e-04 - acc: 1.0000 - val_loss: 3.2383e-04 - val_acc: 1.0000\n",
      "Epoch 620/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.7011e-05 - acc: 1.0000 - val_loss: 2.2348e-04 - val_acc: 1.0000\n",
      "Epoch 621/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1.2842e-04 - acc: 1.0000 - val_loss: 1.5841e-04 - val_acc: 1.0000\n",
      "Epoch 622/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 1.6656e-04 - acc: 1.0000 - val_loss: 8.5073e-05 - val_acc: 1.0000\n",
      "Epoch 623/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 2.1232e-04 - acc: 1.0000 - val_loss: 1.4127e-04 - val_acc: 1.0000\n",
      "Epoch 624/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0029 - acc: 0.9996 - val_loss: 3.1667e-04 - val_acc: 1.0000\n",
      "Epoch 625/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 2.3583e-05 - val_acc: 1.0000\n",
      "Epoch 626/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0132 - acc: 0.9965 - val_loss: 0.0061 - val_acc: 0.9938\n",
      "Epoch 627/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0128 - acc: 0.9970 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 628/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 629/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 4.7919e-04 - val_acc: 1.0000\n",
      "Epoch 630/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 631/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 2.7057e-05 - val_acc: 1.0000\n",
      "Epoch 632/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 633/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 6.4938e-04 - val_acc: 1.0000\n",
      "Epoch 634/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.5335e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 635/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.0368 - val_acc: 0.9906\n",
      "Epoch 636/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 4.7428e-04 - val_acc: 1.0000\n",
      "Epoch 637/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 8.8843e-04 - acc: 0.9996 - val_loss: 1.3073e-04 - val_acc: 1.0000\n",
      "Epoch 638/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 5.3227e-04 - acc: 0.9996 - val_loss: 0.0035 - val_acc: 0.9969\n",
      "Epoch 639/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.9111e-04 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9969\n",
      "Epoch 640/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.1241e-04 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 0.9969\n",
      "Epoch 641/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 2.5015e-04 - val_acc: 1.0000\n",
      "Epoch 642/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 5.1343e-05 - acc: 1.0000 - val_loss: 1.4452e-04 - val_acc: 1.0000\n",
      "Epoch 643/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0076 - val_acc: 0.9969\n",
      "Epoch 644/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 2.0208e-04 - val_acc: 1.0000\n",
      "Epoch 645/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0065 - acc: 0.9983 - val_loss: 5.4009e-05 - val_acc: 1.0000\n",
      "Epoch 646/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0115 - val_acc: 0.9938\n",
      "Epoch 647/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0555 - val_acc: 0.9906\n",
      "Epoch 648/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.9991 - val_loss: 4.2677e-06 - val_acc: 1.0000\n",
      "Epoch 649/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0048 - acc: 0.9996 - val_loss: 7.8064e-04 - val_acc: 1.0000\n",
      "Epoch 650/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5284e-04 - acc: 1.0000 - val_loss: 3.6957e-04 - val_acc: 1.0000\n",
      "Epoch 651/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.1268e-04 - acc: 1.0000 - val_loss: 3.4204e-04 - val_acc: 1.0000\n",
      "Epoch 652/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 2.9504e-04 - val_acc: 1.0000\n",
      "Epoch 653/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 654/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1.0092e-04 - acc: 1.0000 - val_loss: 1.7737e-04 - val_acc: 1.0000\n",
      "Epoch 655/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 656/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0094 - val_acc: 0.9938\n",
      "Epoch 657/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0040 - acc: 0.9991 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 658/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.1422e-04 - acc: 1.0000 - val_loss: 5.3394e-04 - val_acc: 1.0000\n",
      "Epoch 659/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0176 - val_acc: 0.9969\n",
      "Epoch 660/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 9.5700e-06 - val_acc: 1.0000\n",
      "Epoch 661/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0149 - acc: 0.9974 - val_loss: 2.5866e-04 - val_acc: 1.0000\n",
      "Epoch 662/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 3.1303e-04 - val_acc: 1.0000\n",
      "Epoch 663/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 4.0585e-04 - val_acc: 1.0000\n",
      "Epoch 664/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0054 - acc: 0.9978 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 665/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 3.8808e-04 - val_acc: 1.0000\n",
      "Epoch 666/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.2730e-05 - acc: 1.0000 - val_loss: 2.5433e-04 - val_acc: 1.0000\n",
      "Epoch 667/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0064 - val_acc: 0.9969\n",
      "Epoch 668/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 2.6093e-04 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9969\n",
      "Epoch 669/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 9.4201e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 670/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5001e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 671/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 7.9689e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 672/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 1.5251e-05 - val_acc: 1.0000\n",
      "Epoch 673/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.5178e-05 - acc: 1.0000 - val_loss: 5.5328e-06 - val_acc: 1.0000\n",
      "Epoch 674/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0036 - acc: 0.9996 - val_loss: 1.4947e-04 - val_acc: 1.0000\n",
      "Epoch 675/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.4875e-05 - acc: 1.0000 - val_loss: 7.9538e-05 - val_acc: 1.0000\n",
      "Epoch 676/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.3434e-04 - acc: 0.9996 - val_loss: 0.0392 - val_acc: 0.9875\n",
      "Epoch 677/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0074 - acc: 0.9996 - val_loss: 0.0240 - val_acc: 0.9938\n",
      "Epoch 678/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.6913e-04 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9938\n",
      "Epoch 679/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.0215 - val_acc: 0.9938\n",
      "Epoch 680/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 3.0538e-04 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9938\n",
      "Epoch 681/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 2.6408e-04 - acc: 1.0000 - val_loss: 0.0572 - val_acc: 0.9844\n",
      "Epoch 682/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0144 - acc: 0.9983 - val_loss: 0.1520 - val_acc: 0.9750\n",
      "Epoch 683/1000\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0056 - val_acc: 0.9938\n",
      "Epoch 684/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0896 - val_acc: 0.9875\n",
      "Epoch 685/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 8.2287e-05 - val_acc: 1.0000\n",
      "Epoch 686/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 687/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.6013e-04 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9969\n",
      "Epoch 688/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0072 - val_acc: 0.9969\n",
      "Epoch 689/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0062 - acc: 0.9991 - val_loss: 0.0030 - val_acc: 0.9969\n",
      "Epoch 690/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.4842e-04 - acc: 1.0000 - val_loss: 8.8793e-04 - val_acc: 1.0000\n",
      "Epoch 691/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 9.3926e-05 - acc: 1.0000 - val_loss: 3.9707e-04 - val_acc: 1.0000\n",
      "Epoch 692/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 693/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 4.1252e-04 - acc: 1.0000 - val_loss: 4.2020e-04 - val_acc: 1.0000\n",
      "Epoch 694/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0135 - acc: 0.9978 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 695/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0045 - acc: 0.9991 - val_loss: 9.7301e-05 - val_acc: 1.0000\n",
      "Epoch 696/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0086 - acc: 0.9978 - val_loss: 5.2639e-04 - val_acc: 1.0000\n",
      "Epoch 697/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 3.6475e-05 - val_acc: 1.0000\n",
      "Epoch 698/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 2.0349e-04 - val_acc: 1.0000\n",
      "Epoch 699/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 9.2329e-04 - acc: 0.9996 - val_loss: 0.0828 - val_acc: 0.9938\n",
      "Epoch 700/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0411 - val_acc: 0.9969\n",
      "Epoch 701/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 5.8605e-04 - val_acc: 1.0000\n",
      "Epoch 702/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0051 - acc: 0.9991 - val_loss: 0.0033 - val_acc: 0.9969\n",
      "Epoch 703/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.7796e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 704/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0071 - val_acc: 0.9969\n",
      "Epoch 705/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.4679e-04 - acc: 0.9996 - val_loss: 6.0665e-05 - val_acc: 1.0000\n",
      "Epoch 706/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 6.8008e-05 - acc: 1.0000 - val_loss: 4.1816e-05 - val_acc: 1.0000\n",
      "Epoch 707/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 2.1574e-06 - val_acc: 1.0000\n",
      "Epoch 708/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0055 - val_acc: 0.9969\n",
      "Epoch 709/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 710/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 7.9290e-04 - acc: 0.9996 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 711/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9991 - val_loss: 3.2459e-04 - val_acc: 1.0000\n",
      "Epoch 712/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0381 - val_acc: 0.9938\n",
      "Epoch 713/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.3902e-04 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9938\n",
      "Epoch 714/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0063 - acc: 0.9987 - val_loss: 3.0598e-04 - val_acc: 1.0000\n",
      "Epoch 715/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 716/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0065 - acc: 0.9987 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 717/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.6222e-04 - acc: 1.0000 - val_loss: 8.3046e-04 - val_acc: 1.0000\n",
      "Epoch 718/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0068 - acc: 0.9987 - val_loss: 0.0256 - val_acc: 0.9969\n",
      "Epoch 719/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 2.4891e-04 - val_acc: 1.0000\n",
      "Epoch 720/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0101 - val_acc: 0.9969\n",
      "Epoch 721/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 6.9536e-05 - val_acc: 1.0000\n",
      "Epoch 722/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0043 - acc: 0.9991 - val_loss: 0.0191 - val_acc: 0.9938\n",
      "Epoch 723/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0121 - val_acc: 0.9969\n",
      "Epoch 724/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0082 - val_acc: 0.9938\n",
      "Epoch 725/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.5039e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 726/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0029 - acc: 0.9996 - val_loss: 6.7743e-04 - val_acc: 1.0000\n",
      "Epoch 727/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 2.6383e-05 - val_acc: 1.0000\n",
      "Epoch 728/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.4647e-04 - acc: 1.0000 - val_loss: 5.5086e-05 - val_acc: 1.0000\n",
      "Epoch 729/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 730/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0656e-04 - acc: 1.0000 - val_loss: 6.2121e-04 - val_acc: 1.0000\n",
      "Epoch 731/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9969\n",
      "Epoch 732/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0040 - acc: 0.9991 - val_loss: 0.0194 - val_acc: 0.9969\n",
      "Epoch 733/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0118 - acc: 0.9978 - val_loss: 7.6194e-05 - val_acc: 1.0000\n",
      "Epoch 734/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 5.6943e-06 - val_acc: 1.0000\n",
      "Epoch 735/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9987 - val_loss: 1.0171e-05 - val_acc: 1.0000\n",
      "Epoch 736/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0078 - acc: 0.9987 - val_loss: 1.6233e-04 - val_acc: 1.0000\n",
      "Epoch 737/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 1.4717e-04 - val_acc: 1.0000\n",
      "Epoch 738/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 1.0350e-04 - val_acc: 1.0000\n",
      "Epoch 739/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0035 - acc: 0.9987 - val_loss: 9.4426e-04 - val_acc: 1.0000\n",
      "Epoch 740/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9996 - val_loss: 0.0035 - val_acc: 0.9969\n",
      "Epoch 741/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.3699e-04 - acc: 0.9996 - val_loss: 2.7901e-05 - val_acc: 1.0000\n",
      "Epoch 742/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 9.6006e-05 - acc: 1.0000 - val_loss: 2.3418e-05 - val_acc: 1.0000\n",
      "Epoch 743/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0045 - acc: 0.9991 - val_loss: 9.5389e-05 - val_acc: 1.0000\n",
      "Epoch 744/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 2.3067e-04 - acc: 1.0000 - val_loss: 8.5190e-05 - val_acc: 1.0000\n",
      "Epoch 745/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 2.3783e-04 - acc: 1.0000 - val_loss: 8.8284e-05 - val_acc: 1.0000\n",
      "Epoch 746/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 6.8223e-05 - val_acc: 1.0000\n",
      "Epoch 747/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 6.5068e-04 - acc: 0.9996 - val_loss: 3.2911e-05 - val_acc: 1.0000\n",
      "Epoch 748/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 5.9781e-04 - acc: 0.9996 - val_loss: 3.8315e-05 - val_acc: 1.0000\n",
      "Epoch 749/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 5.0453e-05 - acc: 1.0000 - val_loss: 4.8438e-05 - val_acc: 1.0000\n",
      "Epoch 750/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.7379e-04 - acc: 1.0000 - val_loss: 4.2830e-05 - val_acc: 1.0000\n",
      "Epoch 751/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0041 - acc: 0.9996 - val_loss: 2.2235e-04 - val_acc: 1.0000\n",
      "Epoch 752/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 9.0481e-04 - acc: 0.9996 - val_loss: 0.0029 - val_acc: 0.9969\n",
      "Epoch 753/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 7.0445e-05 - val_acc: 1.0000\n",
      "Epoch 754/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 4.0116e-05 - val_acc: 1.0000\n",
      "Epoch 755/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 5.7728e-05 - val_acc: 1.0000\n",
      "Epoch 756/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 5.1318e-05 - val_acc: 1.0000\n",
      "Epoch 757/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0285 - val_acc: 0.9906\n",
      "Epoch 758/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0299 - val_acc: 0.9906\n",
      "Epoch 759/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 2.1966e-04 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9906\n",
      "Epoch 760/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.8713e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 761/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0060 - acc: 0.9987 - val_loss: 3.0136e-04 - val_acc: 1.0000\n",
      "Epoch 762/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 7.9430e-05 - acc: 1.0000 - val_loss: 8.9185e-05 - val_acc: 1.0000\n",
      "Epoch 763/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.4297e-04 - acc: 1.0000 - val_loss: 5.2057e-05 - val_acc: 1.0000\n",
      "Epoch 764/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 9.6136e-05 - acc: 1.0000 - val_loss: 5.9938e-05 - val_acc: 1.0000\n",
      "Epoch 765/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0034 - val_acc: 0.9969\n",
      "Epoch 766/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.6666e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 767/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 8.6644e-05 - acc: 1.0000 - val_loss: 3.7737e-04 - val_acc: 1.0000\n",
      "Epoch 768/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.7102e-05 - acc: 1.0000 - val_loss: 2.8044e-04 - val_acc: 1.0000\n",
      "Epoch 769/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0040 - acc: 0.9991 - val_loss: 5.6407e-05 - val_acc: 1.0000\n",
      "Epoch 770/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0074 - acc: 0.9991 - val_loss: 1.0768e-04 - val_acc: 1.0000\n",
      "Epoch 771/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0061 - acc: 0.9987 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 772/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0101 - val_acc: 0.9969\n",
      "Epoch 773/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0068 - acc: 0.9991 - val_loss: 0.0236 - val_acc: 0.9938\n",
      "Epoch 774/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0049 - acc: 0.9991 - val_loss: 1.9424e-04 - val_acc: 1.0000\n",
      "Epoch 775/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 1.4470e-05 - val_acc: 1.0000\n",
      "Epoch 776/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0063 - acc: 0.9987 - val_loss: 0.0061 - val_acc: 0.9938\n",
      "Epoch 777/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9987 - val_loss: 2.6950e-04 - val_acc: 1.0000\n",
      "Epoch 778/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0035 - acc: 0.9987 - val_loss: 6.2676e-05 - val_acc: 1.0000\n",
      "Epoch 779/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 1.2301e-04 - val_acc: 1.0000\n",
      "Epoch 780/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 9.4937e-04 - acc: 0.9996 - val_loss: 1.7158e-04 - val_acc: 1.0000\n",
      "Epoch 781/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 3.4609e-04 - val_acc: 1.0000\n",
      "Epoch 782/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2656e-04 - acc: 1.0000 - val_loss: 1.0445e-04 - val_acc: 1.0000\n",
      "Epoch 783/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 1.9193e-04 - val_acc: 1.0000\n",
      "Epoch 784/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.0628 - val_acc: 0.9938\n",
      "Epoch 785/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 7.0586e-06 - val_acc: 1.0000\n",
      "Epoch 786/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.7991e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 787/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 2.2183e-05 - val_acc: 1.0000\n",
      "Epoch 788/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 1.4649e-05 - val_acc: 1.0000\n",
      "Epoch 789/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 6.0940e-04 - val_acc: 1.0000\n",
      "Epoch 790/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 5.5386e-04 - acc: 0.9996 - val_loss: 2.5217e-05 - val_acc: 1.0000\n",
      "Epoch 791/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 9.2019e-06 - val_acc: 1.0000\n",
      "Epoch 792/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0101 - acc: 0.9987 - val_loss: 1.1220e-04 - val_acc: 1.0000\n",
      "Epoch 793/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0032 - acc: 0.9996 - val_loss: 0.0051 - val_acc: 0.9969\n",
      "Epoch 794/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 795/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 4.8544e-04 - val_acc: 1.0000\n",
      "Epoch 796/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0624 - val_acc: 0.9812\n",
      "Epoch 797/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.0086 - val_acc: 0.9969\n",
      "Epoch 798/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 2.5503e-05 - val_acc: 1.0000\n",
      "Epoch 799/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0089 - acc: 0.9974 - val_loss: 1.1729e-04 - val_acc: 1.0000\n",
      "Epoch 800/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0109 - acc: 0.9978 - val_loss: 0.0406 - val_acc: 0.9906\n",
      "Epoch 801/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 802/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0059 - acc: 0.9987 - val_loss: 0.0638 - val_acc: 0.9875\n",
      "Epoch 803/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 5.5191e-04 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9938\n",
      "Epoch 804/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 4.8877e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 805/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 6.4139e-04 - val_acc: 1.0000\n",
      "Epoch 806/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.1278e-04 - acc: 1.0000 - val_loss: 2.4418e-04 - val_acc: 1.0000\n",
      "Epoch 807/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.8183e-04 - acc: 1.0000 - val_loss: 1.2797e-04 - val_acc: 1.0000\n",
      "Epoch 808/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 3.3073e-04 - val_acc: 1.0000\n",
      "Epoch 809/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0156 - val_acc: 0.9969\n",
      "Epoch 810/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 2.0340e-04 - val_acc: 1.0000\n",
      "Epoch 811/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 7.4090e-04 - acc: 0.9996 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 812/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 4.9936e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 813/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0064 - acc: 0.9991 - val_loss: 0.0138 - val_acc: 0.9938\n",
      "Epoch 814/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.7217e-04 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 815/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0071 - acc: 0.9987 - val_loss: 0.0163 - val_acc: 0.9906\n",
      "Epoch 816/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 4.2845e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 817/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 3.9579e-04 - acc: 1.0000 - val_loss: 8.1932e-04 - val_acc: 1.0000\n",
      "Epoch 818/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 819/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0060 - acc: 0.9987 - val_loss: 0.0716 - val_acc: 0.9875\n",
      "Epoch 820/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0101 - val_acc: 0.9969\n",
      "Epoch 821/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0031 - acc: 0.9987 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 822/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 2.0301e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 823/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.0732e-04 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 0.9969\n",
      "Epoch 824/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 9.8662e-05 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 825/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0025 - acc: 0.9987 - val_loss: 8.5986e-04 - val_acc: 1.0000\n",
      "Epoch 826/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0865 - val_acc: 0.9875\n",
      "Epoch 827/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0689 - val_acc: 0.9875\n",
      "Epoch 828/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0523 - val_acc: 0.9969\n",
      "Epoch 829/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0556 - val_acc: 0.9969\n",
      "Epoch 830/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0297 - val_acc: 0.9969\n",
      "Epoch 831/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 3.6696e-04 - acc: 1.0000 - val_loss: 0.0356 - val_acc: 0.9969\n",
      "Epoch 832/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.2119e-04 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 0.9969\n",
      "Epoch 833/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 9ms/step - loss: 7.1465e-05 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 0.9969\n",
      "Epoch 834/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0111 - acc: 0.9978 - val_loss: 0.0458 - val_acc: 0.9969\n",
      "Epoch 835/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0078 - acc: 0.9987 - val_loss: 0.0111 - val_acc: 0.9969\n",
      "Epoch 836/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.9601e-05 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 0.9938\n",
      "Epoch 837/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0013 - acc: 0.9991 - val_loss: 0.0511 - val_acc: 0.9969\n",
      "Epoch 838/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4013e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 839/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 2.5300e-04 - val_acc: 1.0000\n",
      "Epoch 840/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0554 - val_acc: 0.9938\n",
      "Epoch 841/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0050 - val_acc: 0.9969\n",
      "Epoch 842/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0088 - acc: 0.9978 - val_loss: 0.0157 - val_acc: 0.9938\n",
      "Epoch 843/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.5211e-04 - acc: 0.9996 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 844/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0125 - val_acc: 0.9938\n",
      "Epoch 845/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 3.7063e-04 - acc: 1.0000 - val_loss: 1.0185e-04 - val_acc: 1.0000\n",
      "Epoch 846/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.8735e-04 - acc: 1.0000 - val_loss: 6.1750e-04 - val_acc: 1.0000\n",
      "Epoch 847/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0094 - val_acc: 0.9938\n",
      "Epoch 848/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0045 - acc: 0.9991 - val_loss: 2.2508e-04 - val_acc: 1.0000\n",
      "Epoch 849/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0066 - acc: 0.9987 - val_loss: 0.0868 - val_acc: 0.9906\n",
      "Epoch 850/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0077 - acc: 0.9987 - val_loss: 1.9872e-05 - val_acc: 1.0000\n",
      "Epoch 851/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0137 - acc: 0.9983 - val_loss: 0.0187 - val_acc: 0.9969\n",
      "Epoch 852/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0071 - acc: 0.9978 - val_loss: 4.6449e-04 - val_acc: 1.0000\n",
      "Epoch 853/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0041 - val_acc: 0.9969\n",
      "Epoch 854/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0443 - val_acc: 0.9969\n",
      "Epoch 855/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0528 - val_acc: 0.9969\n",
      "Epoch 856/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0111 - acc: 0.9978 - val_loss: 0.0521 - val_acc: 0.9969\n",
      "Epoch 857/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0519 - val_acc: 0.9969\n",
      "Epoch 858/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0036 - acc: 0.9996 - val_loss: 0.0084 - val_acc: 0.9969\n",
      "Epoch 859/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.1325e-04 - acc: 0.9996 - val_loss: 0.0046 - val_acc: 0.9969\n",
      "Epoch 860/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 2.8816e-04 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 0.9969\n",
      "Epoch 861/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0041 - acc: 0.9991 - val_loss: 0.0238 - val_acc: 0.9969\n",
      "Epoch 862/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5470e-04 - acc: 1.0000 - val_loss: 5.5109e-05 - val_acc: 1.0000\n",
      "Epoch 863/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 1.3694e-04 - val_acc: 1.0000\n",
      "Epoch 864/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0394 - val_acc: 0.9938\n",
      "Epoch 865/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0135 - val_acc: 0.9969\n",
      "Epoch 866/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0059 - acc: 0.9987 - val_loss: 0.0133 - val_acc: 0.9938\n",
      "Epoch 867/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 4.9191e-04 - val_acc: 1.0000\n",
      "Epoch 868/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0056 - val_acc: 0.9969\n",
      "Epoch 869/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0097 - val_acc: 0.9938\n",
      "Epoch 870/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 2.3403e-04 - val_acc: 1.0000\n",
      "Epoch 871/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.1100 - val_acc: 0.9812\n",
      "Epoch 872/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0179 - val_acc: 0.9938\n",
      "Epoch 873/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0086 - val_acc: 0.9938\n",
      "Epoch 874/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 4.6231e-04 - acc: 1.0000 - val_loss: 7.7589e-05 - val_acc: 1.0000\n",
      "Epoch 875/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0167 - acc: 0.9974 - val_loss: 0.0149 - val_acc: 0.9938\n",
      "Epoch 876/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0359 - val_acc: 0.9938\n",
      "Epoch 877/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0354 - val_acc: 0.9938\n",
      "Epoch 878/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 6.7588e-05 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9969\n",
      "Epoch 879/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0621 - val_acc: 0.9906\n",
      "Epoch 880/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0013 - acc: 0.9991 - val_loss: 0.0229 - val_acc: 0.9938\n",
      "Epoch 881/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.1982e-04 - acc: 1.0000 - val_loss: 0.0454 - val_acc: 0.9938\n",
      "Epoch 882/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0696 - val_acc: 0.9875\n",
      "Epoch 883/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0162 - val_acc: 0.9938\n",
      "Epoch 884/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0358 - val_acc: 0.9969\n",
      "Epoch 885/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0019 - acc: 0.9987 - val_loss: 0.0949 - val_acc: 0.9875\n",
      "Epoch 886/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 2.6418e-04 - acc: 1.0000 - val_loss: 0.0417 - val_acc: 0.9938\n",
      "Epoch 887/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 4.4421e-04 - acc: 1.0000 - val_loss: 0.0578 - val_acc: 0.9938\n",
      "Epoch 888/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.0304 - val_acc: 0.9938\n",
      "Epoch 889/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 6.5724e-04 - acc: 1.0000 - val_loss: 2.8959e-04 - val_acc: 1.0000\n",
      "Epoch 890/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 2.8740e-04 - acc: 1.0000 - val_loss: 1.5944e-04 - val_acc: 1.0000\n",
      "Epoch 891/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 9.0152e-05 - acc: 1.0000 - val_loss: 9.4172e-05 - val_acc: 1.0000\n",
      "Epoch 892/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 5.5768e-05 - acc: 1.0000 - val_loss: 6.6690e-05 - val_acc: 1.0000\n",
      "Epoch 893/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 4.6331e-05 - acc: 1.0000 - val_loss: 5.1004e-05 - val_acc: 1.0000\n",
      "Epoch 894/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 5.6898e-04 - acc: 0.9996 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 895/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0413 - val_acc: 0.9906\n",
      "Epoch 896/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 897/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 4.7256e-04 - val_acc: 1.0000\n",
      "Epoch 898/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.6131e-05 - acc: 1.0000 - val_loss: 3.4181e-04 - val_acc: 1.0000\n",
      "Epoch 899/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.4874e-04 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9969\n",
      "Epoch 900/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0059 - acc: 0.9978 - val_loss: 0.0202 - val_acc: 0.9969\n",
      "Epoch 901/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0570 - val_acc: 0.9938\n",
      "Epoch 902/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 3.3029e-04 - acc: 1.0000 - val_loss: 2.0304e-04 - val_acc: 1.0000\n",
      "Epoch 903/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0315 - val_acc: 0.9969\n",
      "Epoch 904/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.2118e-05 - acc: 1.0000 - val_loss: 0.0564 - val_acc: 0.9938\n",
      "Epoch 905/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.0816 - val_acc: 0.9938\n",
      "Epoch 906/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0400 - val_acc: 0.9938\n",
      "Epoch 907/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0137 - val_acc: 0.9969\n",
      "Epoch 908/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 3.2420e-04 - val_acc: 1.0000\n",
      "Epoch 909/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.5655e-04 - acc: 0.9996 - val_loss: 0.0074 - val_acc: 0.9938\n",
      "Epoch 910/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 1.8843e-04 - acc: 1.0000 - val_loss: 5.6102e-04 - val_acc: 1.0000\n",
      "Epoch 911/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 1.4029e-04 - val_acc: 1.0000\n",
      "Epoch 912/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 2.8304e-04 - acc: 1.0000 - val_loss: 9.3233e-04 - val_acc: 1.0000\n",
      "Epoch 913/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 7.7705e-05 - val_acc: 1.0000\n",
      "Epoch 914/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0850 - val_acc: 0.9875\n",
      "Epoch 915/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 1.5641e-04 - val_acc: 1.0000\n",
      "Epoch 916/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0049 - acc: 0.9996 - val_loss: 2.6835e-04 - val_acc: 1.0000\n",
      "Epoch 917/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0462 - val_acc: 0.9969\n",
      "Epoch 918/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0107 - acc: 0.9978 - val_loss: 0.0465 - val_acc: 0.9938\n",
      "Epoch 919/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0224 - acc: 0.9970 - val_loss: 0.0619 - val_acc: 0.9938\n",
      "Epoch 920/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0118 - acc: 0.9974 - val_loss: 3.8860e-04 - val_acc: 1.0000\n",
      "Epoch 921/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0028 - acc: 0.9987 - val_loss: 0.1849 - val_acc: 0.9844\n",
      "Epoch 922/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0128 - acc: 0.9970 - val_loss: 0.0753 - val_acc: 0.9906\n",
      "Epoch 923/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0074 - acc: 0.9974 - val_loss: 1.0313e-04 - val_acc: 1.0000\n",
      "Epoch 924/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0148 - acc: 0.9965 - val_loss: 1.0764e-04 - val_acc: 1.0000\n",
      "Epoch 925/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 1.8476e-05 - val_acc: 1.0000\n",
      "Epoch 926/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0179 - acc: 0.9983 - val_loss: 5.9361e-06 - val_acc: 1.0000\n",
      "Epoch 927/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0208 - acc: 0.9961 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 928/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 929/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 930/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 7.1309e-04 - acc: 1.0000 - val_loss: 2.7668e-04 - val_acc: 1.0000\n",
      "Epoch 931/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0122 - acc: 0.9965 - val_loss: 3.7337e-06 - val_acc: 1.0000\n",
      "Epoch 932/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0151 - acc: 0.9970 - val_loss: 1.5770e-04 - val_acc: 1.0000\n",
      "Epoch 933/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0065 - acc: 0.9987 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 934/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 1.9515e-04 - val_acc: 1.0000\n",
      "Epoch 935/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 936/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0196 - val_acc: 0.9938\n",
      "Epoch 937/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0244 - acc: 0.9970 - val_loss: 3.0615e-05 - val_acc: 1.0000\n",
      "Epoch 938/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0113 - acc: 0.9983 - val_loss: 2.0540e-05 - val_acc: 1.0000\n",
      "Epoch 939/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 1.5800e-05 - val_acc: 1.0000\n",
      "Epoch 940/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0043 - acc: 0.9991 - val_loss: 4.3619e-05 - val_acc: 1.0000\n",
      "Epoch 941/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 5.7301e-04 - acc: 0.9996 - val_loss: 3.4598e-05 - val_acc: 1.0000\n",
      "Epoch 942/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 8.5529e-05 - val_acc: 1.0000\n",
      "Epoch 943/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0186 - val_acc: 0.9969\n",
      "Epoch 944/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0043 - acc: 0.9987 - val_loss: 2.7247e-04 - val_acc: 1.0000\n",
      "Epoch 945/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0014 - acc: 0.9987 - val_loss: 1.5366e-04 - val_acc: 1.0000\n",
      "Epoch 946/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0033 - acc: 0.9987 - val_loss: 2.6231e-04 - val_acc: 1.0000\n",
      "Epoch 947/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 5.6772e-04 - acc: 1.0000 - val_loss: 1.3250e-04 - val_acc: 1.0000\n",
      "Epoch 948/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 5.9004e-04 - acc: 0.9996 - val_loss: 7.0297e-05 - val_acc: 1.0000\n",
      "Epoch 949/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0091 - acc: 0.9983 - val_loss: 6.1711e-04 - val_acc: 1.0000\n",
      "Epoch 950/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 8.5226e-04 - acc: 0.9996 - val_loss: 1.2681e-04 - val_acc: 1.0000\n",
      "Epoch 951/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 1.8020e-04 - val_acc: 1.0000\n",
      "Epoch 952/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 953/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 4.1145e-05 - val_acc: 1.0000\n",
      "Epoch 954/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 3.7249e-04 - val_acc: 1.0000\n",
      "Epoch 955/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 6.8268e-04 - val_acc: 1.0000\n",
      "Epoch 956/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0013 - acc: 0.9991 - val_loss: 3.8237e-04 - val_acc: 1.0000\n",
      "Epoch 957/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9991 - val_loss: 1.8235e-04 - val_acc: 1.0000\n",
      "Epoch 958/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0072 - val_acc: 0.9969\n",
      "Epoch 959/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0082 - acc: 0.9983 - val_loss: 3.2253e-04 - val_acc: 1.0000\n",
      "Epoch 960/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.8846e-04 - acc: 0.9996 - val_loss: 2.6515e-05 - val_acc: 1.0000\n",
      "Epoch 961/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0081 - acc: 0.9974 - val_loss: 1.5167e-04 - val_acc: 1.0000\n",
      "Epoch 962/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0027 - acc: 0.9987 - val_loss: 0.0095 - val_acc: 0.9938\n",
      "Epoch 963/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0086 - acc: 0.9987 - val_loss: 0.0213 - val_acc: 0.9938\n",
      "Epoch 964/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 9.9505e-04 - val_acc: 1.0000\n",
      "Epoch 965/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 966/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0216 - val_acc: 0.9969\n",
      "Epoch 967/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 8.2554e-05 - val_acc: 1.0000\n",
      "Epoch 968/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0069 - val_acc: 0.9969\n",
      "Epoch 969/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.4571e-04 - acc: 0.9996 - val_loss: 4.4403e-04 - val_acc: 1.0000\n",
      "Epoch 970/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.4346e-04 - acc: 1.0000 - val_loss: 4.4361e-04 - val_acc: 1.0000\n",
      "Epoch 971/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.4226e-05 - acc: 1.0000 - val_loss: 3.6006e-04 - val_acc: 1.0000\n",
      "Epoch 972/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.0488e-04 - acc: 1.0000 - val_loss: 0.0260 - val_acc: 0.9938\n",
      "Epoch 973/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0123 - acc: 0.9957 - val_loss: 3.8312e-05 - val_acc: 1.0000\n",
      "Epoch 974/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 6.2961e-05 - val_acc: 1.0000\n",
      "Epoch 975/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0754 - val_acc: 0.9938\n",
      "Epoch 976/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 7.1370e-04 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 0.9969\n",
      "Epoch 977/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0137 - val_acc: 0.9969\n",
      "Epoch 978/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0116 - val_acc: 0.9938\n",
      "Epoch 979/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0068 - acc: 0.9978 - val_loss: 2.0154e-04 - val_acc: 1.0000\n",
      "Epoch 980/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0074 - acc: 0.9970 - val_loss: 3.1551e-05 - val_acc: 1.0000\n",
      "Epoch 981/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0120 - acc: 0.9987 - val_loss: 1.9210e-05 - val_acc: 1.0000\n",
      "Epoch 982/1000\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 983/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0036 - val_acc: 0.9969\n",
      "Epoch 984/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 7.2367e-05 - val_acc: 1.0000\n",
      "Epoch 985/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 4.8891e-04 - val_acc: 1.0000\n",
      "Epoch 986/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 987/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 7.5623e-04 - val_acc: 1.0000\n",
      "Epoch 988/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0027 - acc: 0.9987 - val_loss: 2.3779e-04 - val_acc: 1.0000\n",
      "Epoch 989/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0082 - acc: 0.9983 - val_loss: 0.0088 - val_acc: 0.9969\n",
      "Epoch 990/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0099 - val_acc: 0.9938\n",
      "Epoch 991/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0527 - val_acc: 0.9969\n",
      "Epoch 992/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1008 - val_acc: 0.9938\n",
      "Epoch 993/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0093 - acc: 0.9987 - val_loss: 0.0428 - val_acc: 0.9969\n",
      "Epoch 994/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 6.1952e-04 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 0.9938\n",
      "Epoch 995/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0505 - val_acc: 0.9969\n",
      "Epoch 996/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0505 - val_acc: 0.9969\n",
      "Epoch 997/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 2.1061e-04 - val_acc: 1.0000\n",
      "Epoch 998/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0577 - val_acc: 0.9938\n",
      "Epoch 999/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 3.7327e-04 - acc: 1.0000 - val_loss: 0.0506 - val_acc: 0.9969\n",
      "Epoch 1000/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0506 - val_acc: 0.9969\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating model: A_A_inceptionv3-dot-final_1000_Nadam.h5 ===\n",
      "\n",
      "Accuracy: 0.991\n",
      "\n",
      "Confusion Matrix\n",
      "[[301   6]\n",
      " [  0 333]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99       307\n",
      "          1       0.98      1.00      0.99       333\n",
      "\n",
      "avg / total       0.99      0.99      0.99       640\n",
      "\n",
      "=== Evaluating model: A_A_inceptionv3-dot-best_1000_Nadam.h5 ===\n",
      "\n",
      "Accuracy: 0.998\n",
      "\n",
      "Confusion Matrix\n",
      "[[308   1]\n",
      " [  0 331]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       309\n",
      "          1       1.00      1.00      1.00       331\n",
      "\n",
      "avg / total       1.00      1.00      1.00       640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_gen = data_generator(train_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "val_gen = data_generator(val_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "\n",
    "# In [17]:\n",
    "def cosine_distance(vecs, normalize=False):\n",
    "    x, y = vecs\n",
    "    if normalize:\n",
    "        x = K.l2_normalize(x, axis=0)\n",
    "        y = K.l2_normalize(x, axis=0)\n",
    "    return K.prod(K.stack([x, y], axis=1), axis=1)\n",
    "\n",
    "def cosine_distance_output_shape(shapes):\n",
    "    return shapes[0]\n",
    "\n",
    "vecs = [np.random.random((10,)), np.random.random((10,))]\n",
    "print(vecs[0].shape, vecs[1].shape)\n",
    "s = cosine_distance(vecs)\n",
    "print(s.shape)\n",
    "# (10,) (10,)\n",
    "# (10,)\n",
    "# In [18]:\n",
    "input_1 = Input(shape=(VECTOR_SIZE,))\n",
    "input_2 = Input(shape=(VECTOR_SIZE,))\n",
    "merged = Lambda(cosine_distance, \n",
    "                  output_shape=cosine_distance_output_shape)([input_1, input_2]) ###\n",
    "\n",
    "fc1 = Dense(512, kernel_initializer=\"glorot_uniform\")(merged)\n",
    "fc1 = Dropout(0.2)(fc1)\n",
    "fc1 = Activation(\"relu\")(fc1)\n",
    "\n",
    "fc2 = Dense(128, kernel_initializer=\"glorot_uniform\")(fc1)\n",
    "fc2 = Dropout(0.2)(fc2)\n",
    "fc2 = Activation(\"relu\")(fc2)\n",
    "\n",
    "pred = Dense(2, kernel_initializer=\"glorot_uniform\")(fc2)\n",
    "pred = Activation(\"softmax\")(pred)\n",
    "# In [19]:\n",
    "model = Model(inputs=[input_1, input_2], outputs=pred)\n",
    "# model.summary()\n",
    "# In [20]:\n",
    "model.compile(optimizer=\"Nadam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# In [21]:\n",
    "best_model_name = get_model_file(DATA_DIR, \"inceptionv3\", \"dot\", \"best\")\n",
    "checkpoint = ModelCheckpoint(best_model_name, save_best_only=True)\n",
    "train_steps_per_epoch = len(train_triples) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(val_triples) // BATCH_SIZE\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps_per_epoch, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              validation_data=val_gen, validation_steps=val_steps_per_epoch,\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "# In [22]:\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# In [23]:\n",
    "final_model_name = get_model_file(DATA_DIR, \"inceptionv3\", \"dot\", \"final\")\n",
    "model.save(final_model_name)\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "final_accuracy = evaluate_model(final_model_name, test_gen)\n",
    "\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "best_accuracy = evaluate_model(best_model_name, test_gen)\n",
    "\n",
    "scores[0, 1] = best_accuracy if best_accuracy > final_accuracy else final_accuracy\n",
    "# === Evaluating model: inceptionv3-dot-final.h5 ===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,) (10,)\n",
      "(10,)\n",
      "Epoch 1/1000\n",
      "72/72 [==============================] - 2s 32ms/step - loss: 0.6180 - acc: 0.6411 - val_loss: 0.3889 - val_acc: 0.8531\n",
      "Epoch 2/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3338 - acc: 0.8772 - val_loss: 0.0891 - val_acc: 0.9938\n",
      "Epoch 3/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.1139 - acc: 0.9631 - val_loss: 0.0242 - val_acc: 0.9969\n",
      "Epoch 4/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0302 - acc: 0.9931 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 5/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0151 - acc: 0.9948 - val_loss: 0.3198 - val_acc: 0.9094\n",
      "Epoch 6/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0162 - acc: 0.9935 - val_loss: 0.0081 - val_acc: 0.9938\n",
      "Epoch 7/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0078 - val_acc: 0.9969\n",
      "Epoch 8/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0393 - val_acc: 0.9906\n",
      "Epoch 9/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 6.9645e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 10/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 9.9766e-04 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 0.9938\n",
      "Epoch 11/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.1173 - acc: 0.9753 - val_loss: 0.7559 - val_acc: 0.5687\n",
      "Epoch 12/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.2622 - acc: 0.9201 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 13/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0219 - acc: 0.9961 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 14/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0098 - acc: 0.9987 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 15/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0456 - acc: 0.9905 - val_loss: 0.0416 - val_acc: 0.9906\n",
      "Epoch 16/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0082 - acc: 0.9987 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 17/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0034 - acc: 0.9996 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 18/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 9.6855e-04 - val_acc: 1.0000\n",
      "Epoch 19/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.6175e-04 - val_acc: 1.0000\n",
      "Epoch 20/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0656 - acc: 0.9835 - val_loss: 0.0215 - val_acc: 0.9969\n",
      "Epoch 21/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 8.6599e-04 - val_acc: 1.0000\n",
      "Epoch 22/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 23/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 24/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0127 - acc: 0.9952 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 25/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 5.4598e-04 - val_acc: 1.0000\n",
      "Epoch 26/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9996 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 27/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0211 - val_acc: 0.9969\n",
      "Epoch 28/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0045 - acc: 0.9983 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 29/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 5.7360e-04 - val_acc: 1.0000\n",
      "Epoch 30/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.3069e-04 - acc: 1.0000 - val_loss: 3.2702e-04 - val_acc: 1.0000\n",
      "Epoch 31/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 4.3046e-04 - acc: 1.0000 - val_loss: 1.7629e-04 - val_acc: 1.0000\n",
      "Epoch 32/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 8.0076e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 33/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0063 - acc: 0.9974 - val_loss: 7.3165e-04 - val_acc: 1.0000\n",
      "Epoch 34/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 7.5618e-04 - val_acc: 1.0000\n",
      "Epoch 35/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 6.3942e-04 - val_acc: 1.0000\n",
      "Epoch 36/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 5.0931e-04 - acc: 1.0000 - val_loss: 2.4656e-04 - val_acc: 1.0000\n",
      "Epoch 37/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 4.4666e-04 - acc: 1.0000 - val_loss: 4.2482e-04 - val_acc: 1.0000\n",
      "Epoch 38/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.2706e-04 - acc: 1.0000 - val_loss: 2.1724e-04 - val_acc: 1.0000\n",
      "Epoch 39/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.7004e-04 - acc: 1.0000 - val_loss: 1.6178e-04 - val_acc: 1.0000\n",
      "Epoch 40/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 4.5878e-04 - acc: 1.0000 - val_loss: 2.0157e-04 - val_acc: 1.0000\n",
      "Epoch 41/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 3.7886e-04 - acc: 1.0000 - val_loss: 1.2613e-04 - val_acc: 1.0000\n",
      "Epoch 42/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.1337e-04 - acc: 1.0000 - val_loss: 1.0419e-04 - val_acc: 1.0000\n",
      "Epoch 43/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.2610e-04 - acc: 1.0000 - val_loss: 1.7463e-04 - val_acc: 1.0000\n",
      "Epoch 44/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.7343e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 45/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 9.1028e-05 - acc: 1.0000 - val_loss: 1.9650e-04 - val_acc: 1.0000\n",
      "Epoch 46/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 2.0404e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 47/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.2035e-04 - acc: 1.0000 - val_loss: 6.1021e-04 - val_acc: 1.0000\n",
      "Epoch 48/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 5.4032e-05 - acc: 1.0000 - val_loss: 1.5350e-04 - val_acc: 1.0000\n",
      "Epoch 49/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 4.7577e-05 - acc: 1.0000 - val_loss: 1.2140e-04 - val_acc: 1.0000\n",
      "Epoch 50/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 4.2778e-05 - acc: 1.0000 - val_loss: 1.3858e-04 - val_acc: 1.0000\n",
      "Epoch 51/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 3.7928e-05 - acc: 1.0000 - val_loss: 1.1459e-04 - val_acc: 1.0000\n",
      "Epoch 52/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 6.3451e-05 - acc: 1.0000 - val_loss: 7.5820e-04 - val_acc: 1.0000\n",
      "Epoch 53/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 4.2612e-05 - acc: 1.0000 - val_loss: 5.0338e-05 - val_acc: 1.0000\n",
      "Epoch 54/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.7110e-05 - acc: 1.0000 - val_loss: 3.6574e-05 - val_acc: 1.0000\n",
      "Epoch 55/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 3.3105e-05 - acc: 1.0000 - val_loss: 2.4980e-05 - val_acc: 1.0000\n",
      "Epoch 56/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1338 - acc: 0.9722 - val_loss: 0.0820 - val_acc: 1.0000\n",
      "Epoch 57/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0634 - acc: 0.9848 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 58/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0164 - acc: 0.9957 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 59/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0073 - acc: 0.9983 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0105 - acc: 0.9978 - val_loss: 4.5175e-04 - val_acc: 1.0000\n",
      "Epoch 61/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0059 - acc: 0.9978 - val_loss: 0.0053 - val_acc: 0.9969\n",
      "Epoch 62/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0095 - acc: 0.9987 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 63/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 64/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0045 - acc: 0.9991 - val_loss: 8.5503e-04 - val_acc: 1.0000\n",
      "Epoch 65/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 5.4342e-04 - val_acc: 1.0000\n",
      "Epoch 66/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0091 - acc: 0.9983 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 67/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0065 - acc: 0.9987 - val_loss: 9.8894e-04 - val_acc: 1.0000\n",
      "Epoch 68/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 5.3116e-04 - val_acc: 1.0000\n",
      "Epoch 69/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 6.7160e-04 - val_acc: 1.0000\n",
      "Epoch 70/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.1009e-04 - acc: 1.0000 - val_loss: 3.4254e-04 - val_acc: 1.0000\n",
      "Epoch 71/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 2.6399e-04 - val_acc: 1.0000\n",
      "Epoch 72/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 7.9089e-04 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9938\n",
      "Epoch 73/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 5.0720e-04 - acc: 1.0000 - val_loss: 2.7455e-04 - val_acc: 1.0000\n",
      "Epoch 74/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0035 - acc: 0.9987 - val_loss: 2.3803e-04 - val_acc: 1.0000\n",
      "Epoch 75/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.8564e-04 - acc: 1.0000 - val_loss: 1.3143e-04 - val_acc: 1.0000\n",
      "Epoch 76/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.1650e-04 - acc: 1.0000 - val_loss: 1.2621e-04 - val_acc: 1.0000\n",
      "Epoch 77/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.6832e-05 - acc: 1.0000 - val_loss: 9.4146e-05 - val_acc: 1.0000\n",
      "Epoch 78/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 3.0253e-04 - val_acc: 1.0000\n",
      "Epoch 79/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5853e-04 - acc: 1.0000 - val_loss: 1.3320e-04 - val_acc: 1.0000\n",
      "Epoch 80/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.8536e-04 - acc: 0.9996 - val_loss: 1.9407e-04 - val_acc: 1.0000\n",
      "Epoch 81/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0048 - acc: 0.9987 - val_loss: 2.1678e-04 - val_acc: 1.0000\n",
      "Epoch 82/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.2838e-04 - acc: 1.0000 - val_loss: 1.0493e-04 - val_acc: 1.0000\n",
      "Epoch 83/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.5201e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 84/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0049 - acc: 0.9991 - val_loss: 4.7070e-04 - val_acc: 1.0000\n",
      "Epoch 85/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 86/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0051 - acc: 0.9991 - val_loss: 2.9659e-04 - val_acc: 1.0000\n",
      "Epoch 87/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.9302e-04 - acc: 1.0000 - val_loss: 1.3028e-04 - val_acc: 1.0000\n",
      "Epoch 88/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.4809e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 89/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0414 - val_acc: 0.9781\n",
      "Epoch 90/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0634 - acc: 0.9857 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 91/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0148 - acc: 0.9974 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 92/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 93/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0059 - acc: 0.9996 - val_loss: 3.2756e-04 - val_acc: 1.0000\n",
      "Epoch 94/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0048 - acc: 0.9996 - val_loss: 3.5762e-04 - val_acc: 1.0000\n",
      "Epoch 95/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0020 - acc: 0.9983 - val_loss: 0.0146 - val_acc: 0.9969\n",
      "Epoch 96/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 97/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0069 - acc: 0.9991 - val_loss: 7.8358e-04 - val_acc: 1.0000\n",
      "Epoch 98/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 1.4558e-04 - val_acc: 1.0000\n",
      "Epoch 99/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 100/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 8.9313e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 101/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.1473e-04 - acc: 0.9996 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 102/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 7.0874e-04 - val_acc: 1.0000\n",
      "Epoch 103/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0046 - acc: 0.9996 - val_loss: 7.2157e-04 - val_acc: 1.0000\n",
      "Epoch 104/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 1.7968e-04 - val_acc: 1.0000\n",
      "Epoch 105/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0057 - acc: 0.9987 - val_loss: 2.9982e-04 - val_acc: 1.0000\n",
      "Epoch 106/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 4.4735e-04 - val_acc: 1.0000\n",
      "Epoch 107/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0226 - acc: 0.9952 - val_loss: 4.9798e-04 - val_acc: 1.0000\n",
      "Epoch 108/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0055 - acc: 0.9991 - val_loss: 0.0035 - val_acc: 0.9969\n",
      "Epoch 109/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0085 - acc: 0.9987 - val_loss: 5.7711e-04 - val_acc: 1.0000\n",
      "Epoch 110/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 7.4637e-04 - acc: 1.0000 - val_loss: 4.9501e-04 - val_acc: 1.0000\n",
      "Epoch 111/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0093 - acc: 0.9974 - val_loss: 6.9074e-04 - val_acc: 1.0000\n",
      "Epoch 112/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 6.4576e-04 - val_acc: 1.0000\n",
      "Epoch 113/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0055 - acc: 0.9991 - val_loss: 0.0043 - val_acc: 0.9969\n",
      "Epoch 114/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0043 - acc: 0.9996 - val_loss: 2.9063e-04 - val_acc: 1.0000\n",
      "Epoch 115/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0029 - acc: 0.9996 - val_loss: 1.9069e-04 - val_acc: 1.0000\n",
      "Epoch 116/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0068 - acc: 0.9991 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 117/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0039 - acc: 0.9983 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 118/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 2.9320e-04 - val_acc: 1.0000\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 10ms/step - loss: 6.4211e-04 - acc: 1.0000 - val_loss: 5.0491e-04 - val_acc: 1.0000\n",
      "Epoch 120/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.1580e-04 - acc: 1.0000 - val_loss: 1.3932e-04 - val_acc: 1.0000\n",
      "Epoch 121/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.5068e-04 - acc: 1.0000 - val_loss: 2.4785e-04 - val_acc: 1.0000\n",
      "Epoch 122/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 5.0856e-04 - val_acc: 1.0000\n",
      "Epoch 123/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.0513e-04 - acc: 1.0000 - val_loss: 1.5687e-04 - val_acc: 1.0000\n",
      "Epoch 124/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 6.5121e-05 - acc: 1.0000 - val_loss: 4.5361e-05 - val_acc: 1.0000\n",
      "Epoch 125/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.2276e-05 - acc: 1.0000 - val_loss: 8.1596e-05 - val_acc: 1.0000\n",
      "Epoch 126/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.8956e-04 - acc: 1.0000 - val_loss: 2.0985e-04 - val_acc: 1.0000\n",
      "Epoch 127/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0136 - acc: 0.9970 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 128/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0070 - acc: 0.9983 - val_loss: 1.3635e-04 - val_acc: 1.0000\n",
      "Epoch 129/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 1.1958e-04 - val_acc: 1.0000\n",
      "Epoch 130/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0094 - acc: 0.9987 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 131/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 132/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0047 - acc: 0.9991 - val_loss: 2.5405e-04 - val_acc: 1.0000\n",
      "Epoch 133/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.8482e-04 - acc: 1.0000 - val_loss: 1.8200e-04 - val_acc: 1.0000\n",
      "Epoch 134/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.7608e-04 - acc: 1.0000 - val_loss: 1.5053e-04 - val_acc: 1.0000\n",
      "Epoch 135/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.5876e-04 - acc: 1.0000 - val_loss: 2.0351e-04 - val_acc: 1.0000\n",
      "Epoch 136/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.5317e-04 - acc: 1.0000 - val_loss: 9.0099e-04 - val_acc: 1.0000\n",
      "Epoch 137/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.1805e-04 - acc: 1.0000 - val_loss: 5.2441e-04 - val_acc: 1.0000\n",
      "Epoch 138/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0096 - acc: 0.9987 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 139/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 140/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.5494e-04 - acc: 1.0000 - val_loss: 4.1442e-04 - val_acc: 1.0000\n",
      "Epoch 141/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 1.4662e-04 - acc: 1.0000 - val_loss: 2.6886e-04 - val_acc: 1.0000\n",
      "Epoch 142/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.0724e-04 - acc: 1.0000 - val_loss: 1.1860e-04 - val_acc: 1.0000\n",
      "Epoch 143/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.8693e-05 - acc: 1.0000 - val_loss: 1.4568e-04 - val_acc: 1.0000\n",
      "Epoch 144/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0095 - acc: 0.9965 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 145/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.0088e-04 - acc: 1.0000 - val_loss: 7.4882e-05 - val_acc: 1.0000\n",
      "Epoch 146/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0258 - acc: 0.9926 - val_loss: 0.0218 - val_acc: 0.9938\n",
      "Epoch 147/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0332 - acc: 0.9939 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 148/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0143 - acc: 0.9978 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 149/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0230 - acc: 0.9957 - val_loss: 3.8335e-04 - val_acc: 1.0000\n",
      "Epoch 150/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0136 - acc: 0.9974 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 151/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0052 - acc: 0.9996 - val_loss: 6.2395e-04 - val_acc: 1.0000\n",
      "Epoch 152/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0110 - acc: 0.9978 - val_loss: 6.0556e-04 - val_acc: 1.0000\n",
      "Epoch 153/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0548 - val_acc: 0.9906\n",
      "Epoch 154/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0081 - acc: 0.9983 - val_loss: 4.9513e-04 - val_acc: 1.0000\n",
      "Epoch 155/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0132 - acc: 0.9978 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 156/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0080 - acc: 0.9987 - val_loss: 8.0425e-04 - val_acc: 1.0000\n",
      "Epoch 157/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0080 - acc: 0.9987 - val_loss: 8.9414e-04 - val_acc: 1.0000\n",
      "Epoch 158/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0099 - acc: 0.9983 - val_loss: 7.6348e-04 - val_acc: 1.0000\n",
      "Epoch 159/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0079 - acc: 0.9983 - val_loss: 3.9422e-04 - val_acc: 1.0000\n",
      "Epoch 160/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0104 - acc: 0.9983 - val_loss: 4.4388e-04 - val_acc: 1.0000\n",
      "Epoch 161/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 7.7553e-04 - acc: 1.0000 - val_loss: 2.5880e-04 - val_acc: 1.0000\n",
      "Epoch 162/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0058 - acc: 0.9991 - val_loss: 2.7396e-04 - val_acc: 1.0000\n",
      "Epoch 163/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.4055e-04 - acc: 1.0000 - val_loss: 1.9562e-04 - val_acc: 1.0000\n",
      "Epoch 164/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0056 - acc: 0.9991 - val_loss: 4.0598e-04 - val_acc: 1.0000\n",
      "Epoch 165/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0079 - acc: 0.9987 - val_loss: 2.1290e-04 - val_acc: 1.0000\n",
      "Epoch 166/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0029 - acc: 0.9996 - val_loss: 1.9289e-04 - val_acc: 1.0000\n",
      "Epoch 167/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0083 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 168/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0089 - acc: 0.9978 - val_loss: 2.4131e-04 - val_acc: 1.0000\n",
      "Epoch 169/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 170/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 9.1407e-04 - acc: 1.0000 - val_loss: 7.7501e-05 - val_acc: 1.0000\n",
      "Epoch 171/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 9.8259e-05 - val_acc: 1.0000\n",
      "Epoch 172/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 3.0430e-04 - val_acc: 1.0000\n",
      "Epoch 173/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0043 - acc: 0.9991 - val_loss: 4.1674e-05 - val_acc: 1.0000\n",
      "Epoch 174/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.9316e-04 - acc: 1.0000 - val_loss: 6.0013e-05 - val_acc: 1.0000\n",
      "Epoch 175/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 7.4897e-05 - val_acc: 1.0000\n",
      "Epoch 176/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.9393e-04 - acc: 1.0000 - val_loss: 3.6047e-05 - val_acc: 1.0000\n",
      "Epoch 177/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.7218e-04 - acc: 1.0000 - val_loss: 1.9840e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.3887e-04 - acc: 1.0000 - val_loss: 2.0166e-05 - val_acc: 1.0000\n",
      "Epoch 179/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.5950e-04 - acc: 1.0000 - val_loss: 1.4165e-05 - val_acc: 1.0000\n",
      "Epoch 180/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 8.7409e-05 - acc: 1.0000 - val_loss: 1.6077e-05 - val_acc: 1.0000\n",
      "Epoch 181/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 6.9981e-05 - acc: 1.0000 - val_loss: 1.4638e-05 - val_acc: 1.0000\n",
      "Epoch 182/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0038 - acc: 0.9996 - val_loss: 1.8894e-05 - val_acc: 1.0000\n",
      "Epoch 183/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.3926e-04 - acc: 1.0000 - val_loss: 1.8796e-05 - val_acc: 1.0000\n",
      "Epoch 184/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.6512e-04 - acc: 1.0000 - val_loss: 5.0124e-05 - val_acc: 1.0000\n",
      "Epoch 185/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0049 - acc: 0.9983 - val_loss: 1.0580e-04 - val_acc: 1.0000\n",
      "Epoch 186/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 1.3040e-04 - val_acc: 1.0000\n",
      "Epoch 187/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 1.9266e-04 - acc: 1.0000 - val_loss: 2.8176e-05 - val_acc: 1.0000\n",
      "Epoch 188/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 9.6612e-05 - acc: 1.0000 - val_loss: 2.4617e-05 - val_acc: 1.0000\n",
      "Epoch 189/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.0250e-05 - acc: 1.0000 - val_loss: 2.2337e-05 - val_acc: 1.0000\n",
      "Epoch 190/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0034 - acc: 0.9996 - val_loss: 4.5022e-05 - val_acc: 1.0000\n",
      "Epoch 191/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 5.9745e-05 - val_acc: 1.0000\n",
      "Epoch 192/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.9530e-04 - acc: 1.0000 - val_loss: 3.4351e-05 - val_acc: 1.0000\n",
      "Epoch 193/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9978 - val_loss: 4.8795e-05 - val_acc: 1.0000\n",
      "Epoch 194/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.4373e-05 - acc: 1.0000 - val_loss: 2.0309e-05 - val_acc: 1.0000\n",
      "Epoch 195/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0240 - val_acc: 0.9938\n",
      "Epoch 196/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0150 - acc: 0.9970 - val_loss: 3.6594e-04 - val_acc: 1.0000\n",
      "Epoch 197/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 1.4472e-04 - val_acc: 1.0000\n",
      "Epoch 198/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0038 - acc: 0.9996 - val_loss: 2.0018e-04 - val_acc: 1.0000\n",
      "Epoch 199/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.3984e-04 - acc: 1.0000 - val_loss: 8.5330e-05 - val_acc: 1.0000\n",
      "Epoch 200/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 2.3184e-05 - val_acc: 1.0000\n",
      "Epoch 201/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0108 - acc: 0.9974 - val_loss: 1.4816e-04 - val_acc: 1.0000\n",
      "Epoch 202/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0050 - acc: 0.9991 - val_loss: 1.2332e-04 - val_acc: 1.0000\n",
      "Epoch 203/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0098 - acc: 0.9987 - val_loss: 3.9545e-04 - val_acc: 1.0000\n",
      "Epoch 204/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 1.1392e-04 - val_acc: 1.0000\n",
      "Epoch 205/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0127 - acc: 0.9957 - val_loss: 5.0386e-04 - val_acc: 1.0000\n",
      "Epoch 206/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0060 - acc: 0.9987 - val_loss: 2.5675e-04 - val_acc: 1.0000\n",
      "Epoch 207/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.7490e-04 - acc: 1.0000 - val_loss: 1.6184e-04 - val_acc: 1.0000\n",
      "Epoch 208/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 3.5839e-04 - val_acc: 1.0000\n",
      "Epoch 209/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 1.9868e-04 - val_acc: 1.0000\n",
      "Epoch 210/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.3581e-04 - acc: 1.0000 - val_loss: 1.0764e-04 - val_acc: 1.0000\n",
      "Epoch 211/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0071 - acc: 0.9974 - val_loss: 5.9985e-05 - val_acc: 1.0000\n",
      "Epoch 212/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0106 - acc: 0.9978 - val_loss: 4.1320e-04 - val_acc: 1.0000\n",
      "Epoch 213/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 5.4022e-04 - acc: 1.0000 - val_loss: 2.9711e-04 - val_acc: 1.0000\n",
      "Epoch 214/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 1.3042e-04 - val_acc: 1.0000\n",
      "Epoch 215/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.3401e-04 - acc: 1.0000 - val_loss: 8.7141e-05 - val_acc: 1.0000\n",
      "Epoch 216/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 7.8246e-04 - acc: 1.0000 - val_loss: 5.9384e-05 - val_acc: 1.0000\n",
      "Epoch 217/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0109 - acc: 0.9974 - val_loss: 1.1710e-04 - val_acc: 1.0000\n",
      "Epoch 218/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0056 - acc: 0.9987 - val_loss: 2.7569e-04 - val_acc: 1.0000\n",
      "Epoch 219/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 4.1559e-04 - acc: 1.0000 - val_loss: 1.1992e-04 - val_acc: 1.0000\n",
      "Epoch 220/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0136 - acc: 0.9983 - val_loss: 5.1497e-04 - val_acc: 1.0000\n",
      "Epoch 221/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0077 - acc: 0.9987 - val_loss: 4.1368e-04 - val_acc: 1.0000\n",
      "Epoch 222/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.4074e-04 - acc: 1.0000 - val_loss: 1.7418e-04 - val_acc: 1.0000\n",
      "Epoch 223/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 1.3261e-04 - val_acc: 1.0000\n",
      "Epoch 224/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 5.5540e-04 - acc: 1.0000 - val_loss: 1.0974e-04 - val_acc: 1.0000\n",
      "Epoch 225/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0217 - acc: 0.9952 - val_loss: 4.7870e-04 - val_acc: 1.0000\n",
      "Epoch 226/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0265 - acc: 0.9944 - val_loss: 1.2744e-04 - val_acc: 1.0000\n",
      "Epoch 227/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0055 - acc: 0.9991 - val_loss: 1.6594e-04 - val_acc: 1.0000\n",
      "Epoch 228/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 1.1702e-04 - val_acc: 1.0000\n",
      "Epoch 229/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0104 - acc: 0.9978 - val_loss: 2.0245e-04 - val_acc: 1.0000\n",
      "Epoch 230/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0100 - acc: 0.9974 - val_loss: 1.9620e-04 - val_acc: 1.0000\n",
      "Epoch 231/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 1.1715e-04 - val_acc: 1.0000\n",
      "Epoch 232/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0063 - acc: 0.9987 - val_loss: 2.8499e-04 - val_acc: 1.0000\n",
      "Epoch 233/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0073 - acc: 0.9987 - val_loss: 2.4050e-04 - val_acc: 1.0000\n",
      "Epoch 234/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 1.5891e-04 - val_acc: 1.0000\n",
      "Epoch 235/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0063 - acc: 0.9987 - val_loss: 8.1896e-05 - val_acc: 1.0000\n",
      "Epoch 236/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0077 - acc: 0.9974 - val_loss: 2.3312e-04 - val_acc: 1.0000\n",
      "Epoch 237/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0065 - acc: 0.9987 - val_loss: 2.3324e-04 - val_acc: 1.0000\n",
      "Epoch 238/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0049 - acc: 0.9991 - val_loss: 1.2731e-04 - val_acc: 1.0000\n",
      "Epoch 239/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 1.1574e-04 - val_acc: 1.0000\n",
      "Epoch 240/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0066 - acc: 0.9987 - val_loss: 1.2274e-04 - val_acc: 1.0000\n",
      "Epoch 241/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.9987 - val_loss: 1.5246e-04 - val_acc: 1.0000\n",
      "Epoch 242/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 7.7192e-05 - val_acc: 1.0000\n",
      "Epoch 243/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 6.0944e-05 - val_acc: 1.0000\n",
      "Epoch 244/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.5729e-04 - acc: 1.0000 - val_loss: 2.7710e-05 - val_acc: 1.0000\n",
      "Epoch 245/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0096 - acc: 0.9987 - val_loss: 2.5358e-04 - val_acc: 1.0000\n",
      "Epoch 246/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.4822e-04 - acc: 1.0000 - val_loss: 6.1890e-05 - val_acc: 1.0000\n",
      "Epoch 247/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 6.4197e-04 - acc: 1.0000 - val_loss: 1.1904e-05 - val_acc: 1.0000\n",
      "Epoch 248/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 3.3664e-05 - val_acc: 1.0000\n",
      "Epoch 249/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 4.0235e-05 - val_acc: 1.0000\n",
      "Epoch 250/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0087 - acc: 0.9983 - val_loss: 1.0296e-04 - val_acc: 1.0000\n",
      "Epoch 251/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0064 - acc: 0.9987 - val_loss: 6.2577e-05 - val_acc: 1.0000\n",
      "Epoch 252/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 5.1653e-05 - val_acc: 1.0000\n",
      "Epoch 253/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0052 - acc: 0.9991 - val_loss: 7.6588e-05 - val_acc: 1.0000\n",
      "Epoch 254/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.9473e-04 - acc: 1.0000 - val_loss: 3.6395e-05 - val_acc: 1.0000\n",
      "Epoch 255/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 7.4417e-05 - val_acc: 1.0000\n",
      "Epoch 256/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.3160e-04 - acc: 1.0000 - val_loss: 4.1895e-05 - val_acc: 1.0000\n",
      "Epoch 257/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.6339e-04 - acc: 1.0000 - val_loss: 2.4097e-05 - val_acc: 1.0000\n",
      "Epoch 258/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 2.8019e-05 - val_acc: 1.0000\n",
      "Epoch 259/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 5.8324e-05 - val_acc: 1.0000\n",
      "Epoch 260/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 2.8232e-05 - val_acc: 1.0000\n",
      "Epoch 261/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0061 - acc: 0.9987 - val_loss: 6.9286e-05 - val_acc: 1.0000\n",
      "Epoch 262/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0066 - acc: 0.9987 - val_loss: 6.0247e-05 - val_acc: 1.0000\n",
      "Epoch 263/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0096 - acc: 0.9974 - val_loss: 2.2650e-04 - val_acc: 1.0000\n",
      "Epoch 264/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9996 - val_loss: 8.2528e-05 - val_acc: 1.0000\n",
      "Epoch 265/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0143 - acc: 0.9970 - val_loss: 5.8093e-05 - val_acc: 1.0000\n",
      "Epoch 266/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0043 - acc: 0.9991 - val_loss: 5.7069e-05 - val_acc: 1.0000\n",
      "Epoch 267/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9983 - val_loss: 2.7534e-05 - val_acc: 1.0000\n",
      "Epoch 268/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.6619e-04 - acc: 1.0000 - val_loss: 3.2454e-05 - val_acc: 1.0000\n",
      "Epoch 269/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 6.5458e-05 - val_acc: 1.0000\n",
      "Epoch 270/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.8856e-04 - acc: 1.0000 - val_loss: 2.0735e-05 - val_acc: 1.0000\n",
      "Epoch 271/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0054 - acc: 0.9991 - val_loss: 4.1099e-05 - val_acc: 1.0000\n",
      "Epoch 272/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 5.3087e-04 - acc: 1.0000 - val_loss: 5.7266e-05 - val_acc: 1.0000\n",
      "Epoch 273/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0059 - acc: 0.9987 - val_loss: 6.3808e-05 - val_acc: 1.0000\n",
      "Epoch 274/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 3.3891e-04 - acc: 1.0000 - val_loss: 5.0045e-05 - val_acc: 1.0000\n",
      "Epoch 275/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 6.4937e-05 - val_acc: 1.0000\n",
      "Epoch 276/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.3677e-04 - acc: 1.0000 - val_loss: 6.0582e-05 - val_acc: 1.0000\n",
      "Epoch 277/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 8.7286e-05 - val_acc: 1.0000\n",
      "Epoch 278/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 4.8256e-04 - acc: 1.0000 - val_loss: 3.2708e-05 - val_acc: 1.0000\n",
      "Epoch 279/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0053 - acc: 0.9991 - val_loss: 5.9834e-05 - val_acc: 1.0000\n",
      "Epoch 280/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0057 - acc: 0.9987 - val_loss: 8.9888e-05 - val_acc: 1.0000\n",
      "Epoch 281/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0013 - acc: 0.9991 - val_loss: 2.2523e-04 - val_acc: 1.0000\n",
      "Epoch 282/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 4.3751e-05 - val_acc: 1.0000\n",
      "Epoch 283/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0146 - acc: 0.9952 - val_loss: 1.1342e-04 - val_acc: 1.0000\n",
      "Epoch 284/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 2.4945e-04 - val_acc: 1.0000\n",
      "Epoch 285/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 3.1074e-04 - val_acc: 1.0000\n",
      "Epoch 286/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 3.6818e-04 - val_acc: 1.0000\n",
      "Epoch 287/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0121 - acc: 0.9974 - val_loss: 1.3915e-04 - val_acc: 1.0000\n",
      "Epoch 288/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 1.3545e-04 - val_acc: 1.0000\n",
      "Epoch 289/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0080 - acc: 0.9961 - val_loss: 5.5719e-05 - val_acc: 1.0000\n",
      "Epoch 290/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0145 - acc: 0.9965 - val_loss: 4.3433e-04 - val_acc: 1.0000\n",
      "Epoch 291/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.1203e-04 - val_acc: 1.0000\n",
      "Epoch 292/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 6.0500e-04 - acc: 1.0000 - val_loss: 1.2166e-04 - val_acc: 1.0000\n",
      "Epoch 293/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0083 - acc: 0.9983 - val_loss: 2.9536e-04 - val_acc: 1.0000\n",
      "Epoch 294/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0077 - acc: 0.9978 - val_loss: 4.5367e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 1.5517e-04 - val_acc: 1.0000\n",
      "Epoch 296/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 1.0848e-04 - val_acc: 1.0000\n",
      "Epoch 297/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 1.0731e-04 - val_acc: 1.0000\n",
      "Epoch 298/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 6.9072e-05 - val_acc: 1.0000\n",
      "Epoch 299/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 8.7010e-05 - val_acc: 1.0000\n",
      "Epoch 300/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 5.3625e-04 - acc: 1.0000 - val_loss: 7.8395e-05 - val_acc: 1.0000\n",
      "Epoch 301/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 8.0650e-05 - val_acc: 1.0000\n",
      "Epoch 302/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 1.3565e-04 - val_acc: 1.0000\n",
      "Epoch 303/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 5.7310e-05 - val_acc: 1.0000\n",
      "Epoch 304/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.9276e-04 - acc: 1.0000 - val_loss: 4.5611e-05 - val_acc: 1.0000\n",
      "Epoch 305/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 4.7018e-05 - val_acc: 1.0000\n",
      "Epoch 306/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 4.4288e-05 - val_acc: 1.0000\n",
      "Epoch 307/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.8000e-04 - acc: 1.0000 - val_loss: 2.9809e-05 - val_acc: 1.0000\n",
      "Epoch 308/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0065 - acc: 0.9974 - val_loss: 2.0757e-04 - val_acc: 1.0000\n",
      "Epoch 309/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0173 - acc: 0.9957 - val_loss: 8.3465e-04 - val_acc: 1.0000\n",
      "Epoch 310/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 3.4658e-04 - val_acc: 1.0000\n",
      "Epoch 311/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0112 - acc: 0.9983 - val_loss: 4.9708e-04 - val_acc: 1.0000\n",
      "Epoch 312/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0081 - acc: 0.9978 - val_loss: 1.1582e-04 - val_acc: 1.0000\n",
      "Epoch 313/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0071 - acc: 0.9991 - val_loss: 1.8663e-04 - val_acc: 1.0000\n",
      "Epoch 314/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 1.0005e-04 - val_acc: 1.0000\n",
      "Epoch 315/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0078 - acc: 0.9983 - val_loss: 2.8207e-04 - val_acc: 1.0000\n",
      "Epoch 316/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9996 - val_loss: 2.6949e-04 - val_acc: 1.0000\n",
      "Epoch 317/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 1.0775e-04 - val_acc: 1.0000\n",
      "Epoch 318/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 1.4161e-04 - val_acc: 1.0000\n",
      "Epoch 319/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0029 - acc: 0.9996 - val_loss: 7.8563e-05 - val_acc: 1.0000\n",
      "Epoch 320/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 7.8752e-05 - val_acc: 1.0000\n",
      "Epoch 321/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.4671e-04 - acc: 1.0000 - val_loss: 6.1475e-05 - val_acc: 1.0000\n",
      "Epoch 322/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 3.9948e-05 - val_acc: 1.0000\n",
      "Epoch 323/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0112 - acc: 0.9974 - val_loss: 2.5889e-04 - val_acc: 1.0000\n",
      "Epoch 324/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 1.7126e-04 - val_acc: 1.0000\n",
      "Epoch 325/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 3.0399e-04 - val_acc: 1.0000\n",
      "Epoch 326/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 8.9758e-05 - val_acc: 1.0000\n",
      "Epoch 327/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 8.1149e-05 - val_acc: 1.0000\n",
      "Epoch 328/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0042 - acc: 0.9991 - val_loss: 2.4945e-04 - val_acc: 1.0000\n",
      "Epoch 329/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0068 - acc: 0.9978 - val_loss: 2.0538e-04 - val_acc: 1.0000\n",
      "Epoch 330/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 7.9356e-04 - acc: 1.0000 - val_loss: 1.6373e-04 - val_acc: 1.0000\n",
      "Epoch 331/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 4.2007e-04 - val_acc: 1.0000\n",
      "Epoch 332/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 8.1688e-04 - acc: 1.0000 - val_loss: 8.9123e-05 - val_acc: 1.0000\n",
      "Epoch 333/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 7.5479e-04 - acc: 0.9996 - val_loss: 1.5984e-04 - val_acc: 1.0000\n",
      "Epoch 334/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 1.8478e-04 - val_acc: 1.0000\n",
      "Epoch 335/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0047 - acc: 0.9978 - val_loss: 8.3986e-05 - val_acc: 1.0000\n",
      "Epoch 336/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0053 - acc: 0.9987 - val_loss: 7.6543e-05 - val_acc: 1.0000\n",
      "Epoch 337/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 7.4751e-05 - val_acc: 1.0000\n",
      "Epoch 338/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 1.9339e-04 - val_acc: 1.0000\n",
      "Epoch 339/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 1.2606e-04 - val_acc: 1.0000\n",
      "Epoch 340/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 3.9811e-04 - acc: 1.0000 - val_loss: 1.0075e-04 - val_acc: 1.0000\n",
      "Epoch 341/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 1.0295e-04 - val_acc: 1.0000\n",
      "Epoch 342/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 6.9695e-05 - val_acc: 1.0000\n",
      "Epoch 343/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.2919e-04 - acc: 1.0000 - val_loss: 4.7547e-05 - val_acc: 1.0000\n",
      "Epoch 344/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0036 - acc: 0.9996 - val_loss: 7.0460e-05 - val_acc: 1.0000\n",
      "Epoch 345/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 7.3373e-05 - val_acc: 1.0000\n",
      "Epoch 346/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 8.9382e-05 - val_acc: 1.0000\n",
      "Epoch 347/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 5.8283e-05 - val_acc: 1.0000\n",
      "Epoch 348/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0137 - acc: 0.9983 - val_loss: 7.8847e-05 - val_acc: 1.0000\n",
      "Epoch 349/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 3.3519e-05 - val_acc: 1.0000\n",
      "Epoch 350/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 6.2153e-04 - acc: 1.0000 - val_loss: 3.5047e-05 - val_acc: 1.0000\n",
      "Epoch 351/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 5.0418e-04 - acc: 1.0000 - val_loss: 2.7863e-05 - val_acc: 1.0000\n",
      "Epoch 352/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 3.8653e-05 - val_acc: 1.0000\n",
      "Epoch 353/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 3.8259e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 4.5447e-04 - acc: 1.0000 - val_loss: 2.2299e-05 - val_acc: 1.0000\n",
      "Epoch 355/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 1.8913e-05 - val_acc: 1.0000\n",
      "Epoch 356/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 2.3175e-05 - val_acc: 1.0000\n",
      "Epoch 357/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 6.3332e-04 - acc: 1.0000 - val_loss: 1.6792e-05 - val_acc: 1.0000\n",
      "Epoch 358/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 7.8517e-05 - val_acc: 1.0000\n",
      "Epoch 359/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0022 - acc: 0.9987 - val_loss: 2.0277e-04 - val_acc: 1.0000\n",
      "Epoch 360/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 1.0130e-04 - val_acc: 1.0000\n",
      "Epoch 361/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 8.1662e-05 - val_acc: 1.0000\n",
      "Epoch 362/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 1.4770e-05 - val_acc: 1.0000\n",
      "Epoch 363/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.2062e-04 - acc: 0.9996 - val_loss: 9.8684e-06 - val_acc: 1.0000\n",
      "Epoch 364/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 7.0050e-06 - val_acc: 1.0000\n",
      "Epoch 365/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 1.8761e-05 - val_acc: 1.0000\n",
      "Epoch 366/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 1.9832e-05 - val_acc: 1.0000\n",
      "Epoch 367/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 4.1342e-05 - val_acc: 1.0000\n",
      "Epoch 368/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 3.0668e-05 - val_acc: 1.0000\n",
      "Epoch 369/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 3.9660e-05 - val_acc: 1.0000\n",
      "Epoch 370/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 4.9034e-04 - acc: 0.9996 - val_loss: 1.9389e-05 - val_acc: 1.0000\n",
      "Epoch 371/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.4348e-05 - acc: 1.0000 - val_loss: 1.3859e-05 - val_acc: 1.0000\n",
      "Epoch 372/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.7556e-04 - acc: 1.0000 - val_loss: 1.4917e-05 - val_acc: 1.0000\n",
      "Epoch 373/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.1147e-05 - acc: 1.0000 - val_loss: 9.6852e-06 - val_acc: 1.0000\n",
      "Epoch 374/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.7969e-05 - acc: 1.0000 - val_loss: 7.8493e-06 - val_acc: 1.0000\n",
      "Epoch 375/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 1.5462e-05 - val_acc: 1.0000\n",
      "Epoch 376/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 1.9045e-05 - val_acc: 1.0000\n",
      "Epoch 377/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5146e-04 - acc: 1.0000 - val_loss: 1.3830e-05 - val_acc: 1.0000\n",
      "Epoch 378/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0068 - acc: 0.9978 - val_loss: 2.3051e-05 - val_acc: 1.0000\n",
      "Epoch 379/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0167 - acc: 0.9961 - val_loss: 2.0079e-04 - val_acc: 1.0000\n",
      "Epoch 380/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0113 - acc: 0.9974 - val_loss: 1.7477e-04 - val_acc: 1.0000\n",
      "Epoch 381/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 2.0864e-04 - val_acc: 1.0000\n",
      "Epoch 382/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0029 - acc: 0.9987 - val_loss: 8.3955e-05 - val_acc: 1.0000\n",
      "Epoch 383/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 6.2805e-04 - val_acc: 1.0000\n",
      "Epoch 384/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0035 - acc: 0.9987 - val_loss: 9.1478e-05 - val_acc: 1.0000\n",
      "Epoch 385/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9987 - val_loss: 8.6495e-05 - val_acc: 1.0000\n",
      "Epoch 386/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 9.7361e-05 - val_acc: 1.0000\n",
      "Epoch 387/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.7928e-04 - acc: 1.0000 - val_loss: 1.1055e-04 - val_acc: 1.0000\n",
      "Epoch 388/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0069 - acc: 0.9978 - val_loss: 2.5006e-04 - val_acc: 1.0000\n",
      "Epoch 389/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0120 - acc: 0.9957 - val_loss: 2.5041e-04 - val_acc: 1.0000\n",
      "Epoch 390/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0034 - acc: 0.9974 - val_loss: 1.4188e-04 - val_acc: 1.0000\n",
      "Epoch 391/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0049 - acc: 0.9974 - val_loss: 1.0795e-04 - val_acc: 1.0000\n",
      "Epoch 392/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0031 - acc: 0.9987 - val_loss: 6.5906e-05 - val_acc: 1.0000\n",
      "Epoch 393/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0033 - acc: 0.9987 - val_loss: 5.2406e-05 - val_acc: 1.0000\n",
      "Epoch 394/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 5.8557e-05 - val_acc: 1.0000\n",
      "Epoch 395/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0050 - acc: 0.9983 - val_loss: 5.6255e-05 - val_acc: 1.0000\n",
      "Epoch 396/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 8.2856e-05 - val_acc: 1.0000\n",
      "Epoch 397/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 9.6369e-05 - val_acc: 1.0000\n",
      "Epoch 398/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0044 - acc: 0.9970 - val_loss: 5.7813e-05 - val_acc: 1.0000\n",
      "Epoch 399/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0084 - acc: 0.9987 - val_loss: 1.1204e-04 - val_acc: 1.0000\n",
      "Epoch 400/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 6.4057e-04 - acc: 0.9996 - val_loss: 3.1639e-05 - val_acc: 1.0000\n",
      "Epoch 401/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 1.2650e-05 - val_acc: 1.0000\n",
      "Epoch 402/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 2.5809e-05 - val_acc: 1.0000\n",
      "Epoch 403/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 404/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 1.2794e-04 - val_acc: 1.0000\n",
      "Epoch 405/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0094 - acc: 0.9987 - val_loss: 9.1448e-05 - val_acc: 1.0000\n",
      "Epoch 406/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 2.7552e-05 - val_acc: 1.0000\n",
      "Epoch 407/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 7.8252e-04 - acc: 0.9996 - val_loss: 2.6423e-05 - val_acc: 1.0000\n",
      "Epoch 408/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 3.3630e-05 - val_acc: 1.0000\n",
      "Epoch 409/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 2.6044e-04 - acc: 1.0000 - val_loss: 2.9262e-05 - val_acc: 1.0000\n",
      "Epoch 410/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.8579e-04 - acc: 1.0000 - val_loss: 4.7412e-05 - val_acc: 1.0000\n",
      "Epoch 411/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 3.4593e-04 - acc: 1.0000 - val_loss: 3.1944e-05 - val_acc: 1.0000\n",
      "Epoch 412/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 1.5183e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 1.9532e-05 - val_acc: 1.0000\n",
      "Epoch 414/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 4.8122e-04 - acc: 1.0000 - val_loss: 9.5800e-06 - val_acc: 1.0000\n",
      "Epoch 415/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0031 - acc: 0.9983 - val_loss: 1.5337e-05 - val_acc: 1.0000\n",
      "Epoch 416/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 2.5808e-04 - acc: 1.0000 - val_loss: 1.1305e-05 - val_acc: 1.0000\n",
      "Epoch 417/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 5.1420e-04 - acc: 0.9996 - val_loss: 7.6545e-06 - val_acc: 1.0000\n",
      "Epoch 418/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 1.3385e-05 - val_acc: 1.0000\n",
      "Epoch 419/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 9.6444e-04 - acc: 0.9996 - val_loss: 1.6717e-05 - val_acc: 1.0000\n",
      "Epoch 420/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 2.1243e-05 - val_acc: 1.0000\n",
      "Epoch 421/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.0693e-04 - acc: 0.9996 - val_loss: 4.4484e-06 - val_acc: 1.0000\n",
      "Epoch 422/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 1.9631e-05 - val_acc: 1.0000\n",
      "Epoch 423/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 2.9962e-05 - val_acc: 1.0000\n",
      "Epoch 424/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.2636e-04 - acc: 1.0000 - val_loss: 3.9011e-05 - val_acc: 1.0000\n",
      "Epoch 425/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5388e-04 - acc: 1.0000 - val_loss: 1.7824e-05 - val_acc: 1.0000\n",
      "Epoch 426/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0091 - acc: 0.9978 - val_loss: 1.7800e-05 - val_acc: 1.0000\n",
      "Epoch 427/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0053 - acc: 0.9991 - val_loss: 3.3187e-04 - val_acc: 1.0000\n",
      "Epoch 428/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0052 - acc: 0.9970 - val_loss: 7.1496e-05 - val_acc: 1.0000\n",
      "Epoch 429/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 0.9987 - val_loss: 4.4697e-05 - val_acc: 1.0000\n",
      "Epoch 430/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 8.4500e-05 - val_acc: 1.0000\n",
      "Epoch 431/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0044 - acc: 0.9978 - val_loss: 1.0925e-04 - val_acc: 1.0000\n",
      "Epoch 432/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0047 - acc: 0.9983 - val_loss: 2.4295e-05 - val_acc: 1.0000\n",
      "Epoch 433/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 3.0972e-05 - val_acc: 1.0000\n",
      "Epoch 434/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 3.7287e-05 - val_acc: 1.0000\n",
      "Epoch 435/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 3.8382e-05 - val_acc: 1.0000\n",
      "Epoch 436/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9987 - val_loss: 2.5442e-05 - val_acc: 1.0000\n",
      "Epoch 437/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0039 - acc: 0.9983 - val_loss: 2.8724e-05 - val_acc: 1.0000\n",
      "Epoch 438/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9987 - val_loss: 5.4892e-05 - val_acc: 1.0000\n",
      "Epoch 439/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0047 - acc: 0.9970 - val_loss: 2.7660e-05 - val_acc: 1.0000\n",
      "Epoch 440/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0084 - acc: 0.9965 - val_loss: 1.3198e-05 - val_acc: 1.0000\n",
      "Epoch 441/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9978 - val_loss: 5.2997e-05 - val_acc: 1.0000\n",
      "Epoch 442/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0029 - acc: 0.9983 - val_loss: 8.8623e-05 - val_acc: 1.0000\n",
      "Epoch 443/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 7.9241e-05 - val_acc: 1.0000\n",
      "Epoch 444/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 1.5708e-04 - val_acc: 1.0000\n",
      "Epoch 445/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 4.9050e-05 - val_acc: 1.0000\n",
      "Epoch 446/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 8.1983e-05 - val_acc: 1.0000\n",
      "Epoch 447/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 5.3322e-05 - val_acc: 1.0000\n",
      "Epoch 448/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9983 - val_loss: 3.1979e-05 - val_acc: 1.0000\n",
      "Epoch 449/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 1.3915e-05 - val_acc: 1.0000\n",
      "Epoch 450/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0015 - acc: 0.9991 - val_loss: 1.4487e-05 - val_acc: 1.0000\n",
      "Epoch 451/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0053 - acc: 0.9978 - val_loss: 5.5059e-05 - val_acc: 1.0000\n",
      "Epoch 452/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0020 - acc: 0.9987 - val_loss: 2.9966e-05 - val_acc: 1.0000\n",
      "Epoch 453/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 4.4704e-05 - val_acc: 1.0000\n",
      "Epoch 454/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 7.0237e-04 - acc: 0.9996 - val_loss: 4.1647e-05 - val_acc: 1.0000\n",
      "Epoch 455/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0028 - acc: 0.9983 - val_loss: 4.2526e-05 - val_acc: 1.0000\n",
      "Epoch 456/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0036 - acc: 0.9983 - val_loss: 4.1434e-05 - val_acc: 1.0000\n",
      "Epoch 457/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0026 - acc: 0.9983 - val_loss: 6.7194e-05 - val_acc: 1.0000\n",
      "Epoch 458/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 1.3785e-05 - val_acc: 1.0000\n",
      "Epoch 459/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 8.1953e-04 - acc: 0.9996 - val_loss: 5.9828e-05 - val_acc: 1.0000\n",
      "Epoch 460/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0070 - acc: 0.9961 - val_loss: 7.0051e-05 - val_acc: 1.0000\n",
      "Epoch 461/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0062 - acc: 0.9965 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 462/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0016 - acc: 0.9987 - val_loss: 4.4869e-05 - val_acc: 1.0000\n",
      "Epoch 463/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0033 - acc: 0.9983 - val_loss: 8.2587e-05 - val_acc: 1.0000\n",
      "Epoch 464/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0029 - acc: 0.9978 - val_loss: 7.4651e-05 - val_acc: 1.0000\n",
      "Epoch 465/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0085 - acc: 0.9991 - val_loss: 2.9530e-05 - val_acc: 1.0000\n",
      "Epoch 466/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0040 - acc: 0.9983 - val_loss: 8.6328e-05 - val_acc: 1.0000\n",
      "Epoch 467/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0023 - acc: 0.9978 - val_loss: 2.4291e-04 - val_acc: 1.0000\n",
      "Epoch 468/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.1620e-04 - val_acc: 1.0000\n",
      "Epoch 469/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 8.3828e-05 - val_acc: 1.0000\n",
      "Epoch 470/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 3.0503e-04 - acc: 1.0000 - val_loss: 7.6506e-05 - val_acc: 1.0000\n",
      "Epoch 471/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0044 - acc: 0.9974 - val_loss: 1.1119e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0051 - acc: 0.9970 - val_loss: 6.7559e-05 - val_acc: 1.0000\n",
      "Epoch 473/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 1.3947e-04 - val_acc: 1.0000\n",
      "Epoch 474/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0019 - acc: 0.9987 - val_loss: 7.6725e-05 - val_acc: 1.0000\n",
      "Epoch 475/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 4.7394e-05 - val_acc: 1.0000\n",
      "Epoch 476/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0037 - acc: 0.9978 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 477/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0129 - acc: 0.9957 - val_loss: 4.9381e-05 - val_acc: 1.0000\n",
      "Epoch 478/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 1.1445e-04 - val_acc: 1.0000\n",
      "Epoch 479/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 1.5903e-04 - val_acc: 1.0000\n",
      "Epoch 480/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0018 - acc: 0.9987 - val_loss: 1.1408e-04 - val_acc: 1.0000\n",
      "Epoch 481/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0033 - acc: 0.9978 - val_loss: 5.6078e-05 - val_acc: 1.0000\n",
      "Epoch 482/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0038 - acc: 0.9983 - val_loss: 8.6684e-05 - val_acc: 1.0000\n",
      "Epoch 483/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 1.2081e-04 - val_acc: 1.0000\n",
      "Epoch 484/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 8.1910e-05 - val_acc: 1.0000\n",
      "Epoch 485/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0063 - acc: 0.9970 - val_loss: 1.9993e-04 - val_acc: 1.0000\n",
      "Epoch 486/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0035 - acc: 0.9983 - val_loss: 5.7686e-05 - val_acc: 1.0000\n",
      "Epoch 487/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 7.7142e-05 - val_acc: 1.0000\n",
      "Epoch 488/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0024 - acc: 0.9987 - val_loss: 6.0691e-05 - val_acc: 1.0000\n",
      "Epoch 489/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0039 - acc: 0.9983 - val_loss: 7.0901e-05 - val_acc: 1.0000\n",
      "Epoch 490/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 5.5339e-05 - val_acc: 1.0000\n",
      "Epoch 491/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 5.3028e-05 - val_acc: 1.0000\n",
      "Epoch 492/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.2095e-04 - acc: 1.0000 - val_loss: 6.8402e-05 - val_acc: 1.0000\n",
      "Epoch 493/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 3.4956e-05 - val_acc: 1.0000\n",
      "Epoch 494/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 4.0806e-05 - val_acc: 1.0000\n",
      "Epoch 495/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9983 - val_loss: 2.7411e-05 - val_acc: 1.0000\n",
      "Epoch 496/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.2630e-04 - acc: 0.9996 - val_loss: 2.8396e-05 - val_acc: 1.0000\n",
      "Epoch 497/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 5.0846e-05 - val_acc: 1.0000\n",
      "Epoch 498/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0049 - acc: 0.9974 - val_loss: 1.0417e-04 - val_acc: 1.0000\n",
      "Epoch 499/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 5.6653e-05 - val_acc: 1.0000\n",
      "Epoch 500/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0021 - acc: 0.9987 - val_loss: 2.9629e-05 - val_acc: 1.0000\n",
      "Epoch 501/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 1.0775e-04 - val_acc: 1.0000\n",
      "Epoch 502/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 8.3406e-05 - val_acc: 1.0000\n",
      "Epoch 503/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9987 - val_loss: 2.5386e-05 - val_acc: 1.0000\n",
      "Epoch 504/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 4.8106e-05 - val_acc: 1.0000\n",
      "Epoch 505/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 9.0950e-05 - val_acc: 1.0000\n",
      "Epoch 506/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0086 - acc: 0.9978 - val_loss: 4.5748e-05 - val_acc: 1.0000\n",
      "Epoch 507/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0067 - acc: 0.9974 - val_loss: 1.0724e-04 - val_acc: 1.0000\n",
      "Epoch 508/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0043 - acc: 0.9978 - val_loss: 2.3335e-05 - val_acc: 1.0000\n",
      "Epoch 509/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0034 - acc: 0.9983 - val_loss: 4.5156e-05 - val_acc: 1.0000\n",
      "Epoch 510/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 8.4534e-04 - acc: 1.0000 - val_loss: 5.7221e-05 - val_acc: 1.0000\n",
      "Epoch 511/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 4.1553e-05 - val_acc: 1.0000\n",
      "Epoch 512/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0031 - acc: 0.9978 - val_loss: 4.6083e-05 - val_acc: 1.0000\n",
      "Epoch 513/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 3.2350e-05 - val_acc: 1.0000\n",
      "Epoch 514/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 6.8848e-04 - acc: 0.9996 - val_loss: 3.9458e-05 - val_acc: 1.0000\n",
      "Epoch 515/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0012 - acc: 0.9991 - val_loss: 4.0500e-05 - val_acc: 1.0000\n",
      "Epoch 516/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 2.6915e-05 - val_acc: 1.0000\n",
      "Epoch 517/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0013 - acc: 0.9991 - val_loss: 3.7808e-05 - val_acc: 1.0000\n",
      "Epoch 518/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0038 - acc: 0.9978 - val_loss: 2.1647e-05 - val_acc: 1.0000\n",
      "Epoch 519/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0044 - acc: 0.9978 - val_loss: 6.1599e-05 - val_acc: 1.0000\n",
      "Epoch 520/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 2.5032e-05 - val_acc: 1.0000\n",
      "Epoch 521/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0011 - acc: 0.9991 - val_loss: 3.3515e-05 - val_acc: 1.0000\n",
      "Epoch 522/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 8.1487e-04 - acc: 0.9996 - val_loss: 1.4264e-05 - val_acc: 1.0000\n",
      "Epoch 523/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.1688e-04 - acc: 1.0000 - val_loss: 1.1019e-05 - val_acc: 1.0000\n",
      "Epoch 524/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 1.9490e-04 - val_acc: 1.0000\n",
      "Epoch 525/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 2.7367e-05 - val_acc: 1.0000\n",
      "Epoch 526/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0026 - acc: 0.9983 - val_loss: 4.0276e-05 - val_acc: 1.0000\n",
      "Epoch 527/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0030 - acc: 0.9983 - val_loss: 3.9753e-05 - val_acc: 1.0000\n",
      "Epoch 528/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 8.7881e-05 - val_acc: 1.0000\n",
      "Epoch 529/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 6.2802e-05 - val_acc: 1.0000\n",
      "Epoch 530/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0027 - acc: 0.9987 - val_loss: 3.8617e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 7.4824e-04 - acc: 1.0000 - val_loss: 3.9731e-05 - val_acc: 1.0000\n",
      "Epoch 532/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0012 - acc: 0.9991 - val_loss: 9.6486e-05 - val_acc: 1.0000\n",
      "Epoch 533/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0065 - acc: 0.9961 - val_loss: 1.1354e-05 - val_acc: 1.0000\n",
      "Epoch 534/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0047 - acc: 0.9974 - val_loss: 8.8043e-05 - val_acc: 1.0000\n",
      "Epoch 535/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0035 - acc: 0.9983 - val_loss: 1.6504e-04 - val_acc: 1.0000\n",
      "Epoch 536/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0106 - acc: 0.9965 - val_loss: 1.2509e-05 - val_acc: 1.0000\n",
      "Epoch 537/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0146 - acc: 0.9952 - val_loss: 8.0503e-05 - val_acc: 1.0000\n",
      "Epoch 538/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 1.0375e-04 - val_acc: 1.0000\n",
      "Epoch 539/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0075 - acc: 0.9965 - val_loss: 1.6855e-04 - val_acc: 1.0000\n",
      "Epoch 540/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0044 - acc: 0.9983 - val_loss: 9.0504e-05 - val_acc: 1.0000\n",
      "Epoch 541/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 6.9492e-05 - val_acc: 1.0000\n",
      "Epoch 542/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0031 - acc: 0.9987 - val_loss: 3.4125e-04 - val_acc: 1.0000\n",
      "Epoch 543/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 2.6952e-04 - val_acc: 1.0000\n",
      "Epoch 544/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 1.1359e-04 - val_acc: 1.0000\n",
      "Epoch 545/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0041 - acc: 0.9983 - val_loss: 1.4865e-04 - val_acc: 1.0000\n",
      "Epoch 546/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0022 - acc: 0.9987 - val_loss: 1.7351e-04 - val_acc: 1.0000\n",
      "Epoch 547/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 8.5999e-05 - val_acc: 1.0000\n",
      "Epoch 548/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 1.0203e-04 - val_acc: 1.0000\n",
      "Epoch 549/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 1.0906e-04 - val_acc: 1.0000\n",
      "Epoch 550/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0069 - acc: 0.9983 - val_loss: 1.3611e-04 - val_acc: 1.0000\n",
      "Epoch 551/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0040 - acc: 0.9983 - val_loss: 4.6727e-05 - val_acc: 1.0000\n",
      "Epoch 552/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 9.3709e-05 - val_acc: 1.0000\n",
      "Epoch 553/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 7.7774e-05 - val_acc: 1.0000\n",
      "Epoch 554/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 5.9595e-05 - val_acc: 1.0000\n",
      "Epoch 555/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0041 - acc: 0.9978 - val_loss: 1.2454e-04 - val_acc: 1.0000\n",
      "Epoch 556/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.3347e-04 - acc: 0.9996 - val_loss: 8.7180e-05 - val_acc: 1.0000\n",
      "Epoch 557/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.3280e-04 - acc: 0.9996 - val_loss: 3.8542e-05 - val_acc: 1.0000\n",
      "Epoch 558/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0020 - acc: 0.9987 - val_loss: 8.0945e-05 - val_acc: 1.0000\n",
      "Epoch 559/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 1.6578e-05 - val_acc: 1.0000\n",
      "Epoch 560/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0063 - acc: 0.9965 - val_loss: 2.1566e-05 - val_acc: 1.0000\n",
      "Epoch 561/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.9991 - val_loss: 4.8994e-05 - val_acc: 1.0000\n",
      "Epoch 562/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.3393e-04 - acc: 0.9996 - val_loss: 1.0835e-04 - val_acc: 1.0000\n",
      "Epoch 563/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9978 - val_loss: 2.7197e-05 - val_acc: 1.0000\n",
      "Epoch 564/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 5.9842e-05 - val_acc: 1.0000\n",
      "Epoch 565/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 4.5461e-05 - val_acc: 1.0000\n",
      "Epoch 566/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0085 - acc: 0.9970 - val_loss: 6.4389e-05 - val_acc: 1.0000\n",
      "Epoch 567/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 1.7613e-04 - val_acc: 1.0000\n",
      "Epoch 568/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.3663e-04 - acc: 1.0000 - val_loss: 1.2696e-04 - val_acc: 1.0000\n",
      "Epoch 569/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 1.1511e-04 - val_acc: 1.0000\n",
      "Epoch 570/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0023 - acc: 0.9987 - val_loss: 3.9349e-05 - val_acc: 1.0000\n",
      "Epoch 571/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0021 - acc: 0.9987 - val_loss: 3.4816e-05 - val_acc: 1.0000\n",
      "Epoch 572/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 7.2274e-04 - acc: 0.9996 - val_loss: 2.7973e-05 - val_acc: 1.0000\n",
      "Epoch 573/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 3.5944e-05 - val_acc: 1.0000\n",
      "Epoch 574/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 5.8795e-05 - val_acc: 1.0000\n",
      "Epoch 575/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0023 - acc: 0.9983 - val_loss: 4.2990e-05 - val_acc: 1.0000\n",
      "Epoch 576/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.9536e-04 - acc: 0.9996 - val_loss: 1.4561e-05 - val_acc: 1.0000\n",
      "Epoch 577/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 4.6237e-05 - val_acc: 1.0000\n",
      "Epoch 578/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0023 - acc: 0.9987 - val_loss: 4.7298e-05 - val_acc: 1.0000\n",
      "Epoch 579/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0011 - acc: 0.9991 - val_loss: 3.1033e-05 - val_acc: 1.0000\n",
      "Epoch 580/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 8.2907e-04 - acc: 1.0000 - val_loss: 2.5265e-05 - val_acc: 1.0000\n",
      "Epoch 581/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 5.6127e-05 - val_acc: 1.0000\n",
      "Epoch 582/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 6.8502e-04 - acc: 0.9996 - val_loss: 1.5062e-04 - val_acc: 1.0000\n",
      "Epoch 583/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0012 - acc: 0.9991 - val_loss: 5.4663e-05 - val_acc: 1.0000\n",
      "Epoch 584/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0011 - acc: 0.9991 - val_loss: 4.7137e-05 - val_acc: 1.0000\n",
      "Epoch 585/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 7.8950e-05 - acc: 1.0000 - val_loss: 4.0493e-05 - val_acc: 1.0000\n",
      "Epoch 586/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0015 - acc: 0.9991 - val_loss: 2.4427e-05 - val_acc: 1.0000\n",
      "Epoch 587/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0012 - acc: 0.9991 - val_loss: 2.3060e-05 - val_acc: 1.0000\n",
      "Epoch 588/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 3.0275e-05 - val_acc: 1.0000\n",
      "Epoch 589/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 7.9495e-04 - acc: 0.9996 - val_loss: 4.0333e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 590/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0011 - acc: 0.9991 - val_loss: 6.7089e-05 - val_acc: 1.0000\n",
      "Epoch 591/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 2.2271e-04 - acc: 1.0000 - val_loss: 7.0098e-05 - val_acc: 1.0000\n",
      "Epoch 592/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0053 - acc: 0.9965 - val_loss: 6.1323e-05 - val_acc: 1.0000\n",
      "Epoch 593/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 2.4202e-05 - val_acc: 1.0000\n",
      "Epoch 594/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0030 - acc: 0.9983 - val_loss: 3.0126e-05 - val_acc: 1.0000\n",
      "Epoch 595/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 1.4684e-05 - val_acc: 1.0000\n",
      "Epoch 596/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 7.2978e-06 - val_acc: 1.0000\n",
      "Epoch 597/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0191 - acc: 0.9957 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 598/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0126 - acc: 0.9965 - val_loss: 9.3418e-05 - val_acc: 1.0000\n",
      "Epoch 599/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0041 - acc: 0.9970 - val_loss: 4.6439e-05 - val_acc: 1.0000\n",
      "Epoch 600/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0063 - acc: 0.9978 - val_loss: 2.3183e-04 - val_acc: 1.0000\n",
      "Epoch 601/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 2.5784e-04 - val_acc: 1.0000\n",
      "Epoch 602/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 1.4828e-04 - val_acc: 1.0000\n",
      "Epoch 603/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 1.7447e-04 - val_acc: 1.0000\n",
      "Epoch 604/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 4.5423e-05 - val_acc: 1.0000\n",
      "Epoch 605/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 7.7634e-05 - val_acc: 1.0000\n",
      "Epoch 606/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0032 - acc: 0.9983 - val_loss: 8.5792e-05 - val_acc: 1.0000\n",
      "Epoch 607/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 9.0225e-05 - val_acc: 1.0000\n",
      "Epoch 608/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 6.2990e-05 - val_acc: 1.0000\n",
      "Epoch 609/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 8.2949e-04 - acc: 0.9996 - val_loss: 8.9542e-05 - val_acc: 1.0000\n",
      "Epoch 610/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 7.9580e-05 - val_acc: 1.0000\n",
      "Epoch 611/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0015 - acc: 0.9991 - val_loss: 5.3933e-05 - val_acc: 1.0000\n",
      "Epoch 612/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.2155e-04 - acc: 1.0000 - val_loss: 4.6912e-05 - val_acc: 1.0000\n",
      "Epoch 613/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 4.3253e-05 - val_acc: 1.0000\n",
      "Epoch 614/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2748e-04 - acc: 1.0000 - val_loss: 3.1258e-05 - val_acc: 1.0000\n",
      "Epoch 615/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.9991 - val_loss: 3.3300e-05 - val_acc: 1.0000\n",
      "Epoch 616/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.4681e-04 - acc: 1.0000 - val_loss: 2.6596e-05 - val_acc: 1.0000\n",
      "Epoch 617/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 3.9758e-05 - val_acc: 1.0000\n",
      "Epoch 618/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0024 - acc: 0.9983 - val_loss: 3.5618e-05 - val_acc: 1.0000\n",
      "Epoch 619/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0026 - acc: 0.9983 - val_loss: 1.9034e-05 - val_acc: 1.0000\n",
      "Epoch 620/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 2.2748e-05 - val_acc: 1.0000\n",
      "Epoch 621/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.5713e-04 - acc: 1.0000 - val_loss: 1.7104e-05 - val_acc: 1.0000\n",
      "Epoch 622/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.0472e-05 - acc: 1.0000 - val_loss: 1.5543e-05 - val_acc: 1.0000\n",
      "Epoch 623/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 6.1839e-05 - val_acc: 1.0000\n",
      "Epoch 624/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0025 - acc: 0.9987 - val_loss: 1.7408e-05 - val_acc: 1.0000\n",
      "Epoch 625/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0085 - acc: 0.9987 - val_loss: 2.4604e-05 - val_acc: 1.0000\n",
      "Epoch 626/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.0010e-04 - acc: 1.0000 - val_loss: 4.8030e-05 - val_acc: 1.0000\n",
      "Epoch 627/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 1.2895e-05 - val_acc: 1.0000\n",
      "Epoch 628/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 9.0332e-04 - acc: 0.9996 - val_loss: 3.5433e-05 - val_acc: 1.0000\n",
      "Epoch 629/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0037 - acc: 0.9983 - val_loss: 4.6847e-05 - val_acc: 1.0000\n",
      "Epoch 630/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 4.0380e-05 - val_acc: 1.0000\n",
      "Epoch 631/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 7.5634e-04 - acc: 0.9996 - val_loss: 1.5838e-05 - val_acc: 1.0000\n",
      "Epoch 632/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0040 - acc: 0.9970 - val_loss: 2.4973e-05 - val_acc: 1.0000\n",
      "Epoch 633/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0049 - acc: 0.9978 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 634/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0027 - acc: 0.9987 - val_loss: 5.0674e-05 - val_acc: 1.0000\n",
      "Epoch 635/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0045 - acc: 0.9978 - val_loss: 1.2028e-04 - val_acc: 1.0000\n",
      "Epoch 636/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0025 - acc: 0.9983 - val_loss: 6.7762e-05 - val_acc: 1.0000\n",
      "Epoch 637/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0023 - acc: 0.9987 - val_loss: 5.0116e-05 - val_acc: 1.0000\n",
      "Epoch 638/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0026 - acc: 0.9987 - val_loss: 1.1888e-04 - val_acc: 1.0000\n",
      "Epoch 639/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 8.6863e-04 - acc: 1.0000 - val_loss: 1.1488e-04 - val_acc: 1.0000\n",
      "Epoch 640/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0092 - acc: 0.9957 - val_loss: 2.6485e-04 - val_acc: 1.0000\n",
      "Epoch 641/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 9.4050e-04 - acc: 1.0000 - val_loss: 7.8967e-05 - val_acc: 1.0000\n",
      "Epoch 642/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0024 - acc: 0.9987 - val_loss: 1.0502e-04 - val_acc: 1.0000\n",
      "Epoch 643/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0016 - acc: 0.9987 - val_loss: 8.4522e-05 - val_acc: 1.0000\n",
      "Epoch 644/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0053 - acc: 0.9965 - val_loss: 7.6665e-05 - val_acc: 1.0000\n",
      "Epoch 645/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0053 - acc: 0.9974 - val_loss: 7.8836e-05 - val_acc: 1.0000\n",
      "Epoch 646/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 1.1797e-04 - val_acc: 1.0000\n",
      "Epoch 647/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 1.5240e-04 - val_acc: 1.0000\n",
      "Epoch 648/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0015 - acc: 0.9991 - val_loss: 8.6022e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 649/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0042 - acc: 0.9978 - val_loss: 1.2716e-04 - val_acc: 1.0000\n",
      "Epoch 650/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0034 - acc: 0.9983 - val_loss: 7.1841e-05 - val_acc: 1.0000\n",
      "Epoch 651/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0015 - acc: 0.9991 - val_loss: 1.4407e-04 - val_acc: 1.0000\n",
      "Epoch 652/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0020 - acc: 0.9983 - val_loss: 5.8307e-05 - val_acc: 1.0000\n",
      "Epoch 653/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 3.8504e-05 - val_acc: 1.0000\n",
      "Epoch 654/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0019 - acc: 0.9987 - val_loss: 7.6586e-05 - val_acc: 1.0000\n",
      "Epoch 655/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 5.5700e-05 - val_acc: 1.0000\n",
      "Epoch 656/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0035 - acc: 0.9978 - val_loss: 4.2734e-05 - val_acc: 1.0000\n",
      "Epoch 657/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 5.6103e-05 - val_acc: 1.0000\n",
      "Epoch 658/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 7.9833e-05 - val_acc: 1.0000\n",
      "Epoch 659/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 3.4521e-05 - val_acc: 1.0000\n",
      "Epoch 660/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 1.8944e-05 - val_acc: 1.0000\n",
      "Epoch 661/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 2.4770e-05 - val_acc: 1.0000\n",
      "Epoch 662/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0024 - acc: 0.9983 - val_loss: 3.6120e-05 - val_acc: 1.0000\n",
      "Epoch 663/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 2.4802e-05 - val_acc: 1.0000\n",
      "Epoch 664/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0140 - acc: 0.9948 - val_loss: 4.9305e-05 - val_acc: 1.0000\n",
      "Epoch 665/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 8.2916e-05 - val_acc: 1.0000\n",
      "Epoch 666/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 9.5544e-05 - val_acc: 1.0000\n",
      "Epoch 667/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 1.2364e-04 - val_acc: 1.0000\n",
      "Epoch 668/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9978 - val_loss: 1.1771e-04 - val_acc: 1.0000\n",
      "Epoch 669/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 1.5678e-04 - val_acc: 1.0000\n",
      "Epoch 670/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.3083e-04 - acc: 1.0000 - val_loss: 1.1983e-04 - val_acc: 1.0000\n",
      "Epoch 671/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 6.6365e-05 - val_acc: 1.0000\n",
      "Epoch 672/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.5017e-04 - acc: 1.0000 - val_loss: 4.8228e-05 - val_acc: 1.0000\n",
      "Epoch 673/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 5.4187e-05 - val_acc: 1.0000\n",
      "Epoch 674/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 1.1827e-04 - val_acc: 1.0000\n",
      "Epoch 675/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 6.0413e-05 - val_acc: 1.0000\n",
      "Epoch 676/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0029 - acc: 0.9978 - val_loss: 9.7900e-05 - val_acc: 1.0000\n",
      "Epoch 677/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0081 - acc: 0.9970 - val_loss: 1.5215e-05 - val_acc: 1.0000\n",
      "Epoch 678/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0123 - acc: 0.9952 - val_loss: 1.3811e-04 - val_acc: 1.0000\n",
      "Epoch 679/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0026 - acc: 0.9987 - val_loss: 1.4083e-04 - val_acc: 1.0000\n",
      "Epoch 680/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 9.8647e-05 - val_acc: 1.0000\n",
      "Epoch 681/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 9.3089e-05 - val_acc: 1.0000\n",
      "Epoch 682/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 7.9350e-05 - val_acc: 1.0000\n",
      "Epoch 683/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 8.3336e-05 - val_acc: 1.0000\n",
      "Epoch 684/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9987 - val_loss: 6.5082e-05 - val_acc: 1.0000\n",
      "Epoch 685/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0029 - acc: 0.9987 - val_loss: 8.1074e-05 - val_acc: 1.0000\n",
      "Epoch 686/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0025 - acc: 0.9987 - val_loss: 1.0809e-04 - val_acc: 1.0000\n",
      "Epoch 687/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.6524e-04 - acc: 1.0000 - val_loss: 1.1537e-04 - val_acc: 1.0000\n",
      "Epoch 688/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 6.0997e-04 - acc: 0.9996 - val_loss: 7.3518e-05 - val_acc: 1.0000\n",
      "Epoch 689/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 1.8569e-05 - val_acc: 1.0000\n",
      "Epoch 690/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0053 - acc: 0.9987 - val_loss: 3.1619e-04 - val_acc: 1.0000\n",
      "Epoch 691/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 6.0429e-05 - val_acc: 1.0000\n",
      "Epoch 692/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 3.4847e-04 - acc: 1.0000 - val_loss: 4.4858e-05 - val_acc: 1.0000\n",
      "Epoch 693/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 7.2668e-05 - val_acc: 1.0000\n",
      "Epoch 694/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0038 - acc: 0.9978 - val_loss: 9.9483e-05 - val_acc: 1.0000\n",
      "Epoch 695/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 9.7499e-05 - val_acc: 1.0000\n",
      "Epoch 696/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 1.2825e-04 - val_acc: 1.0000\n",
      "Epoch 697/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0025 - acc: 0.9987 - val_loss: 4.5688e-05 - val_acc: 1.0000\n",
      "Epoch 698/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0013 - acc: 0.9991 - val_loss: 4.1766e-05 - val_acc: 1.0000\n",
      "Epoch 699/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.7890e-04 - acc: 0.9996 - val_loss: 4.0400e-05 - val_acc: 1.0000\n",
      "Epoch 700/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 6.9678e-05 - val_acc: 1.0000\n",
      "Epoch 701/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0046 - acc: 0.9961 - val_loss: 1.4236e-04 - val_acc: 1.0000\n",
      "Epoch 702/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 1.4527e-04 - val_acc: 1.0000\n",
      "Epoch 703/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0045 - acc: 0.9983 - val_loss: 1.9142e-04 - val_acc: 1.0000\n",
      "Epoch 704/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 3.3476e-05 - val_acc: 1.0000\n",
      "Epoch 705/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0051 - acc: 0.9983 - val_loss: 1.5830e-04 - val_acc: 1.0000\n",
      "Epoch 706/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 1.5161e-04 - val_acc: 1.0000\n",
      "Epoch 707/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 1.7653e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 708/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 1.5766e-04 - val_acc: 1.0000\n",
      "Epoch 709/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0086 - acc: 0.9974 - val_loss: 8.1628e-05 - val_acc: 1.0000\n",
      "Epoch 710/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0033 - acc: 0.9987 - val_loss: 1.2359e-04 - val_acc: 1.0000\n",
      "Epoch 711/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 1.2259e-04 - val_acc: 1.0000\n",
      "Epoch 712/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 0.9987 - val_loss: 1.1131e-04 - val_acc: 1.0000\n",
      "Epoch 713/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0016 - acc: 0.9987 - val_loss: 9.1405e-05 - val_acc: 1.0000\n",
      "Epoch 714/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 8.5260e-05 - val_acc: 1.0000\n",
      "Epoch 715/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 2.8905e-04 - val_acc: 1.0000\n",
      "Epoch 716/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 1.9742e-04 - val_acc: 1.0000\n",
      "Epoch 717/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 6.5773e-04 - acc: 0.9996 - val_loss: 1.3504e-04 - val_acc: 1.0000\n",
      "Epoch 718/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 1.1472e-04 - val_acc: 1.0000\n",
      "Epoch 719/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 9.2873e-04 - acc: 0.9996 - val_loss: 7.1466e-05 - val_acc: 1.0000\n",
      "Epoch 720/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.4966e-04 - acc: 1.0000 - val_loss: 5.3599e-05 - val_acc: 1.0000\n",
      "Epoch 721/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0035 - acc: 0.9978 - val_loss: 8.6692e-05 - val_acc: 1.0000\n",
      "Epoch 722/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 6.4858e-05 - val_acc: 1.0000\n",
      "Epoch 723/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0024 - acc: 0.9983 - val_loss: 9.2919e-05 - val_acc: 1.0000\n",
      "Epoch 724/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0036 - acc: 0.9974 - val_loss: 1.7588e-04 - val_acc: 1.0000\n",
      "Epoch 725/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 8.6190e-05 - val_acc: 1.0000\n",
      "Epoch 726/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 9.8802e-05 - val_acc: 1.0000\n",
      "Epoch 727/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 7.9170e-05 - val_acc: 1.0000\n",
      "Epoch 728/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 4.7871e-05 - val_acc: 1.0000\n",
      "Epoch 729/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.9075e-04 - acc: 0.9996 - val_loss: 4.4010e-05 - val_acc: 1.0000\n",
      "Epoch 730/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0020 - acc: 0.9987 - val_loss: 7.6987e-05 - val_acc: 1.0000\n",
      "Epoch 731/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 1.0183e-04 - val_acc: 1.0000\n",
      "Epoch 732/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.6809e-04 - acc: 1.0000 - val_loss: 1.1114e-04 - val_acc: 1.0000\n",
      "Epoch 733/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 1.3534e-04 - val_acc: 1.0000\n",
      "Epoch 734/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0189 - acc: 0.9974 - val_loss: 7.2931e-06 - val_acc: 1.0000\n",
      "Epoch 735/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0057 - acc: 0.9978 - val_loss: 6.4401e-05 - val_acc: 1.0000\n",
      "Epoch 736/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 3.6688e-05 - val_acc: 1.0000\n",
      "Epoch 737/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0034 - acc: 0.9983 - val_loss: 7.6836e-05 - val_acc: 1.0000\n",
      "Epoch 738/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0045 - acc: 0.9970 - val_loss: 3.6667e-05 - val_acc: 1.0000\n",
      "Epoch 739/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 6.0085e-05 - val_acc: 1.0000\n",
      "Epoch 740/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9983 - val_loss: 5.0957e-05 - val_acc: 1.0000\n",
      "Epoch 741/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9987 - val_loss: 4.2758e-05 - val_acc: 1.0000\n",
      "Epoch 742/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.1988e-04 - acc: 1.0000 - val_loss: 2.9900e-05 - val_acc: 1.0000\n",
      "Epoch 743/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9983 - val_loss: 5.4542e-05 - val_acc: 1.0000\n",
      "Epoch 744/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 5.4362e-05 - val_acc: 1.0000\n",
      "Epoch 745/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 7.6147e-05 - val_acc: 1.0000\n",
      "Epoch 746/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0040 - acc: 0.9983 - val_loss: 1.4911e-04 - val_acc: 1.0000\n",
      "Epoch 747/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0025 - acc: 0.9983 - val_loss: 1.3516e-04 - val_acc: 1.0000\n",
      "Epoch 748/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0089 - acc: 0.9974 - val_loss: 9.5839e-05 - val_acc: 1.0000\n",
      "Epoch 749/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0027 - acc: 0.9987 - val_loss: 3.0227e-05 - val_acc: 1.0000\n",
      "Epoch 750/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0041 - acc: 0.9983 - val_loss: 2.3487e-04 - val_acc: 1.0000\n",
      "Epoch 751/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0089 - acc: 0.9957 - val_loss: 1.1557e-04 - val_acc: 1.0000\n",
      "Epoch 752/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0070 - acc: 0.9965 - val_loss: 1.0369e-04 - val_acc: 1.0000\n",
      "Epoch 753/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0101 - acc: 0.9952 - val_loss: 1.3438e-04 - val_acc: 1.0000\n",
      "Epoch 754/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0043 - acc: 0.9974 - val_loss: 8.5385e-05 - val_acc: 1.0000\n",
      "Epoch 755/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0071 - acc: 0.9957 - val_loss: 1.9051e-04 - val_acc: 1.0000\n",
      "Epoch 756/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0068 - acc: 0.9970 - val_loss: 9.3996e-05 - val_acc: 1.0000\n",
      "Epoch 757/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0083 - acc: 0.9961 - val_loss: 7.5458e-05 - val_acc: 1.0000\n",
      "Epoch 758/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0041 - acc: 0.9974 - val_loss: 8.5581e-05 - val_acc: 1.0000\n",
      "Epoch 759/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0097 - acc: 0.9944 - val_loss: 9.9941e-05 - val_acc: 1.0000\n",
      "Epoch 760/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0059 - acc: 0.9961 - val_loss: 9.3461e-05 - val_acc: 1.0000\n",
      "Epoch 761/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0104 - acc: 0.9944 - val_loss: 9.3103e-05 - val_acc: 1.0000\n",
      "Epoch 762/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0081 - acc: 0.9952 - val_loss: 1.3112e-04 - val_acc: 1.0000\n",
      "Epoch 763/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0133 - acc: 0.9957 - val_loss: 4.0078e-05 - val_acc: 1.0000\n",
      "Epoch 764/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0071 - acc: 0.9952 - val_loss: 6.0232e-05 - val_acc: 1.0000\n",
      "Epoch 765/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0091 - acc: 0.9944 - val_loss: 1.1358e-04 - val_acc: 1.0000\n",
      "Epoch 766/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0212 - acc: 0.9926 - val_loss: 7.8678e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 767/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0093 - acc: 0.9944 - val_loss: 8.5116e-05 - val_acc: 1.0000\n",
      "Epoch 768/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0092 - acc: 0.9961 - val_loss: 8.0438e-05 - val_acc: 1.0000\n",
      "Epoch 769/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 7.4707e-05 - val_acc: 1.0000\n",
      "Epoch 770/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0059 - acc: 0.9961 - val_loss: 1.0980e-04 - val_acc: 1.0000\n",
      "Epoch 771/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0086 - acc: 0.9948 - val_loss: 1.1419e-04 - val_acc: 1.0000\n",
      "Epoch 772/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0069 - acc: 0.9965 - val_loss: 3.6509e-04 - val_acc: 1.0000\n",
      "Epoch 773/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0070 - acc: 0.9957 - val_loss: 9.1838e-05 - val_acc: 1.0000\n",
      "Epoch 774/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0074 - acc: 0.9957 - val_loss: 1.8461e-04 - val_acc: 1.0000\n",
      "Epoch 775/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0104 - acc: 0.9948 - val_loss: 1.1239e-04 - val_acc: 1.0000\n",
      "Epoch 776/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0065 - acc: 0.9961 - val_loss: 7.9699e-05 - val_acc: 1.0000\n",
      "Epoch 777/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0157 - acc: 0.9978 - val_loss: 1.0073e-05 - val_acc: 1.0000\n",
      "Epoch 778/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0119 - acc: 0.9970 - val_loss: 9.2977e-05 - val_acc: 1.0000\n",
      "Epoch 779/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0116 - acc: 0.9944 - val_loss: 1.7475e-04 - val_acc: 1.0000\n",
      "Epoch 780/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0160 - acc: 0.9935 - val_loss: 0.0433 - val_acc: 0.9844\n",
      "Epoch 781/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 8.4288e-05 - val_acc: 1.0000\n",
      "Epoch 782/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 5.6061e-05 - val_acc: 1.0000\n",
      "Epoch 783/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 784/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0130e-04 - val_acc: 1.0000\n",
      "Epoch 785/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 7.0243e-05 - val_acc: 1.0000\n",
      "Epoch 786/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 5.8432e-04 - acc: 1.0000 - val_loss: 5.6345e-05 - val_acc: 1.0000\n",
      "Epoch 787/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 6.1163e-05 - val_acc: 1.0000\n",
      "Epoch 788/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 6.8765e-05 - val_acc: 1.0000\n",
      "Epoch 789/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 7.2449e-05 - val_acc: 1.0000\n",
      "Epoch 790/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0027 - acc: 0.9987 - val_loss: 6.4700e-05 - val_acc: 1.0000\n",
      "Epoch 791/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0028 - acc: 0.9983 - val_loss: 7.9737e-05 - val_acc: 1.0000\n",
      "Epoch 792/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9983 - val_loss: 6.9148e-05 - val_acc: 1.0000\n",
      "Epoch 793/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0034 - acc: 0.9987 - val_loss: 5.0091e-05 - val_acc: 1.0000\n",
      "Epoch 794/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 1.1467e-04 - val_acc: 1.0000\n",
      "Epoch 795/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 8.4741e-05 - val_acc: 1.0000\n",
      "Epoch 796/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0024 - acc: 0.9987 - val_loss: 6.8840e-05 - val_acc: 1.0000\n",
      "Epoch 797/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9987 - val_loss: 9.3001e-05 - val_acc: 1.0000\n",
      "Epoch 798/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9987 - val_loss: 6.7465e-05 - val_acc: 1.0000\n",
      "Epoch 799/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 6.6695e-04 - acc: 0.9996 - val_loss: 4.2221e-05 - val_acc: 1.0000\n",
      "Epoch 800/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 5.1968e-05 - val_acc: 1.0000\n",
      "Epoch 801/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 9.1747e-05 - val_acc: 1.0000\n",
      "Epoch 802/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 3.6883e-04 - val_acc: 1.0000\n",
      "Epoch 803/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9996 - val_loss: 1.4159e-04 - val_acc: 1.0000\n",
      "Epoch 804/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0030 - acc: 0.9987 - val_loss: 1.4962e-04 - val_acc: 1.0000\n",
      "Epoch 805/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0025 - acc: 0.9987 - val_loss: 1.0335e-04 - val_acc: 1.0000\n",
      "Epoch 806/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 8.9819e-05 - val_acc: 1.0000\n",
      "Epoch 807/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9983 - val_loss: 2.6744e-04 - val_acc: 1.0000\n",
      "Epoch 808/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 1.1106e-04 - val_acc: 1.0000\n",
      "Epoch 809/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0024 - acc: 0.9987 - val_loss: 1.4055e-04 - val_acc: 1.0000\n",
      "Epoch 810/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 1.2422e-04 - val_acc: 1.0000\n",
      "Epoch 811/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0025 - acc: 0.9987 - val_loss: 1.5081e-04 - val_acc: 1.0000\n",
      "Epoch 812/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 6.0080e-04 - acc: 0.9996 - val_loss: 1.0481e-04 - val_acc: 1.0000\n",
      "Epoch 813/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 5.3102e-04 - acc: 0.9996 - val_loss: 7.3652e-05 - val_acc: 1.0000\n",
      "Epoch 814/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 1.0718e-04 - val_acc: 1.0000\n",
      "Epoch 815/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0028 - acc: 0.9987 - val_loss: 8.3348e-05 - val_acc: 1.0000\n",
      "Epoch 816/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0019 - acc: 0.9987 - val_loss: 5.9903e-05 - val_acc: 1.0000\n",
      "Epoch 817/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0011 - acc: 0.9991 - val_loss: 7.6680e-05 - val_acc: 1.0000\n",
      "Epoch 818/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0023 - acc: 0.9987 - val_loss: 8.0021e-05 - val_acc: 1.0000\n",
      "Epoch 819/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 9.7386e-04 - acc: 0.9996 - val_loss: 5.0108e-05 - val_acc: 1.0000\n",
      "Epoch 820/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 6.7636e-05 - acc: 1.0000 - val_loss: 3.6817e-05 - val_acc: 1.0000\n",
      "Epoch 821/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0049 - acc: 0.9970 - val_loss: 6.9798e-05 - val_acc: 1.0000\n",
      "Epoch 822/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 8.0435e-05 - val_acc: 1.0000\n",
      "Epoch 823/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0013 - acc: 0.9991 - val_loss: 3.2283e-05 - val_acc: 1.0000\n",
      "Epoch 824/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 1.0149e-04 - val_acc: 1.0000\n",
      "Epoch 825/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 5.8246e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0016 - acc: 0.9987 - val_loss: 4.6069e-05 - val_acc: 1.0000\n",
      "Epoch 827/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0017 - acc: 0.9987 - val_loss: 5.7389e-05 - val_acc: 1.0000\n",
      "Epoch 828/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 6.5306e-05 - val_acc: 1.0000\n",
      "Epoch 829/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 5.3148e-04 - acc: 1.0000 - val_loss: 1.0113e-04 - val_acc: 1.0000\n",
      "Epoch 830/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0037 - acc: 0.9974 - val_loss: 3.7646e-05 - val_acc: 1.0000\n",
      "Epoch 831/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0024 - acc: 0.9987 - val_loss: 5.5552e-05 - val_acc: 1.0000\n",
      "Epoch 832/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.8965e-04 - acc: 1.0000 - val_loss: 3.9914e-05 - val_acc: 1.0000\n",
      "Epoch 833/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9987 - val_loss: 3.2340e-05 - val_acc: 1.0000\n",
      "Epoch 834/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 2.6574e-05 - val_acc: 1.0000\n",
      "Epoch 835/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0021 - acc: 0.9987 - val_loss: 4.6942e-05 - val_acc: 1.0000\n",
      "Epoch 836/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9987 - val_loss: 3.7788e-05 - val_acc: 1.0000\n",
      "Epoch 837/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 3.4507e-05 - val_acc: 1.0000\n",
      "Epoch 838/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 4.1929e-05 - val_acc: 1.0000\n",
      "Epoch 839/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 9.3021e-04 - acc: 0.9996 - val_loss: 4.4528e-05 - val_acc: 1.0000\n",
      "Epoch 840/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 4.0752e-04 - acc: 1.0000 - val_loss: 4.8937e-05 - val_acc: 1.0000\n",
      "Epoch 841/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 2.1410e-05 - val_acc: 1.0000\n",
      "Epoch 842/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0049 - acc: 0.9983 - val_loss: 1.3651e-04 - val_acc: 1.0000\n",
      "Epoch 843/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0077 - acc: 0.9983 - val_loss: 2.0523e-04 - val_acc: 1.0000\n",
      "Epoch 844/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 1.2328e-04 - val_acc: 1.0000\n",
      "Epoch 845/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 1.3248e-04 - val_acc: 1.0000\n",
      "Epoch 846/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 3.6007e-04 - val_acc: 1.0000\n",
      "Epoch 847/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 1.6019e-04 - val_acc: 1.0000\n",
      "Epoch 848/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0024 - acc: 0.9987 - val_loss: 1.0545e-04 - val_acc: 1.0000\n",
      "Epoch 849/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 9.0451e-05 - val_acc: 1.0000\n",
      "Epoch 850/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 7.8010e-05 - val_acc: 1.0000\n",
      "Epoch 851/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 8.6790e-05 - val_acc: 1.0000\n",
      "Epoch 852/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0059 - acc: 0.9970 - val_loss: 3.3908e-05 - val_acc: 1.0000\n",
      "Epoch 853/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0070 - acc: 0.9987 - val_loss: 4.6197e-05 - val_acc: 1.0000\n",
      "Epoch 854/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 4.1995e-05 - val_acc: 1.0000\n",
      "Epoch 855/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0060 - acc: 0.9970 - val_loss: 1.4260e-04 - val_acc: 1.0000\n",
      "Epoch 856/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 1.2811e-04 - val_acc: 1.0000\n",
      "Epoch 857/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 1.1539e-04 - val_acc: 1.0000\n",
      "Epoch 858/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 1.3069e-04 - val_acc: 1.0000\n",
      "Epoch 859/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0028 - acc: 0.9987 - val_loss: 1.4880e-04 - val_acc: 1.0000\n",
      "Epoch 860/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0023 - acc: 0.9987 - val_loss: 1.4012e-04 - val_acc: 1.0000\n",
      "Epoch 861/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 9.0111e-05 - val_acc: 1.0000\n",
      "Epoch 862/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 1.5306e-05 - val_acc: 1.0000\n",
      "Epoch 863/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0134 - acc: 0.9965 - val_loss: 1.6583e-04 - val_acc: 1.0000\n",
      "Epoch 864/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9996 - val_loss: 1.5694e-04 - val_acc: 1.0000\n",
      "Epoch 865/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 1.9241e-04 - val_acc: 1.0000\n",
      "Epoch 866/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.5880e-04 - acc: 1.0000 - val_loss: 1.6417e-04 - val_acc: 1.0000\n",
      "Epoch 867/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0062 - acc: 0.9978 - val_loss: 8.7733e-05 - val_acc: 1.0000\n",
      "Epoch 868/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 7.6501e-05 - val_acc: 1.0000\n",
      "Epoch 869/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 8.6938e-05 - val_acc: 1.0000\n",
      "Epoch 870/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0057 - acc: 0.9978 - val_loss: 2.7273e-04 - val_acc: 1.0000\n",
      "Epoch 871/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 1.5477e-04 - val_acc: 1.0000\n",
      "Epoch 872/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 6.0027e-04 - val_acc: 1.0000\n",
      "Epoch 873/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 4.3737e-04 - acc: 1.0000 - val_loss: 1.9885e-04 - val_acc: 1.0000\n",
      "Epoch 874/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 3.6909e-04 - acc: 1.0000 - val_loss: 1.4632e-04 - val_acc: 1.0000\n",
      "Epoch 875/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.2084e-04 - acc: 1.0000 - val_loss: 1.1570e-04 - val_acc: 1.0000\n",
      "Epoch 876/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 6.7926e-05 - val_acc: 1.0000\n",
      "Epoch 877/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 5.5223e-05 - val_acc: 1.0000\n",
      "Epoch 878/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.8148e-04 - acc: 0.9996 - val_loss: 5.1020e-05 - val_acc: 1.0000\n",
      "Epoch 879/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 6.0627e-05 - val_acc: 1.0000\n",
      "Epoch 880/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0010 - acc: 0.9991 - val_loss: 4.6825e-05 - val_acc: 1.0000\n",
      "Epoch 881/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 4.4313e-05 - val_acc: 1.0000\n",
      "Epoch 882/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 7.8408e-05 - val_acc: 1.0000\n",
      "Epoch 883/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0019 - acc: 0.9987 - val_loss: 6.7679e-05 - val_acc: 1.0000\n",
      "Epoch 884/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 7.3525e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0023 - acc: 0.9983 - val_loss: 7.1607e-05 - val_acc: 1.0000\n",
      "Epoch 886/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 9.9043e-04 - acc: 0.9991 - val_loss: 4.5839e-05 - val_acc: 1.0000\n",
      "Epoch 887/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 3.9776e-04 - acc: 1.0000 - val_loss: 3.3683e-05 - val_acc: 1.0000\n",
      "Epoch 888/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 8.5571e-05 - val_acc: 1.0000\n",
      "Epoch 889/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 1.3335e-04 - val_acc: 1.0000\n",
      "Epoch 890/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0015 - acc: 0.9991 - val_loss: 1.1347e-04 - val_acc: 1.0000\n",
      "Epoch 891/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 6.2733e-05 - val_acc: 1.0000\n",
      "Epoch 892/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 1.2272e-04 - val_acc: 1.0000\n",
      "Epoch 893/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 1.5387e-04 - val_acc: 1.0000\n",
      "Epoch 894/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 1.5888e-04 - val_acc: 1.0000\n",
      "Epoch 895/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 8.5898e-04 - acc: 0.9996 - val_loss: 1.7797e-04 - val_acc: 1.0000\n",
      "Epoch 896/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 1.0384e-04 - val_acc: 1.0000\n",
      "Epoch 897/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 8.3663e-04 - acc: 0.9996 - val_loss: 1.3872e-04 - val_acc: 1.0000\n",
      "Epoch 898/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 6.3091e-05 - val_acc: 1.0000\n",
      "Epoch 899/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 1.3031e-04 - val_acc: 1.0000\n",
      "Epoch 900/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 1.9857e-04 - val_acc: 1.0000\n",
      "Epoch 901/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 1.2185e-04 - val_acc: 1.0000\n",
      "Epoch 902/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0050 - acc: 0.9983 - val_loss: 4.8806e-05 - val_acc: 1.0000\n",
      "Epoch 903/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 1.1365e-04 - val_acc: 1.0000\n",
      "Epoch 904/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0043 - acc: 0.9983 - val_loss: 1.2757e-04 - val_acc: 1.0000\n",
      "Epoch 905/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0057 - acc: 0.9978 - val_loss: 3.7353e-04 - val_acc: 1.0000\n",
      "Epoch 906/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0017 - acc: 0.9987 - val_loss: 1.0455e-04 - val_acc: 1.0000\n",
      "Epoch 907/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0103 - acc: 0.9974 - val_loss: 2.3515e-04 - val_acc: 1.0000\n",
      "Epoch 908/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 2.8251e-04 - val_acc: 1.0000\n",
      "Epoch 909/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 2.6986e-04 - val_acc: 1.0000\n",
      "Epoch 910/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 1.9526e-04 - val_acc: 1.0000\n",
      "Epoch 911/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0043 - acc: 0.9983 - val_loss: 1.5468e-04 - val_acc: 1.0000\n",
      "Epoch 912/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.4984e-04 - acc: 0.9996 - val_loss: 1.3313e-04 - val_acc: 1.0000\n",
      "Epoch 913/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.8672e-04 - acc: 1.0000 - val_loss: 1.2624e-04 - val_acc: 1.0000\n",
      "Epoch 914/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1911e-04 - acc: 1.0000 - val_loss: 1.3780e-05 - val_acc: 1.0000\n",
      "Epoch 915/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0088 - acc: 0.9983 - val_loss: 2.1235e-04 - val_acc: 1.0000\n",
      "Epoch 916/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 3.1368e-04 - val_acc: 1.0000\n",
      "Epoch 917/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0088 - acc: 0.9974 - val_loss: 1.2869e-04 - val_acc: 1.0000\n",
      "Epoch 918/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0122 - acc: 0.9965 - val_loss: 1.2788e-04 - val_acc: 1.0000\n",
      "Epoch 919/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 1.7215e-04 - val_acc: 1.0000\n",
      "Epoch 920/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 1.5419e-04 - val_acc: 1.0000\n",
      "Epoch 921/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 1.4248e-04 - val_acc: 1.0000\n",
      "Epoch 922/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 1.8134e-04 - val_acc: 1.0000\n",
      "Epoch 923/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9987 - val_loss: 1.5557e-04 - val_acc: 1.0000\n",
      "Epoch 924/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9987 - val_loss: 1.3999e-04 - val_acc: 1.0000\n",
      "Epoch 925/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 1.4083e-04 - val_acc: 1.0000\n",
      "Epoch 926/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0020 - acc: 0.9987 - val_loss: 1.5183e-04 - val_acc: 1.0000\n",
      "Epoch 927/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 1.4007e-04 - val_acc: 1.0000\n",
      "Epoch 928/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 1.4589e-04 - val_acc: 1.0000\n",
      "Epoch 929/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 2.0653e-04 - acc: 1.0000 - val_loss: 1.2547e-04 - val_acc: 1.0000\n",
      "Epoch 930/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0013 - acc: 0.9991 - val_loss: 1.1755e-04 - val_acc: 1.0000\n",
      "Epoch 931/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 1.3002e-04 - val_acc: 1.0000\n",
      "Epoch 932/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0013 - acc: 0.9991 - val_loss: 1.0875e-04 - val_acc: 1.0000\n",
      "Epoch 933/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 8.8873e-05 - val_acc: 1.0000\n",
      "Epoch 934/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 3.8731e-04 - acc: 1.0000 - val_loss: 7.7434e-05 - val_acc: 1.0000\n",
      "Epoch 935/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 1.3224e-04 - val_acc: 1.0000\n",
      "Epoch 936/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.0346e-04 - acc: 1.0000 - val_loss: 1.2887e-04 - val_acc: 1.0000\n",
      "Epoch 937/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 1.3167e-04 - val_acc: 1.0000\n",
      "Epoch 938/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 9.9950e-05 - val_acc: 1.0000\n",
      "Epoch 939/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 9.6353e-05 - val_acc: 1.0000\n",
      "Epoch 940/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 3.0752e-04 - acc: 1.0000 - val_loss: 7.8173e-05 - val_acc: 1.0000\n",
      "Epoch 941/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.2262e-04 - acc: 1.0000 - val_loss: 7.7212e-05 - val_acc: 1.0000\n",
      "Epoch 942/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 7.8715e-05 - val_acc: 1.0000\n",
      "Epoch 943/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.5439e-04 - acc: 1.0000 - val_loss: 6.8832e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 9.4049e-05 - acc: 1.0000 - val_loss: 6.0533e-05 - val_acc: 1.0000\n",
      "Epoch 945/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0044 - acc: 0.9978 - val_loss: 1.2441e-04 - val_acc: 1.0000\n",
      "Epoch 946/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 3.7553e-04 - acc: 1.0000 - val_loss: 1.0800e-04 - val_acc: 1.0000\n",
      "Epoch 947/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.8130e-04 - acc: 0.9996 - val_loss: 1.5156e-04 - val_acc: 1.0000\n",
      "Epoch 948/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 1.4489e-04 - val_acc: 1.0000\n",
      "Epoch 949/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0032 - acc: 0.9996 - val_loss: 2.7577e-04 - val_acc: 1.0000\n",
      "Epoch 950/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 4.1973e-04 - acc: 1.0000 - val_loss: 1.9985e-04 - val_acc: 1.0000\n",
      "Epoch 951/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 8.6599e-04 - acc: 0.9996 - val_loss: 1.4743e-04 - val_acc: 1.0000\n",
      "Epoch 952/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 8.8614e-04 - acc: 0.9996 - val_loss: 1.9112e-04 - val_acc: 1.0000\n",
      "Epoch 953/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9983 - val_loss: 1.7831e-04 - val_acc: 1.0000\n",
      "Epoch 954/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 8.4539e-04 - acc: 0.9996 - val_loss: 1.2299e-04 - val_acc: 1.0000\n",
      "Epoch 955/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 1.5518e-04 - val_acc: 1.0000\n",
      "Epoch 956/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0049 - acc: 0.9983 - val_loss: 1.0471e-04 - val_acc: 1.0000\n",
      "Epoch 957/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 6.9583e-04 - acc: 1.0000 - val_loss: 8.9612e-05 - val_acc: 1.0000\n",
      "Epoch 958/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 9.8859e-05 - val_acc: 1.0000\n",
      "Epoch 959/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 6.9617e-04 - acc: 0.9996 - val_loss: 1.0145e-04 - val_acc: 1.0000\n",
      "Epoch 960/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 1.5123e-04 - val_acc: 1.0000\n",
      "Epoch 961/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 8.7607e-05 - val_acc: 1.0000\n",
      "Epoch 962/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 4.9421e-04 - acc: 1.0000 - val_loss: 9.4946e-05 - val_acc: 1.0000\n",
      "Epoch 963/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.6060e-04 - acc: 0.9996 - val_loss: 9.7311e-05 - val_acc: 1.0000\n",
      "Epoch 964/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.6449e-04 - acc: 1.0000 - val_loss: 8.3335e-05 - val_acc: 1.0000\n",
      "Epoch 965/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0098 - acc: 0.9978 - val_loss: 6.3972e-05 - val_acc: 1.0000\n",
      "Epoch 966/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0105 - acc: 0.9961 - val_loss: 1.0203e-04 - val_acc: 1.0000\n",
      "Epoch 967/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0044 - acc: 0.9983 - val_loss: 1.1823e-04 - val_acc: 1.0000\n",
      "Epoch 968/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.3659e-04 - acc: 1.0000 - val_loss: 1.0563e-04 - val_acc: 1.0000\n",
      "Epoch 969/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.9614e-04 - acc: 1.0000 - val_loss: 1.0697e-04 - val_acc: 1.0000\n",
      "Epoch 970/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 6.7306e-05 - val_acc: 1.0000\n",
      "Epoch 971/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0035 - acc: 0.9987 - val_loss: 8.8122e-05 - val_acc: 1.0000\n",
      "Epoch 972/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 1.6177e-04 - val_acc: 1.0000\n",
      "Epoch 973/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.4005e-04 - acc: 1.0000 - val_loss: 9.6710e-05 - val_acc: 1.0000\n",
      "Epoch 974/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 8.1923e-05 - val_acc: 1.0000\n",
      "Epoch 975/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.9991 - val_loss: 7.4970e-05 - val_acc: 1.0000\n",
      "Epoch 976/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0039 - acc: 0.9996 - val_loss: 8.7942e-05 - val_acc: 1.0000\n",
      "Epoch 977/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.7674e-04 - acc: 1.0000 - val_loss: 7.3719e-05 - val_acc: 1.0000\n",
      "Epoch 978/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 6.4057e-05 - val_acc: 1.0000\n",
      "Epoch 979/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.9991 - val_loss: 6.0633e-05 - val_acc: 1.0000\n",
      "Epoch 980/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0089 - acc: 0.9974 - val_loss: 8.9729e-04 - val_acc: 1.0000\n",
      "Epoch 981/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 1.3330e-04 - val_acc: 1.0000\n",
      "Epoch 982/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.8973e-04 - acc: 0.9996 - val_loss: 1.0927e-04 - val_acc: 1.0000\n",
      "Epoch 983/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0106 - acc: 0.9970 - val_loss: 1.5408e-04 - val_acc: 1.0000\n",
      "Epoch 984/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0066 - acc: 0.9965 - val_loss: 1.2554e-04 - val_acc: 1.0000\n",
      "Epoch 985/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0075 - acc: 0.9987 - val_loss: 1.3969e-04 - val_acc: 1.0000\n",
      "Epoch 986/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.9991 - val_loss: 1.0963e-04 - val_acc: 1.0000\n",
      "Epoch 987/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.4652e-04 - acc: 1.0000 - val_loss: 1.0530e-04 - val_acc: 1.0000\n",
      "Epoch 988/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 1.3129e-04 - val_acc: 1.0000\n",
      "Epoch 989/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 9.9736e-05 - val_acc: 1.0000\n",
      "Epoch 990/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0026 - acc: 0.9983 - val_loss: 9.4601e-05 - val_acc: 1.0000\n",
      "Epoch 991/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 9.9251e-04 - acc: 0.9996 - val_loss: 1.1079e-04 - val_acc: 1.0000\n",
      "Epoch 992/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 3.7495e-04 - acc: 1.0000 - val_loss: 1.0425e-04 - val_acc: 1.0000\n",
      "Epoch 993/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 2.7128e-04 - acc: 1.0000 - val_loss: 1.0693e-04 - val_acc: 1.0000\n",
      "Epoch 994/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0022 - acc: 0.9987 - val_loss: 9.8698e-05 - val_acc: 1.0000\n",
      "Epoch 995/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 1.0478e-04 - val_acc: 1.0000\n",
      "Epoch 996/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 1.0725e-04 - val_acc: 1.0000\n",
      "Epoch 997/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 6.7665e-04 - acc: 0.9996 - val_loss: 9.9117e-05 - val_acc: 1.0000\n",
      "Epoch 998/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 9.2065e-05 - val_acc: 1.0000\n",
      "Epoch 999/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 1.2283e-04 - val_acc: 1.0000\n",
      "Epoch 1000/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.9772e-04 - acc: 1.0000 - val_loss: 1.0196e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating model: A_A_inceptionv3-l1-final_1000_Nadam.h5 ===\n",
      "\n",
      "Accuracy: 1.000\n",
      "\n",
      "Confusion Matrix\n",
      "[[312   0]\n",
      " [  0 328]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       312\n",
      "          1       1.00      1.00      1.00       328\n",
      "\n",
      "avg / total       1.00      1.00      1.00       640\n",
      "\n",
      "=== Evaluating model: A_A_inceptionv3-l1-best_1000_Nadam.h5 ===\n",
      "\n",
      "Accuracy: 1.000\n",
      "\n",
      "Confusion Matrix\n",
      "[[308   0]\n",
      " [  0 332]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       308\n",
      "          1       1.00      1.00      1.00       332\n",
      "\n",
      "avg / total       1.00      1.00      1.00       640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In [24]:\n",
    "train_gen = data_generator(train_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "val_gen = data_generator(val_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "# In [25]:\n",
    "def absdiff(vecs):\n",
    "    x, y = vecs\n",
    "    return K.abs(K.sum(K.stack([x, -y], axis=1), axis=1))\n",
    "\n",
    "'''\n",
    "abs 元素级的绝对值操作。\n",
    "'''\n",
    "\n",
    "def absdiff_output_shape(shapes):\n",
    "    return shapes[0]\n",
    "\n",
    "vecs = [np.random.random((10,)), np.random.random((10,))]\n",
    "print(vecs[0].shape, vecs[1].shape)\n",
    "s = absdiff(vecs)\n",
    "print(s.shape)\n",
    "\n",
    "# In [26]:\n",
    "input_1 = Input(shape=(VECTOR_SIZE,))\n",
    "input_2 = Input(shape=(VECTOR_SIZE,))\n",
    "merged = Lambda(absdiff, output_shape=absdiff_output_shape)([input_1, input_2])\n",
    "\n",
    "fc1 = Dense(512, kernel_initializer=\"glorot_uniform\")(merged)\n",
    "fc1 = Dropout(0.2)(fc1)\n",
    "fc1 = Activation(\"relu\")(fc1)\n",
    "\n",
    "fc2 = Dense(128, kernel_initializer=\"glorot_uniform\")(fc1)\n",
    "fc2 = Dropout(0.2)(fc2)\n",
    "fc2 = Activation(\"relu\")(fc2)\n",
    "\n",
    "pred = Dense(2, kernel_initializer=\"glorot_uniform\")(fc2)\n",
    "pred = Activation(\"softmax\")(pred)\n",
    "# In [27]:\n",
    "model = Model(inputs=[input_1, input_2], outputs=pred)\n",
    "# model.summary()\n",
    "# In [28]:\n",
    "model.compile(optimizer=\"Nadam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# In [29]:\n",
    "best_model_name = get_model_file(DATA_DIR, \"inceptionv3\", \"l1\", \"best\")\n",
    "checkpoint = ModelCheckpoint(best_model_name, save_best_only=True)\n",
    "train_steps_per_epoch = len(train_triples) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(val_triples) // BATCH_SIZE\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps_per_epoch, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              validation_data=val_gen, validation_steps=val_steps_per_epoch,\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "# In [30]:\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# In [31]:\n",
    "final_model_name = get_model_file(DATA_DIR, \"inceptionv3\", \"l1\", \"final\")\n",
    "model.save(final_model_name)\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "final_accuracy = evaluate_model(final_model_name, test_gen)\n",
    "\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "best_accuracy = evaluate_model(best_model_name, test_gen)\n",
    "\n",
    "scores[0, 2] = best_accuracy if best_accuracy > final_accuracy else final_accuracy\n",
    "# === Evaluating model: inceptionv3-l1-final.h5 ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,) (10,)\n",
      "(10,)\n",
      "Epoch 1/1000\n",
      "72/72 [==============================] - 2s 32ms/step - loss: 0.6402 - acc: 0.6094 - val_loss: 0.4068 - val_acc: 0.8781\n",
      "Epoch 2/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3040 - acc: 0.8885 - val_loss: 0.1505 - val_acc: 0.9594\n",
      "Epoch 3/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.1285 - acc: 0.9562 - val_loss: 0.0807 - val_acc: 0.9781\n",
      "Epoch 4/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0628 - acc: 0.9809 - val_loss: 0.1107 - val_acc: 0.9656\n",
      "Epoch 5/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0595 - acc: 0.9805 - val_loss: 0.0429 - val_acc: 0.9750\n",
      "Epoch 6/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0410 - acc: 0.9874 - val_loss: 0.0468 - val_acc: 0.9938\n",
      "Epoch 7/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0382 - acc: 0.9896 - val_loss: 0.0318 - val_acc: 0.9844\n",
      "Epoch 8/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0322 - acc: 0.9896 - val_loss: 0.1235 - val_acc: 0.9531\n",
      "Epoch 9/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0180 - acc: 0.9952 - val_loss: 0.0317 - val_acc: 0.9875\n",
      "Epoch 10/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0144 - acc: 0.9952 - val_loss: 0.0110 - val_acc: 0.9938\n",
      "Epoch 11/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0304 - acc: 0.9922 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 12/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0271 - acc: 0.9926 - val_loss: 0.0222 - val_acc: 0.9906\n",
      "Epoch 13/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0532 - acc: 0.9835 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 14/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.0319 - val_acc: 0.9906\n",
      "Epoch 15/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0052 - acc: 0.9974 - val_loss: 0.0200 - val_acc: 0.9906\n",
      "Epoch 16/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0195 - val_acc: 0.9938\n",
      "Epoch 17/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9938\n",
      "Epoch 18/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0077 - acc: 0.9970 - val_loss: 0.0127 - val_acc: 0.9906\n",
      "Epoch 19/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0214 - acc: 0.9944 - val_loss: 0.1092 - val_acc: 0.9656\n",
      "Epoch 20/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0237 - acc: 0.9948 - val_loss: 0.0259 - val_acc: 0.9969\n",
      "Epoch 21/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0196 - val_acc: 0.9938\n",
      "Epoch 22/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0129 - acc: 0.9948 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 23/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0198 - acc: 0.9926 - val_loss: 0.0220 - val_acc: 0.9906\n",
      "Epoch 24/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0201 - acc: 0.9944 - val_loss: 0.0171 - val_acc: 0.9938\n",
      "Epoch 25/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0115 - acc: 0.9970 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 26/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 27/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0015 - acc: 0.9991 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 28/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0136 - acc: 0.9961 - val_loss: 0.0126 - val_acc: 0.9938\n",
      "Epoch 29/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0049 - acc: 0.9983 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 30/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0084 - acc: 0.9965 - val_loss: 0.0097 - val_acc: 0.9969\n",
      "Epoch 31/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0147 - acc: 0.9952 - val_loss: 0.0248 - val_acc: 0.9969\n",
      "Epoch 32/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0359 - acc: 0.9918 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 33/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 34/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0043 - acc: 0.9983 - val_loss: 0.0505 - val_acc: 0.9938\n",
      "Epoch 35/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0138 - acc: 0.9970 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 36/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0058 - val_acc: 0.9969\n",
      "Epoch 37/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 6.0010e-04 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 0.9969\n",
      "Epoch 38/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 2.8023e-04 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 39/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 40/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0093 - acc: 0.9978 - val_loss: 0.0229 - val_acc: 0.9938\n",
      "Epoch 41/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0236 - acc: 0.9935 - val_loss: 0.0342 - val_acc: 0.9906\n",
      "Epoch 42/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0068 - acc: 0.9983 - val_loss: 0.0250 - val_acc: 0.9875\n",
      "Epoch 43/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0174 - val_acc: 0.9969\n",
      "Epoch 44/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0034 - acc: 0.9983 - val_loss: 0.0066 - val_acc: 0.9969\n",
      "Epoch 45/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0235 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 46/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0212 - acc: 0.9952 - val_loss: 0.0334 - val_acc: 0.9812\n",
      "Epoch 47/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0148 - acc: 0.9957 - val_loss: 0.0173 - val_acc: 0.9938\n",
      "Epoch 48/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0161 - acc: 0.9970 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 49/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0190 - acc: 0.9939 - val_loss: 0.0112 - val_acc: 0.9969\n",
      "Epoch 50/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0050 - acc: 0.9991 - val_loss: 0.0173 - val_acc: 0.9969\n",
      "Epoch 51/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0081 - acc: 0.9978 - val_loss: 0.0166 - val_acc: 0.9906\n",
      "Epoch 52/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.1673 - val_acc: 0.9500\n",
      "Epoch 53/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0153 - acc: 0.9944 - val_loss: 0.0407 - val_acc: 0.9906\n",
      "Epoch 54/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0085 - acc: 0.9983 - val_loss: 0.0231 - val_acc: 0.9906\n",
      "Epoch 55/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0123 - val_acc: 0.9969\n",
      "Epoch 56/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0105 - val_acc: 0.9969\n",
      "Epoch 57/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 6.7836e-04 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 0.9938\n",
      "Epoch 58/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.7791e-04 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 0.9906\n",
      "Epoch 59/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.8910e-04 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 0.9906\n",
      "Epoch 60/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 2.0149e-04 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9938\n",
      "Epoch 61/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.9067e-04 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 0.9906\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0078 - val_acc: 0.9938\n",
      "Epoch 63/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0245 - acc: 0.9948 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 64/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0143 - acc: 0.9965 - val_loss: 0.0202 - val_acc: 0.9906\n",
      "Epoch 65/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0130 - acc: 0.9957 - val_loss: 0.0143 - val_acc: 0.9969\n",
      "Epoch 66/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0124 - val_acc: 0.9969\n",
      "Epoch 67/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0367 - acc: 0.9913 - val_loss: 0.0165 - val_acc: 0.9906\n",
      "Epoch 68/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0224 - acc: 0.9939 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 69/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0061 - acc: 0.9991 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 70/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 9.9277e-04 - val_acc: 1.0000\n",
      "Epoch 71/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.1961e-04 - acc: 1.0000 - val_loss: 7.3745e-04 - val_acc: 1.0000\n",
      "Epoch 72/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9987 - val_loss: 0.0323 - val_acc: 0.9875\n",
      "Epoch 73/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0065 - acc: 0.9987 - val_loss: 0.0113 - val_acc: 0.9969\n",
      "Epoch 74/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0069 - acc: 0.9996 - val_loss: 0.0193 - val_acc: 0.9969\n",
      "Epoch 75/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0166 - acc: 0.9952 - val_loss: 0.0045 - val_acc: 0.9969\n",
      "Epoch 76/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 77/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9987 - val_loss: 0.0093 - val_acc: 0.9938\n",
      "Epoch 78/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0038 - acc: 0.9996 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 79/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9987 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 80/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.0243e-04 - acc: 1.0000 - val_loss: 8.7880e-04 - val_acc: 1.0000\n",
      "Epoch 81/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 82/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.9793e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 83/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.0011e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 84/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.4598e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 85/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0048 - val_acc: 0.9938\n",
      "Epoch 86/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0168 - acc: 0.9957 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 87/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 6.2225e-04 - val_acc: 1.0000\n",
      "Epoch 88/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 89/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 90/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.6632e-04 - acc: 1.0000 - val_loss: 7.5287e-04 - val_acc: 1.0000\n",
      "Epoch 91/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 7.5485e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 92/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 7.8153e-04 - acc: 0.9996 - val_loss: 0.0031 - val_acc: 0.9969\n",
      "Epoch 93/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0066 - acc: 0.9983 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 94/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 95/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1.7634e-04 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9969\n",
      "Epoch 96/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 2.9186e-04 - acc: 1.0000 - val_loss: 1.7631e-04 - val_acc: 1.0000\n",
      "Epoch 97/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 2.7816e-04 - val_acc: 1.0000\n",
      "Epoch 98/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0158 - val_acc: 0.9969\n",
      "Epoch 99/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0224 - acc: 0.9965 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 100/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0058 - acc: 0.9978 - val_loss: 0.0111 - val_acc: 0.9906\n",
      "Epoch 101/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0040 - acc: 0.9978 - val_loss: 0.0156 - val_acc: 0.9938\n",
      "Epoch 102/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 1.0773e-04 - val_acc: 1.0000\n",
      "Epoch 103/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0042 - acc: 0.9978 - val_loss: 0.0100 - val_acc: 0.9938\n",
      "Epoch 104/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0081 - acc: 0.9970 - val_loss: 9.5616e-04 - val_acc: 1.0000\n",
      "Epoch 105/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0267 - acc: 0.9939 - val_loss: 0.0517 - val_acc: 0.9812\n",
      "Epoch 106/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0038 - val_acc: 0.9969\n",
      "Epoch 107/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0156 - val_acc: 0.9969\n",
      "Epoch 108/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0177 - acc: 0.9957 - val_loss: 0.0330 - val_acc: 0.9844\n",
      "Epoch 109/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0166 - acc: 0.9939 - val_loss: 0.0226 - val_acc: 0.9938\n",
      "Epoch 110/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0156 - acc: 0.9961 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 111/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0192 - acc: 0.9948 - val_loss: 0.0158 - val_acc: 0.9969\n",
      "Epoch 112/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0044 - acc: 0.9978 - val_loss: 0.0074 - val_acc: 0.9969\n",
      "Epoch 113/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0059 - acc: 0.9978 - val_loss: 0.0059 - val_acc: 0.9969\n",
      "Epoch 114/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 5.2628e-04 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9969\n",
      "Epoch 115/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 0.0059 - val_acc: 0.9969\n",
      "Epoch 116/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 8.7342e-04 - val_acc: 1.0000\n",
      "Epoch 117/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.8794e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 118/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.4587e-04 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 0.9938\n",
      "Epoch 119/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0114 - val_acc: 0.9938\n",
      "Epoch 120/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 121/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 6.1376e-04 - val_acc: 1.0000\n",
      "Epoch 122/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 11ms/step - loss: 9.5329e-04 - acc: 0.9996 - val_loss: 0.0039 - val_acc: 0.9969\n",
      "Epoch 123/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0082 - acc: 0.9987 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 124/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.9709e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 125/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.6521e-04 - acc: 1.0000 - val_loss: 3.9452e-04 - val_acc: 1.0000\n",
      "Epoch 126/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 127/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 1.7776e-04 - val_acc: 1.0000\n",
      "Epoch 128/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 4.3766e-04 - acc: 1.0000 - val_loss: 1.2366e-04 - val_acc: 1.0000\n",
      "Epoch 129/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 130/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0079 - acc: 0.9987 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 131/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 132/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.3758e-04 - acc: 1.0000 - val_loss: 1.9004e-04 - val_acc: 1.0000\n",
      "Epoch 133/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0063 - acc: 0.9987 - val_loss: 9.3281e-04 - val_acc: 1.0000\n",
      "Epoch 134/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 3.4558e-04 - val_acc: 1.0000\n",
      "Epoch 135/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.8997e-04 - acc: 1.0000 - val_loss: 7.4943e-04 - val_acc: 1.0000\n",
      "Epoch 136/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.7398e-04 - acc: 1.0000 - val_loss: 9.0673e-04 - val_acc: 1.0000\n",
      "Epoch 137/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 2.2278e-04 - val_acc: 1.0000\n",
      "Epoch 138/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0271 - val_acc: 0.9844\n",
      "Epoch 139/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9983 - val_loss: 8.5641e-04 - val_acc: 1.0000\n",
      "Epoch 140/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 141/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0051 - acc: 0.9978 - val_loss: 0.0105 - val_acc: 0.9906\n",
      "Epoch 142/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0037 - acc: 0.9978 - val_loss: 0.0092 - val_acc: 0.9938\n",
      "Epoch 143/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0091 - acc: 0.9978 - val_loss: 5.4424e-04 - val_acc: 1.0000\n",
      "Epoch 144/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0072 - acc: 0.9991 - val_loss: 0.0130 - val_acc: 0.9938\n",
      "Epoch 145/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0064 - acc: 0.9991 - val_loss: 0.0063 - val_acc: 0.9969\n",
      "Epoch 146/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 147/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0061 - acc: 0.9978 - val_loss: 0.0131 - val_acc: 0.9969\n",
      "Epoch 148/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0080 - acc: 0.9983 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 149/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0081 - acc: 0.9991 - val_loss: 5.6773e-04 - val_acc: 1.0000\n",
      "Epoch 150/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 7.9893e-04 - acc: 0.9996 - val_loss: 6.2801e-04 - val_acc: 1.0000\n",
      "Epoch 151/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 8.9496e-04 - val_acc: 1.0000\n",
      "Epoch 152/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 2.2859e-04 - acc: 1.0000 - val_loss: 5.6215e-04 - val_acc: 1.0000\n",
      "Epoch 153/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0041 - acc: 0.9996 - val_loss: 0.0344 - val_acc: 0.9938\n",
      "Epoch 154/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 9.7158e-04 - acc: 0.9996 - val_loss: 3.9523e-04 - val_acc: 1.0000\n",
      "Epoch 155/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0123 - acc: 0.9965 - val_loss: 0.0071 - val_acc: 0.9969\n",
      "Epoch 156/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 6.9996e-04 - acc: 0.9996 - val_loss: 0.0035 - val_acc: 0.9969\n",
      "Epoch 157/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.3198e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 158/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.4453e-04 - acc: 1.0000 - val_loss: 2.8361e-04 - val_acc: 1.0000\n",
      "Epoch 159/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.7712e-04 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9969\n",
      "Epoch 160/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.4272e-04 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9969\n",
      "Epoch 161/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0085 - acc: 0.9991 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 162/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 5.1494e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9969\n",
      "Epoch 163/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0075 - val_acc: 0.9938\n",
      "Epoch 164/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.2475e-04 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9969\n",
      "Epoch 165/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 5.7346e-05 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 166/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 5.0611e-04 - acc: 0.9996 - val_loss: 0.0237 - val_acc: 0.9938\n",
      "Epoch 167/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 7.4975e-04 - val_acc: 1.0000\n",
      "Epoch 168/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 169/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.0230 - val_acc: 0.9969\n",
      "Epoch 170/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 171/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.9978 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 172/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0163 - acc: 0.9957 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 173/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.3744e-04 - acc: 0.9996 - val_loss: 4.7563e-04 - val_acc: 1.0000\n",
      "Epoch 174/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0280 - val_acc: 0.9938\n",
      "Epoch 175/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 6.2191e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9938\n",
      "Epoch 176/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 177/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.3702e-04 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 0.9906\n",
      "Epoch 178/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.9013e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 179/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 6.6636e-04 - acc: 0.9996 - val_loss: 0.0091 - val_acc: 0.9938\n",
      "Epoch 180/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0065 - val_acc: 0.9969\n",
      "Epoch 181/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4896e-04 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9969\n",
      "Epoch 182/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 7.0708e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 183/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.0691e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 184/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 185/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 5.2079e-05 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9969\n",
      "Epoch 186/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 4.2332e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 187/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.9221e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 188/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.7036e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9938\n",
      "Epoch 189/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.9505e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 190/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 2.9731e-05 - acc: 1.0000 - val_loss: 9.4350e-04 - val_acc: 1.0000\n",
      "Epoch 191/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 6.7355e-05 - acc: 1.0000 - val_loss: 3.0155e-04 - val_acc: 1.0000\n",
      "Epoch 192/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.6790e-06 - acc: 1.0000 - val_loss: 1.1175e-04 - val_acc: 1.0000\n",
      "Epoch 193/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0085 - val_acc: 0.9938\n",
      "Epoch 194/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.8839e-04 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9969\n",
      "Epoch 195/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0331 - acc: 0.9931 - val_loss: 0.0089 - val_acc: 0.9969\n",
      "Epoch 196/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0194 - acc: 0.9957 - val_loss: 0.0279 - val_acc: 0.9969\n",
      "Epoch 197/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0204 - acc: 0.9952 - val_loss: 0.0281 - val_acc: 0.9938\n",
      "Epoch 198/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0045 - val_acc: 0.9969\n",
      "Epoch 199/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0114 - acc: 0.9974 - val_loss: 0.0610 - val_acc: 0.9812\n",
      "Epoch 200/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0028 - acc: 0.9987 - val_loss: 7.9806e-04 - val_acc: 1.0000\n",
      "Epoch 201/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0077 - acc: 0.9978 - val_loss: 0.0053 - val_acc: 0.9969\n",
      "Epoch 202/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0227 - val_acc: 0.9906\n",
      "Epoch 203/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0043 - acc: 0.9991 - val_loss: 0.0114 - val_acc: 0.9938\n",
      "Epoch 204/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1629e-04 - acc: 1.0000 - val_loss: 1.2563e-04 - val_acc: 1.0000\n",
      "Epoch 205/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.0848e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 206/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 207/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0041 - acc: 0.9996 - val_loss: 0.0155 - val_acc: 0.9938\n",
      "Epoch 208/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 0.9938\n",
      "Epoch 209/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 1.1456e-04 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9938\n",
      "Epoch 210/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 8.3927e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9938\n",
      "Epoch 211/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 6.0551e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9969\n",
      "Epoch 212/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 4.6866e-05 - acc: 1.0000 - val_loss: 5.0216e-04 - val_acc: 1.0000\n",
      "Epoch 213/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 7.1922e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 214/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.7837e-05 - acc: 1.0000 - val_loss: 6.7982e-04 - val_acc: 1.0000\n",
      "Epoch 215/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0032 - val_acc: 0.9969\n",
      "Epoch 216/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0082 - val_acc: 0.9969\n",
      "Epoch 217/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.3446e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 218/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 5.3360e-05 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9969\n",
      "Epoch 219/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.2234e-04 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9969\n",
      "Epoch 220/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 221/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0100 - acc: 0.9983 - val_loss: 0.0028 - val_acc: 0.9969\n",
      "Epoch 222/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0105 - val_acc: 0.9938\n",
      "Epoch 223/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 3.3523e-04 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9969\n",
      "Epoch 224/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.4405e-04 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 225/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 9.4929e-04 - acc: 0.9996 - val_loss: 0.0285 - val_acc: 0.9969\n",
      "Epoch 226/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0049 - acc: 0.9991 - val_loss: 0.0054 - val_acc: 0.9969\n",
      "Epoch 227/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0043 - acc: 0.9974 - val_loss: 0.0037 - val_acc: 0.9969\n",
      "Epoch 228/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 0.0034 - val_acc: 0.9969\n",
      "Epoch 229/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.1744e-04 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9969\n",
      "Epoch 230/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0071 - acc: 0.9987 - val_loss: 0.0034 - val_acc: 0.9969\n",
      "Epoch 231/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 3.5091e-05 - val_acc: 1.0000\n",
      "Epoch 232/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0258 - acc: 0.9974 - val_loss: 0.0332 - val_acc: 0.9938\n",
      "Epoch 233/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0173 - acc: 0.9952 - val_loss: 0.0086 - val_acc: 0.9969\n",
      "Epoch 234/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0048 - acc: 0.9996 - val_loss: 0.0657 - val_acc: 0.9875\n",
      "Epoch 235/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0109 - val_acc: 0.9969\n",
      "Epoch 236/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.3976e-04 - acc: 1.0000 - val_loss: 0.0316 - val_acc: 0.9906\n",
      "Epoch 237/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0179 - val_acc: 0.9969\n",
      "Epoch 238/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 7.3351e-04 - acc: 1.0000 - val_loss: 0.0906 - val_acc: 0.9938\n",
      "Epoch 239/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0157 - val_acc: 0.9969\n",
      "Epoch 240/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 0.0425 - val_acc: 0.9969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.6301e-04 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 0.9969\n",
      "Epoch 242/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.4934e-05 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 0.9969\n",
      "Epoch 243/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.0149 - val_acc: 0.9969\n",
      "Epoch 244/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0021 - acc: 0.9987 - val_loss: 0.0527 - val_acc: 0.9938\n",
      "Epoch 245/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 6.4156e-04 - acc: 0.9996 - val_loss: 0.0607 - val_acc: 0.9938\n",
      "Epoch 246/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.5155e-04 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 0.9938\n",
      "Epoch 247/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.6553e-04 - acc: 1.0000 - val_loss: 1.4793e-04 - val_acc: 1.0000\n",
      "Epoch 248/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 9.8010e-05 - acc: 1.0000 - val_loss: 0.0560 - val_acc: 0.9906\n",
      "Epoch 249/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 7.8513e-05 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 0.9938\n",
      "Epoch 250/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.6882e-05 - acc: 1.0000 - val_loss: 0.0503 - val_acc: 0.9906\n",
      "Epoch 251/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0018e-04 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 0.9938\n",
      "Epoch 252/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0015 - acc: 0.9991 - val_loss: 0.1089 - val_acc: 0.9875\n",
      "Epoch 253/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0093 - acc: 0.9983 - val_loss: 0.0078 - val_acc: 0.9969\n",
      "Epoch 254/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3285e-04 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9969\n",
      "Epoch 255/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.5933e-04 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9969\n",
      "Epoch 256/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0063 - val_acc: 0.9969\n",
      "Epoch 257/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 5.4086e-05 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 0.9969\n",
      "Epoch 258/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 2.8292e-05 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9938\n",
      "Epoch 259/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.2212e-05 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9969\n",
      "Epoch 260/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.4248e-04 - acc: 1.0000 - val_loss: 2.4972e-04 - val_acc: 1.0000\n",
      "Epoch 261/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.0139e-04 - acc: 1.0000 - val_loss: 5.4666e-05 - val_acc: 1.0000\n",
      "Epoch 262/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.9454e-05 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 0.9938\n",
      "Epoch 263/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.6103e-04 - acc: 0.9996 - val_loss: 0.0170 - val_acc: 0.9938\n",
      "Epoch 264/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.9639e-04 - acc: 0.9996 - val_loss: 0.0084 - val_acc: 0.9969\n",
      "Epoch 265/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0067 - val_acc: 0.9938\n",
      "Epoch 266/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 267/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 6.2512e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 268/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.0090 - acc: 0.9987 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 269/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 270/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 3.2072e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 271/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 3.0449e-04 - acc: 1.0000 - val_loss: 2.6703e-04 - val_acc: 1.0000\n",
      "Epoch 272/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.7954e-05 - acc: 1.0000 - val_loss: 8.4154e-04 - val_acc: 1.0000\n",
      "Epoch 273/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.3205e-05 - acc: 1.0000 - val_loss: 4.3697e-04 - val_acc: 1.0000\n",
      "Epoch 274/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.5272e-04 - acc: 0.9996 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 275/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0157 - acc: 0.9983 - val_loss: 0.0154 - val_acc: 0.9969\n",
      "Epoch 276/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0243 - val_acc: 0.9906\n",
      "Epoch 277/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 8.2834e-05 - val_acc: 1.0000\n",
      "Epoch 278/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 6.8596e-04 - val_acc: 1.0000\n",
      "Epoch 279/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 280/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.9364e-04 - acc: 1.0000 - val_loss: 3.2941e-04 - val_acc: 1.0000\n",
      "Epoch 281/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 2.6131e-05 - acc: 1.0000 - val_loss: 2.6750e-04 - val_acc: 1.0000\n",
      "Epoch 282/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.8234e-05 - acc: 1.0000 - val_loss: 2.3914e-04 - val_acc: 1.0000\n",
      "Epoch 283/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 2.9590e-04 - val_acc: 1.0000\n",
      "Epoch 284/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.6730e-04 - acc: 1.0000 - val_loss: 6.5446e-05 - val_acc: 1.0000\n",
      "Epoch 285/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0120 - acc: 0.9987 - val_loss: 0.0261 - val_acc: 0.9969\n",
      "Epoch 286/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 3.4442e-04 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 0.9938\n",
      "Epoch 287/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 2.0800e-04 - val_acc: 1.0000\n",
      "Epoch 288/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0498 - val_acc: 0.9906\n",
      "Epoch 289/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.0028 - val_acc: 0.9969\n",
      "Epoch 290/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 4.6393e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 291/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.0639e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 292/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0525 - val_acc: 0.9906\n",
      "Epoch 293/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0117 - acc: 0.9978 - val_loss: 0.0061 - val_acc: 0.9969\n",
      "Epoch 294/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.7076e-04 - acc: 1.0000 - val_loss: 6.6228e-04 - val_acc: 1.0000\n",
      "Epoch 295/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 3.9093e-04 - acc: 0.9996 - val_loss: 1.0746e-04 - val_acc: 1.0000\n",
      "Epoch 296/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 9.4677e-05 - val_acc: 1.0000\n",
      "Epoch 297/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.5548e-05 - acc: 1.0000 - val_loss: 3.3616e-05 - val_acc: 1.0000\n",
      "Epoch 298/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 299/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 6.2670e-05 - val_acc: 1.0000\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 5.1163e-05 - acc: 1.0000 - val_loss: 3.7591e-05 - val_acc: 1.0000\n",
      "Epoch 301/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.5626e-04 - acc: 1.0000 - val_loss: 9.4090e-05 - val_acc: 1.0000\n",
      "Epoch 302/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 1.2293e-04 - val_acc: 1.0000\n",
      "Epoch 303/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 2.3371e-04 - val_acc: 1.0000\n",
      "Epoch 304/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 305/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0034 - acc: 0.9996 - val_loss: 1.8715e-04 - val_acc: 1.0000\n",
      "Epoch 306/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0124 - acc: 0.9983 - val_loss: 4.2546e-04 - val_acc: 1.0000\n",
      "Epoch 307/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0075 - acc: 0.9991 - val_loss: 0.0147 - val_acc: 0.9938\n",
      "Epoch 308/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.3210e-04 - acc: 1.0000 - val_loss: 8.4874e-04 - val_acc: 1.0000\n",
      "Epoch 309/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0931e-04 - acc: 1.0000 - val_loss: 9.8590e-05 - val_acc: 1.0000\n",
      "Epoch 310/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.0805e-04 - acc: 1.0000 - val_loss: 3.4270e-04 - val_acc: 1.0000\n",
      "Epoch 311/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.9111e-04 - acc: 0.9996 - val_loss: 0.0153 - val_acc: 0.9969\n",
      "Epoch 312/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0077 - acc: 0.9987 - val_loss: 2.0228e-04 - val_acc: 1.0000\n",
      "Epoch 313/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0132 - acc: 0.9987 - val_loss: 5.5416e-05 - val_acc: 1.0000\n",
      "Epoch 314/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4538e-04 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9969\n",
      "Epoch 315/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.8542e-04 - acc: 1.0000 - val_loss: 0.0525 - val_acc: 0.9938\n",
      "Epoch 316/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.9142e-04 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 0.9938\n",
      "Epoch 317/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.2115e-05 - acc: 1.0000 - val_loss: 1.1178e-05 - val_acc: 1.0000\n",
      "Epoch 318/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.5435e-04 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9969\n",
      "Epoch 319/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.4357e-05 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9969\n",
      "Epoch 320/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.0476e-05 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 0.9969\n",
      "Epoch 321/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4605e-05 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 0.9969\n",
      "Epoch 322/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.3169e-05 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9938\n",
      "Epoch 323/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.9037e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9969\n",
      "Epoch 324/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 2.4463e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9969\n",
      "Epoch 325/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.3620e-05 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9969\n",
      "Epoch 326/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 1.1968e-05 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 0.9969\n",
      "Epoch 327/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0038 - acc: 0.9996 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 328/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0097 - acc: 0.9983 - val_loss: 0.0410 - val_acc: 0.9906\n",
      "Epoch 329/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.4279e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 330/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 331/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 4.9950e-04 - val_acc: 1.0000\n",
      "Epoch 332/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.1681e-05 - acc: 1.0000 - val_loss: 5.8806e-04 - val_acc: 1.0000\n",
      "Epoch 333/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.3784e-05 - acc: 1.0000 - val_loss: 2.8756e-05 - val_acc: 1.0000\n",
      "Epoch 334/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.2848e-05 - acc: 1.0000 - val_loss: 9.7872e-06 - val_acc: 1.0000\n",
      "Epoch 335/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0051 - acc: 0.9991 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 336/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 7.6832e-05 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9938\n",
      "Epoch 337/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0045 - acc: 0.9991 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 338/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0094 - acc: 0.9978 - val_loss: 0.0057 - val_acc: 0.9969\n",
      "Epoch 339/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0117 - acc: 0.9974 - val_loss: 0.0085 - val_acc: 0.9969\n",
      "Epoch 340/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0109 - acc: 0.9970 - val_loss: 0.0403 - val_acc: 0.9938\n",
      "Epoch 341/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0177 - val_acc: 0.9969\n",
      "Epoch 342/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 343/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0105 - val_acc: 0.9969\n",
      "Epoch 344/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0213 - val_acc: 0.9969\n",
      "Epoch 345/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 2.4234e-04 - acc: 1.0000 - val_loss: 8.7072e-05 - val_acc: 1.0000\n",
      "Epoch 346/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 5.3721e-05 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9969\n",
      "Epoch 347/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 4.0789e-05 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 0.9969\n",
      "Epoch 348/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.4591e-05 - acc: 1.0000 - val_loss: 1.1720e-04 - val_acc: 1.0000\n",
      "Epoch 349/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 3.6236e-05 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 0.9969\n",
      "Epoch 350/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0055 - acc: 0.9996 - val_loss: 0.0235 - val_acc: 0.9969\n",
      "Epoch 351/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0931e-04 - acc: 1.0000 - val_loss: 0.0421 - val_acc: 0.9938\n",
      "Epoch 352/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0330 - val_acc: 0.9938\n",
      "Epoch 353/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.1212e-05 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 0.9938\n",
      "Epoch 354/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 4.3754e-05 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9969\n",
      "Epoch 355/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 3.9788e-05 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9969\n",
      "Epoch 356/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.1788e-05 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9969\n",
      "Epoch 357/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 2.7619e-05 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 0.9969\n",
      "Epoch 358/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.2374e-05 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 0.9938\n",
      "Epoch 359/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 1.9471e-05 - acc: 1.0000 - val_loss: 1.4801e-04 - val_acc: 1.0000\n",
      "Epoch 360/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.8494e-05 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 0.9969\n",
      "Epoch 361/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.6697e-05 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9969\n",
      "Epoch 362/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.4482e-05 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9938\n",
      "Epoch 363/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3780e-05 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 0.9969\n",
      "Epoch 364/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1419e-05 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9969\n",
      "Epoch 365/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 8.4483e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9969\n",
      "Epoch 366/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 8.3900e-06 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9938\n",
      "Epoch 367/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.5484e-06 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9969\n",
      "Epoch 368/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.7050e-06 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9969\n",
      "Epoch 369/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.8535e-06 - acc: 1.0000 - val_loss: 1.3256e-05 - val_acc: 1.0000\n",
      "Epoch 370/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4244e-06 - acc: 1.0000 - val_loss: 4.3870e-04 - val_acc: 1.0000\n",
      "Epoch 371/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4791e-06 - acc: 1.0000 - val_loss: 5.1521e-07 - val_acc: 1.0000\n",
      "Epoch 372/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.0805e-06 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 0.9938\n",
      "Epoch 373/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.6111e-06 - acc: 1.0000 - val_loss: 1.3220e-05 - val_acc: 1.0000\n",
      "Epoch 374/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 1.1142e-06 - acc: 1.0000 - val_loss: 8.1967e-04 - val_acc: 1.0000\n",
      "Epoch 375/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.6699e-06 - acc: 1.0000 - val_loss: 6.0667e-04 - val_acc: 1.0000\n",
      "Epoch 376/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4689e-06 - acc: 1.0000 - val_loss: 5.2588e-04 - val_acc: 1.0000\n",
      "Epoch 377/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0117 - acc: 0.9991 - val_loss: 4.3294e-04 - val_acc: 1.0000\n",
      "Epoch 378/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0305 - acc: 0.9952 - val_loss: 1.8929e-04 - val_acc: 1.0000\n",
      "Epoch 379/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0053 - acc: 0.9996 - val_loss: 4.5068e-04 - val_acc: 1.0000\n",
      "Epoch 380/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 2.7111e-04 - val_acc: 1.0000\n",
      "Epoch 381/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0072 - acc: 0.9991 - val_loss: 4.2169e-04 - val_acc: 1.0000\n",
      "Epoch 382/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0050 - val_acc: 0.9969\n",
      "Epoch 383/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0095 - acc: 0.9987 - val_loss: 0.0388 - val_acc: 0.9969\n",
      "Epoch 384/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0100 - acc: 0.9978 - val_loss: 0.0069 - val_acc: 0.9969\n",
      "Epoch 385/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 6.8227e-04 - acc: 0.9996 - val_loss: 0.0303 - val_acc: 0.9938\n",
      "Epoch 386/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.0216 - val_acc: 0.9969\n",
      "Epoch 387/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.0970e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 388/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0416 - val_acc: 0.9938\n",
      "Epoch 389/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 5.3654e-05 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9969\n",
      "Epoch 390/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 1.0409e-04 - val_acc: 1.0000\n",
      "Epoch 391/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 8.7519e-05 - acc: 1.0000 - val_loss: 6.8221e-04 - val_acc: 1.0000\n",
      "Epoch 392/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0286 - val_acc: 0.9969\n",
      "Epoch 393/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 4.6186e-05 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9969\n",
      "Epoch 394/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 3.6274e-05 - acc: 1.0000 - val_loss: 0.0211 - val_acc: 0.9969\n",
      "Epoch 395/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 3.1031e-05 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 0.9969\n",
      "Epoch 396/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0076 - acc: 0.9987 - val_loss: 0.0578 - val_acc: 0.9938\n",
      "Epoch 397/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0091 - acc: 0.9987 - val_loss: 0.0357 - val_acc: 0.9969\n",
      "Epoch 398/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 6.3678e-05 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 0.9969\n",
      "Epoch 399/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 5.7260e-05 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9969\n",
      "Epoch 400/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 6.1746e-04 - acc: 0.9996 - val_loss: 0.0408 - val_acc: 0.9969\n",
      "Epoch 401/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0064 - acc: 0.9991 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 402/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0175 - acc: 0.9983 - val_loss: 0.1019 - val_acc: 0.9906\n",
      "Epoch 403/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1144 - acc: 0.9883 - val_loss: 0.0212 - val_acc: 0.9969\n",
      "Epoch 404/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0274 - acc: 0.9965 - val_loss: 0.0320 - val_acc: 0.9969\n",
      "Epoch 405/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0274 - val_acc: 0.9938\n",
      "Epoch 406/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0124 - val_acc: 0.9969\n",
      "Epoch 407/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4162e-04 - acc: 1.0000 - val_loss: 5.5701e-05 - val_acc: 1.0000\n",
      "Epoch 408/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.7235e-05 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 0.9969\n",
      "Epoch 409/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0049 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9969\n",
      "Epoch 410/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 4.7406e-05 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 0.9938\n",
      "Epoch 411/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 9.3615e-05 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 0.9938\n",
      "Epoch 412/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.4311e-05 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9969\n",
      "Epoch 413/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.3999e-04 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9969\n",
      "Epoch 414/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 2.2057e-04 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9969\n",
      "Epoch 415/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.7351e-04 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 0.9938\n",
      "Epoch 416/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 2.7779e-05 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9906\n",
      "Epoch 417/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.6536e-05 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9969\n",
      "Epoch 418/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 2.0621e-05 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 0.9938\n",
      "Epoch 419/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.0941e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9938\n",
      "Epoch 420/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0163 - val_acc: 0.9938\n",
      "Epoch 421/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 1.0488e-04 - val_acc: 1.0000\n",
      "Epoch 422/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.3262e-04 - acc: 0.9996 - val_loss: 2.2952e-05 - val_acc: 1.0000\n",
      "Epoch 423/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.8132e-06 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 0.9938\n",
      "Epoch 424/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0066 - acc: 0.9996 - val_loss: 0.0109 - val_acc: 0.9938\n",
      "Epoch 425/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 4.0294e-05 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9938\n",
      "Epoch 426/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.3235e-05 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9938\n",
      "Epoch 427/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2701e-04 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 0.9906\n",
      "Epoch 428/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.1055e-05 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9938\n",
      "Epoch 429/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3550e-05 - acc: 1.0000 - val_loss: 0.0820 - val_acc: 0.9875\n",
      "Epoch 430/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.4191e-05 - acc: 1.0000 - val_loss: 1.3066e-04 - val_acc: 1.0000\n",
      "Epoch 431/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.0671e-05 - acc: 1.0000 - val_loss: 0.0300 - val_acc: 0.9938\n",
      "Epoch 432/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 0.0088 - val_acc: 0.9969\n",
      "Epoch 433/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.0063 - acc: 0.9991 - val_loss: 9.1172e-04 - val_acc: 1.0000\n",
      "Epoch 434/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.0766e-05 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9969\n",
      "Epoch 435/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.9138e-05 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9969\n",
      "Epoch 436/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.9480e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9969\n",
      "Epoch 437/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.7590e-05 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9969\n",
      "Epoch 438/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2359e-05 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9969\n",
      "Epoch 439/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.8663e-05 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9969\n",
      "Epoch 440/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0061 - acc: 0.9996 - val_loss: 0.0444 - val_acc: 0.9938\n",
      "Epoch 441/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0247 - val_acc: 0.9969\n",
      "Epoch 442/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 3.3504e-04 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9969\n",
      "Epoch 443/1000\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0073 - acc: 0.9996 - val_loss: 0.1531 - val_acc: 0.9750\n",
      "Epoch 444/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0138 - val_acc: 0.9938\n",
      "Epoch 445/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 2.3996e-05 - val_acc: 1.0000\n",
      "Epoch 446/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0120 - acc: 0.9983 - val_loss: 0.0199 - val_acc: 0.9969\n",
      "Epoch 447/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0043 - acc: 0.9996 - val_loss: 0.0112 - val_acc: 0.9969\n",
      "Epoch 448/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0903 - val_acc: 0.9875\n",
      "Epoch 449/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0101 - val_acc: 0.9969\n",
      "Epoch 450/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0145 - val_acc: 0.9969\n",
      "Epoch 451/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 3.5366e-05 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 452/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0206 - val_acc: 0.9969\n",
      "Epoch 453/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 8.6169e-05 - acc: 1.0000 - val_loss: 2.4414e-04 - val_acc: 1.0000\n",
      "Epoch 454/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 1.0450e-04 - val_acc: 1.0000\n",
      "Epoch 455/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0052 - acc: 0.9991 - val_loss: 0.0058 - val_acc: 0.9969\n",
      "Epoch 456/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 8.3022e-06 - acc: 1.0000 - val_loss: 6.4085e-06 - val_acc: 1.0000\n",
      "Epoch 457/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 3.0280e-06 - acc: 1.0000 - val_loss: 4.1588e-04 - val_acc: 1.0000\n",
      "Epoch 458/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 3.0634e-06 - acc: 1.0000 - val_loss: 2.1037e-04 - val_acc: 1.0000\n",
      "Epoch 459/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0050 - val_acc: 0.9969\n",
      "Epoch 460/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0055 - acc: 0.9991 - val_loss: 7.2118e-05 - val_acc: 1.0000\n",
      "Epoch 461/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0054 - acc: 0.9996 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 462/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.3878e-05 - acc: 1.0000 - val_loss: 5.3856e-05 - val_acc: 1.0000\n",
      "Epoch 463/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 7.1492e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 464/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 5.2737e-06 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 465/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0053 - acc: 0.9996 - val_loss: 0.0027 - val_acc: 0.9969\n",
      "Epoch 466/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.1980e-04 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9969\n",
      "Epoch 467/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 2.3718e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 468/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.5854e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 469/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.2179e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 470/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.8611e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 471/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.0568e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 472/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 8.5835e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 473/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.6605e-06 - acc: 1.0000 - val_loss: 9.0603e-04 - val_acc: 1.0000\n",
      "Epoch 474/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.0190e-05 - acc: 1.0000 - val_loss: 7.8976e-04 - val_acc: 1.0000\n",
      "Epoch 475/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4500e-05 - acc: 1.0000 - val_loss: 5.3487e-05 - val_acc: 1.0000\n",
      "Epoch 476/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0143 - acc: 0.9978 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 477/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 8.6710e-05 - acc: 1.0000 - val_loss: 1.8539e-04 - val_acc: 1.0000\n",
      "Epoch 478/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.9684e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 479/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.5565e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 480/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1835e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 481/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3709e-05 - acc: 1.0000 - val_loss: 2.1778e-05 - val_acc: 1.0000\n",
      "Epoch 482/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 3.3471e-05 - acc: 1.0000 - val_loss: 1.9234e-04 - val_acc: 1.0000\n",
      "Epoch 483/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0103 - acc: 0.9987 - val_loss: 1.1897e-04 - val_acc: 1.0000\n",
      "Epoch 484/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.6767e-04 - acc: 0.9996 - val_loss: 3.5681e-04 - val_acc: 1.0000\n",
      "Epoch 485/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0085 - acc: 0.9983 - val_loss: 7.0304e-05 - val_acc: 1.0000\n",
      "Epoch 486/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.1702e-04 - acc: 1.0000 - val_loss: 7.0420e-05 - val_acc: 1.0000\n",
      "Epoch 487/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.5422e-04 - acc: 0.9996 - val_loss: 2.8888e-06 - val_acc: 1.0000\n",
      "Epoch 488/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1452e-05 - acc: 1.0000 - val_loss: 1.7767e-05 - val_acc: 1.0000\n",
      "Epoch 489/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.6034e-05 - acc: 1.0000 - val_loss: 8.7264e-06 - val_acc: 1.0000\n",
      "Epoch 490/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.5068e-06 - acc: 1.0000 - val_loss: 1.1591e-05 - val_acc: 1.0000\n",
      "Epoch 491/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 4.5924e-06 - acc: 1.0000 - val_loss: 7.4801e-06 - val_acc: 1.0000\n",
      "Epoch 492/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 5.5278e-04 - val_acc: 1.0000\n",
      "Epoch 493/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0564e-04 - acc: 1.0000 - val_loss: 6.5830e-05 - val_acc: 1.0000\n",
      "Epoch 494/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.0676e-05 - acc: 1.0000 - val_loss: 7.0454e-05 - val_acc: 1.0000\n",
      "Epoch 495/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.0924e-05 - acc: 1.0000 - val_loss: 6.0194e-05 - val_acc: 1.0000\n",
      "Epoch 496/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.3216e-04 - acc: 0.9996 - val_loss: 5.6483e-05 - val_acc: 1.0000\n",
      "Epoch 497/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.5692e-05 - acc: 1.0000 - val_loss: 5.5118e-05 - val_acc: 1.0000\n",
      "Epoch 498/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1236e-05 - acc: 1.0000 - val_loss: 3.5277e-05 - val_acc: 1.0000\n",
      "Epoch 499/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.9573e-06 - acc: 1.0000 - val_loss: 2.9281e-05 - val_acc: 1.0000\n",
      "Epoch 500/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0082 - acc: 0.9991 - val_loss: 9.3134e-04 - val_acc: 1.0000\n",
      "Epoch 501/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0104 - acc: 0.9987 - val_loss: 4.3400e-07 - val_acc: 1.0000\n",
      "Epoch 502/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 0.0059 - acc: 0.9991 - val_loss: 1.0113e-05 - val_acc: 1.0000\n",
      "Epoch 503/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 3.0018e-06 - acc: 1.0000 - val_loss: 1.3080e-04 - val_acc: 1.0000\n",
      "Epoch 504/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.3559e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 505/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 7.4714e-06 - acc: 1.0000 - val_loss: 1.5153e-04 - val_acc: 1.0000\n",
      "Epoch 506/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 9.4735e-05 - acc: 1.0000 - val_loss: 6.3047e-04 - val_acc: 1.0000\n",
      "Epoch 507/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 8.8895e-04 - acc: 0.9996 - val_loss: 1.3237e-06 - val_acc: 1.0000\n",
      "Epoch 508/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0073 - val_acc: 0.9938\n",
      "Epoch 509/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.4179e-05 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9969\n",
      "Epoch 510/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.4494e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 511/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 5.8095e-06 - acc: 1.0000 - val_loss: 6.4396e-04 - val_acc: 1.0000\n",
      "Epoch 512/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 6.5335e-06 - acc: 1.0000 - val_loss: 1.0683e-05 - val_acc: 1.0000\n",
      "Epoch 513/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 3.4719e-06 - acc: 1.0000 - val_loss: 5.0591e-06 - val_acc: 1.0000\n",
      "Epoch 514/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 4.8050e-06 - acc: 1.0000 - val_loss: 4.2497e-04 - val_acc: 1.0000\n",
      "Epoch 515/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 3.9941e-06 - acc: 1.0000 - val_loss: 1.5510e-05 - val_acc: 1.0000\n",
      "Epoch 516/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 3.5937e-06 - acc: 1.0000 - val_loss: 1.5982e-04 - val_acc: 1.0000\n",
      "Epoch 517/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 2.5720e-06 - acc: 1.0000 - val_loss: 1.4660e-04 - val_acc: 1.0000\n",
      "Epoch 518/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0070 - acc: 0.9991 - val_loss: 0.0039 - val_acc: 0.9969\n",
      "Epoch 519/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0043 - acc: 0.9996 - val_loss: 0.0040 - val_acc: 0.9969\n",
      "Epoch 520/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0082 - acc: 0.9987 - val_loss: 0.0629 - val_acc: 0.9906\n",
      "Epoch 521/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 1.1308e-04 - val_acc: 1.0000\n",
      "Epoch 522/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0052 - acc: 0.9996 - val_loss: 5.3871e-05 - val_acc: 1.0000\n",
      "Epoch 523/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.2154e-05 - acc: 1.0000 - val_loss: 5.5261e-04 - val_acc: 1.0000\n",
      "Epoch 524/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.4974e-04 - acc: 0.9996 - val_loss: 0.0198 - val_acc: 0.9938\n",
      "Epoch 525/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.3704e-04 - acc: 1.0000 - val_loss: 3.5642e-04 - val_acc: 1.0000\n",
      "Epoch 526/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.4167e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 527/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.1325e-04 - acc: 1.0000 - val_loss: 9.6819e-04 - val_acc: 1.0000\n",
      "Epoch 528/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 9.5087e-06 - acc: 1.0000 - val_loss: 8.7800e-04 - val_acc: 1.0000\n",
      "Epoch 529/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.7474e-06 - acc: 1.0000 - val_loss: 8.6735e-05 - val_acc: 1.0000\n",
      "Epoch 530/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 7.5333e-06 - acc: 1.0000 - val_loss: 6.5437e-04 - val_acc: 1.0000\n",
      "Epoch 531/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 8.1628e-06 - acc: 1.0000 - val_loss: 5.9909e-04 - val_acc: 1.0000\n",
      "Epoch 532/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 5.9931e-06 - acc: 1.0000 - val_loss: 6.8866e-05 - val_acc: 1.0000\n",
      "Epoch 533/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 6.5733e-06 - acc: 1.0000 - val_loss: 4.2037e-04 - val_acc: 1.0000\n",
      "Epoch 534/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.7447e-06 - acc: 1.0000 - val_loss: 2.9767e-04 - val_acc: 1.0000\n",
      "Epoch 535/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 5.2662e-06 - acc: 1.0000 - val_loss: 2.5486e-04 - val_acc: 1.0000\n",
      "Epoch 536/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.9697e-06 - acc: 1.0000 - val_loss: 2.1196e-04 - val_acc: 1.0000\n",
      "Epoch 537/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 4.7114e-06 - acc: 1.0000 - val_loss: 1.8269e-04 - val_acc: 1.0000\n",
      "Epoch 538/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.0702e-06 - acc: 1.0000 - val_loss: 1.4669e-04 - val_acc: 1.0000\n",
      "Epoch 539/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.3463e-05 - acc: 1.0000 - val_loss: 1.7465e-05 - val_acc: 1.0000\n",
      "Epoch 540/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1319e-06 - acc: 1.0000 - val_loss: 4.8318e-07 - val_acc: 1.0000\n",
      "Epoch 541/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 9.9034e-07 - acc: 1.0000 - val_loss: 5.3160e-07 - val_acc: 1.0000\n",
      "Epoch 542/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0066 - acc: 0.9991 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 543/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0049 - acc: 0.9991 - val_loss: 2.3563e-05 - val_acc: 1.0000\n",
      "Epoch 544/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.3020e-06 - acc: 1.0000 - val_loss: 1.0173e-05 - val_acc: 1.0000\n",
      "Epoch 545/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 546/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0076 - acc: 0.9991 - val_loss: 2.2836e-07 - val_acc: 1.0000\n",
      "Epoch 547/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0249 - acc: 0.9974 - val_loss: 1.9297e-07 - val_acc: 1.0000\n",
      "Epoch 548/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.8647e-06 - acc: 1.0000 - val_loss: 3.3062e-07 - val_acc: 1.0000\n",
      "Epoch 549/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0084 - acc: 0.9991 - val_loss: 1.5067e-04 - val_acc: 1.0000\n",
      "Epoch 550/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.0360e-04 - acc: 1.0000 - val_loss: 9.7638e-05 - val_acc: 1.0000\n",
      "Epoch 551/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.6178e-06 - acc: 1.0000 - val_loss: 6.1517e-06 - val_acc: 1.0000\n",
      "Epoch 552/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.3760e-06 - acc: 1.0000 - val_loss: 5.6284e-05 - val_acc: 1.0000\n",
      "Epoch 553/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.1660e-06 - acc: 1.0000 - val_loss: 8.7836e-06 - val_acc: 1.0000\n",
      "Epoch 554/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0705 - val_acc: 0.9906\n",
      "Epoch 555/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.3484e-05 - acc: 1.0000 - val_loss: 0.0306 - val_acc: 0.9969\n",
      "Epoch 556/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.0374e-06 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 0.9969\n",
      "Epoch 557/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.5985e-06 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 0.9969\n",
      "Epoch 558/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.7324e-06 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 0.9969\n",
      "Epoch 559/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.4921e-06 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 0.9969\n",
      "Epoch 560/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 1.4006e-05 - acc: 1.0000 - val_loss: 0.0459 - val_acc: 0.9938\n",
      "Epoch 561/1000\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 8.9700e-06 - acc: 1.0000 - val_loss: 0.0449 - val_acc: 0.9938\n",
      "Epoch 562/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 7.9644e-06 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 563/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 7.3536e-06 - acc: 1.0000 - val_loss: 0.0505 - val_acc: 0.9969\n",
      "Epoch 564/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 6.8844e-06 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 565/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 6.9061e-06 - acc: 1.0000 - val_loss: 1.1691e-04 - val_acc: 1.0000\n",
      "Epoch 566/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 7.0446e-04 - acc: 0.9996 - val_loss: 0.0414 - val_acc: 0.9969\n",
      "Epoch 567/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 4.2684e-06 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 0.9969\n",
      "Epoch 568/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.6594e-06 - acc: 1.0000 - val_loss: 0.0392 - val_acc: 0.9969\n",
      "Epoch 569/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 3.4648e-06 - acc: 1.0000 - val_loss: 0.0387 - val_acc: 0.9969\n",
      "Epoch 570/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0034 - acc: 0.9996 - val_loss: 0.0592 - val_acc: 0.9938\n",
      "Epoch 571/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0103 - acc: 0.9991 - val_loss: 2.0080e-06 - val_acc: 1.0000\n",
      "Epoch 572/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.9732e-06 - acc: 1.0000 - val_loss: 1.7360e-06 - val_acc: 1.0000\n",
      "Epoch 573/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0077 - acc: 0.9987 - val_loss: 6.0820e-06 - val_acc: 1.0000\n",
      "Epoch 574/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 3.4509e-06 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9969\n",
      "Epoch 575/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 3.4160e-06 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9969\n",
      "Epoch 576/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 3.2440e-06 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 0.9969\n",
      "Epoch 577/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 3.3524e-06 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9969\n",
      "Epoch 578/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 9.8775e-04 - acc: 0.9996 - val_loss: 0.0053 - val_acc: 0.9969\n",
      "Epoch 579/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 3.0657e-06 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9969\n",
      "Epoch 580/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 7.4688e-06 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 0.9938\n",
      "Epoch 581/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 2.4947e-06 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9969\n",
      "Epoch 582/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.1595e-06 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9938\n",
      "Epoch 583/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.7689e-04 - acc: 0.9996 - val_loss: 0.0139 - val_acc: 0.9969\n",
      "Epoch 584/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 8.4930e-06 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9969\n",
      "Epoch 585/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 6.2338e-06 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9969\n",
      "Epoch 586/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 4.9549e-06 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9969\n",
      "Epoch 587/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.3198e-04 - acc: 1.0000 - val_loss: 0.0981 - val_acc: 0.9875\n",
      "Epoch 588/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0063 - acc: 0.9987 - val_loss: 0.0997 - val_acc: 0.9906\n",
      "Epoch 589/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0040 - val_acc: 0.9969\n",
      "Epoch 590/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.1803e-06 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9969\n",
      "Epoch 591/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 4.9293e-06 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9938\n",
      "Epoch 592/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.2599e-06 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9969\n",
      "Epoch 593/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0441 - val_acc: 0.9969\n",
      "Epoch 594/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 10ms/step - loss: 4.1125e-06 - acc: 1.0000 - val_loss: 0.0411 - val_acc: 0.9969\n",
      "Epoch 595/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 4.2903e-06 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 0.9969\n",
      "Epoch 596/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.8997e-06 - acc: 1.0000 - val_loss: 0.0405 - val_acc: 0.9969\n",
      "Epoch 597/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.2249e-05 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 0.9969\n",
      "Epoch 598/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.1068 - val_acc: 0.9906\n",
      "Epoch 599/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0054 - acc: 0.9996 - val_loss: 0.0255 - val_acc: 0.9938\n",
      "Epoch 600/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.3628e-06 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9969\n",
      "Epoch 601/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.1460e-06 - acc: 1.0000 - val_loss: 1.5840e-05 - val_acc: 1.0000\n",
      "Epoch 602/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.7797e-06 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9969\n",
      "Epoch 603/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.1524e-06 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9969\n",
      "Epoch 604/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.2846e-06 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9969\n",
      "Epoch 605/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.8618e-06 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9969\n",
      "Epoch 606/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.1452e-06 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9969\n",
      "Epoch 607/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 2.8543e-06 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9969\n",
      "Epoch 608/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 2.5370e-06 - acc: 1.0000 - val_loss: 1.2169e-06 - val_acc: 1.0000\n",
      "Epoch 609/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.1479e-06 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9969\n",
      "Epoch 610/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.5320e-06 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9969\n",
      "Epoch 611/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.8874e-06 - acc: 1.0000 - val_loss: 3.9339e-06 - val_acc: 1.0000\n",
      "Epoch 612/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.4489e-06 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9969\n",
      "Epoch 613/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.1019e-06 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9969\n",
      "Epoch 614/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.4439e-06 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 0.9969\n",
      "Epoch 615/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.9133e-06 - acc: 1.0000 - val_loss: 0.0248 - val_acc: 0.9969\n",
      "Epoch 616/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.9988e-06 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 0.9969\n",
      "Epoch 617/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 3.8663e-06 - acc: 1.0000 - val_loss: 0.0252 - val_acc: 0.9969\n",
      "Epoch 618/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 2.1456e-04 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 619/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 1.5295e-04 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 620/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0083 - acc: 0.9987 - val_loss: 0.0508 - val_acc: 0.9969\n",
      "Epoch 621/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 2.1174e-06 - acc: 1.0000 - val_loss: 0.0487 - val_acc: 0.9969\n",
      "Epoch 622/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 0.0817 - val_acc: 0.9906\n",
      "Epoch 623/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0143 - acc: 0.9987 - val_loss: 0.0133 - val_acc: 0.9969\n",
      "Epoch 624/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0196 - val_acc: 0.9969\n",
      "Epoch 625/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.1861e-06 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 0.9938\n",
      "Epoch 626/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 9.5230e-04 - acc: 0.9991 - val_loss: 0.1008 - val_acc: 0.9938\n",
      "Epoch 627/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 7.0351e-06 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 628/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.1757e-06 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 629/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0505 - val_acc: 0.9969\n",
      "Epoch 630/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0370 - val_acc: 0.9969\n",
      "Epoch 631/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0015 - acc: 0.9987 - val_loss: 0.0631 - val_acc: 0.9938\n",
      "Epoch 632/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 1.1441e-05 - acc: 1.0000 - val_loss: 0.0511 - val_acc: 0.9969\n",
      "Epoch 633/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 5.8556e-06 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9938\n",
      "Epoch 634/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 5.0313e-04 - acc: 0.9996 - val_loss: 0.1016 - val_acc: 0.9938\n",
      "Epoch 635/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 8.9955e-04 - acc: 0.9996 - val_loss: 2.9923e-06 - val_acc: 1.0000\n",
      "Epoch 636/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 5.5713e-06 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9938\n",
      "Epoch 637/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 4.2989e-06 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 638/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 2.5232e-06 - acc: 1.0000 - val_loss: 0.0494 - val_acc: 0.9969\n",
      "Epoch 639/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 8.6586e-06 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 0.9969\n",
      "Epoch 640/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.1501e-06 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9969\n",
      "Epoch 641/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.9096e-06 - acc: 1.0000 - val_loss: 1.2561e-06 - val_acc: 1.0000\n",
      "Epoch 642/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 2.1221e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 643/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 0.0246 - val_acc: 0.9938\n",
      "Epoch 644/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.5743e-06 - acc: 1.0000 - val_loss: 0.0359 - val_acc: 0.9938\n",
      "Epoch 645/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.8132e-06 - acc: 1.0000 - val_loss: 0.0528 - val_acc: 0.9938\n",
      "Epoch 646/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0193 - val_acc: 0.9969\n",
      "Epoch 647/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.6849e-05 - acc: 1.0000 - val_loss: 1.6354e-04 - val_acc: 1.0000\n",
      "Epoch 648/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2447e-05 - acc: 1.0000 - val_loss: 5.4701e-05 - val_acc: 1.0000\n",
      "Epoch 649/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 2.7180e-05 - val_acc: 1.0000\n",
      "Epoch 650/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1694e-05 - acc: 1.0000 - val_loss: 3.2962e-05 - val_acc: 1.0000\n",
      "Epoch 651/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0791e-05 - acc: 1.0000 - val_loss: 8.1905e-06 - val_acc: 1.0000\n",
      "Epoch 652/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0382e-05 - acc: 1.0000 - val_loss: 5.1424e-06 - val_acc: 1.0000\n",
      "Epoch 653/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 17ms/step - loss: 9.4037e-06 - acc: 1.0000 - val_loss: 2.7551e-06 - val_acc: 1.0000\n",
      "Epoch 654/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 7.5610e-06 - acc: 1.0000 - val_loss: 3.8599e-06 - val_acc: 1.0000\n",
      "Epoch 655/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.0865e-06 - acc: 1.0000 - val_loss: 2.0806e-07 - val_acc: 1.0000\n",
      "Epoch 656/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0057 - acc: 0.9996 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 657/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0199 - acc: 0.9974 - val_loss: 4.4756e-05 - val_acc: 1.0000\n",
      "Epoch 658/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0104 - acc: 0.9991 - val_loss: 3.9211e-04 - val_acc: 1.0000\n",
      "Epoch 659/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0235 - acc: 0.9978 - val_loss: 5.2522e-04 - val_acc: 1.0000\n",
      "Epoch 660/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.6713e-05 - acc: 1.0000 - val_loss: 6.8860e-04 - val_acc: 1.0000\n",
      "Epoch 661/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.1715e-04 - acc: 0.9996 - val_loss: 3.2466e-04 - val_acc: 1.0000\n",
      "Epoch 662/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.2880e-06 - acc: 1.0000 - val_loss: 1.6513e-04 - val_acc: 1.0000\n",
      "Epoch 663/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 1.6618e-04 - val_acc: 1.0000\n",
      "Epoch 664/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0094 - acc: 0.9987 - val_loss: 1.1426e-04 - val_acc: 1.0000\n",
      "Epoch 665/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5851e-06 - acc: 1.0000 - val_loss: 2.6852e-04 - val_acc: 1.0000\n",
      "Epoch 666/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0055 - acc: 0.9996 - val_loss: 1.8352e-05 - val_acc: 1.0000\n",
      "Epoch 667/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.0865e-05 - acc: 1.0000 - val_loss: 4.6597e-04 - val_acc: 1.0000\n",
      "Epoch 668/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1521e-05 - acc: 1.0000 - val_loss: 3.4343e-04 - val_acc: 1.0000\n",
      "Epoch 669/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3789e-05 - acc: 1.0000 - val_loss: 8.6360e-04 - val_acc: 1.0000\n",
      "Epoch 670/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.7497e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 671/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0067 - acc: 0.9987 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 672/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.3594e-05 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 0.9969\n",
      "Epoch 673/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0214 - acc: 0.9987 - val_loss: 0.0706 - val_acc: 0.9875\n",
      "Epoch 674/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.1756e-05 - acc: 1.0000 - val_loss: 3.4589e-07 - val_acc: 1.0000\n",
      "Epoch 675/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 5.7358e-06 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 0.9938\n",
      "Epoch 676/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 2.9902e-05 - acc: 1.0000 - val_loss: 2.4243e-06 - val_acc: 1.0000\n",
      "Epoch 677/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 4.6469e-06 - acc: 1.0000 - val_loss: 1.2797e-06 - val_acc: 1.0000\n",
      "Epoch 678/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0045 - acc: 0.9991 - val_loss: 7.8410e-04 - val_acc: 1.0000\n",
      "Epoch 679/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.0663e-05 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 680/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0047 - acc: 0.9996 - val_loss: 0.0164 - val_acc: 0.9938\n",
      "Epoch 681/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0051 - acc: 0.9991 - val_loss: 0.0399 - val_acc: 0.9969\n",
      "Epoch 682/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 1.2537e-04 - val_acc: 1.0000\n",
      "Epoch 683/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.8097e-06 - acc: 1.0000 - val_loss: 1.0296e-05 - val_acc: 1.0000\n",
      "Epoch 684/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 6.6728e-06 - acc: 1.0000 - val_loss: 4.6946e-04 - val_acc: 1.0000\n",
      "Epoch 685/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.2248e-06 - acc: 1.0000 - val_loss: 4.8934e-04 - val_acc: 1.0000\n",
      "Epoch 686/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.8068e-06 - acc: 1.0000 - val_loss: 5.0626e-04 - val_acc: 1.0000\n",
      "Epoch 687/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.1143e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 688/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.2447e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 689/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 1.9684e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 690/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 1.0299e-05 - acc: 1.0000 - val_loss: 5.4968e-04 - val_acc: 1.0000\n",
      "Epoch 691/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 7.7577e-06 - val_acc: 1.0000\n",
      "Epoch 692/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.5323e-06 - acc: 1.0000 - val_loss: 3.9791e-06 - val_acc: 1.0000\n",
      "Epoch 693/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 2.4807e-06 - acc: 1.0000 - val_loss: 4.3717e-04 - val_acc: 1.0000\n",
      "Epoch 694/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 2.2070e-06 - acc: 1.0000 - val_loss: 3.6527e-06 - val_acc: 1.0000\n",
      "Epoch 695/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1.8795e-06 - acc: 1.0000 - val_loss: 3.4935e-06 - val_acc: 1.0000\n",
      "Epoch 696/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0145 - acc: 0.9983 - val_loss: 2.8134e-06 - val_acc: 1.0000\n",
      "Epoch 697/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0081 - acc: 0.9983 - val_loss: 0.0314 - val_acc: 0.9969\n",
      "Epoch 698/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0276 - acc: 0.9983 - val_loss: 0.0564 - val_acc: 0.9938\n",
      "Epoch 699/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 2.8051e-05 - acc: 1.0000 - val_loss: 0.1424 - val_acc: 0.9875\n",
      "Epoch 700/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.1111e-05 - acc: 1.0000 - val_loss: 0.0714 - val_acc: 0.9938\n",
      "Epoch 701/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.3078e-04 - acc: 1.0000 - val_loss: 0.0511 - val_acc: 0.9969\n",
      "Epoch 702/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.4640e-05 - acc: 1.0000 - val_loss: 0.0514 - val_acc: 0.9969\n",
      "Epoch 703/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.8759e-04 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 704/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 5.6694e-06 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 705/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 4.9800e-06 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 706/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.4496e-06 - acc: 1.0000 - val_loss: 2.2107e-05 - val_acc: 1.0000\n",
      "Epoch 707/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 4.2644e-06 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 708/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.1906e-06 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 709/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.5397e-05 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 710/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.6303e-04 - acc: 0.9996 - val_loss: 0.0504 - val_acc: 0.9969\n",
      "Epoch 711/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 4.3500e-06 - acc: 1.0000 - val_loss: 0.0498 - val_acc: 0.9969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 712/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 3.1713e-06 - acc: 1.0000 - val_loss: 0.0501 - val_acc: 0.9969\n",
      "Epoch 713/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.1476e-06 - acc: 1.0000 - val_loss: 0.0502 - val_acc: 0.9969\n",
      "Epoch 714/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.2628e-06 - acc: 1.0000 - val_loss: 0.1008 - val_acc: 0.9938\n",
      "Epoch 715/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0090 - acc: 0.9991 - val_loss: 0.0384 - val_acc: 0.9969\n",
      "Epoch 716/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 0.0354 - val_acc: 0.9969\n",
      "Epoch 717/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.1029e-06 - acc: 1.0000 - val_loss: 4.4871e-07 - val_acc: 1.0000\n",
      "Epoch 718/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.4759e-06 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 0.9969\n",
      "Epoch 719/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 0.0352 - val_acc: 0.9969\n",
      "Epoch 720/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3256e-06 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 0.9969\n",
      "Epoch 721/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.1841e-06 - acc: 1.0000 - val_loss: 0.0692 - val_acc: 0.9938\n",
      "Epoch 722/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3252e-06 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9969\n",
      "Epoch 723/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.8815e-06 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 0.9969\n",
      "Epoch 724/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 2.9099e-06 - acc: 1.0000 - val_loss: 0.0671 - val_acc: 0.9938\n",
      "Epoch 725/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 1.1409e-06 - acc: 1.0000 - val_loss: 3.1032e-07 - val_acc: 1.0000\n",
      "Epoch 726/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 0.0368 - val_acc: 0.9969\n",
      "Epoch 727/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0063 - acc: 0.9996 - val_loss: 1.8422e-07 - val_acc: 1.0000\n",
      "Epoch 728/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0135 - acc: 0.9991 - val_loss: 0.0408 - val_acc: 0.9969\n",
      "Epoch 729/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0201 - val_acc: 0.9969\n",
      "Epoch 730/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0371 - acc: 0.9965 - val_loss: 0.0684 - val_acc: 0.9938\n",
      "Epoch 731/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0169 - acc: 0.9987 - val_loss: 7.8112e-04 - val_acc: 1.0000\n",
      "Epoch 732/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 1.9744e-07 - val_acc: 1.0000\n",
      "Epoch 733/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 2.1849e-07 - val_acc: 1.0000\n",
      "Epoch 734/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 6.9250e-07 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9969\n",
      "Epoch 735/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 7.8194e-07 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9969\n",
      "Epoch 736/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 5.8603e-07 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9969\n",
      "Epoch 737/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 6.9770e-07 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9969\n",
      "Epoch 738/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0058 - acc: 0.9987 - val_loss: 0.0088 - val_acc: 0.9969\n",
      "Epoch 739/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0049 - acc: 0.9996 - val_loss: 6.7392e-07 - val_acc: 1.0000\n",
      "Epoch 740/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 5.3396e-06 - acc: 1.0000 - val_loss: 5.9997e-07 - val_acc: 1.0000\n",
      "Epoch 741/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.3585e-06 - acc: 1.0000 - val_loss: 2.7008e-07 - val_acc: 1.0000\n",
      "Epoch 742/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 1.8954e-06 - acc: 1.0000 - val_loss: 3.0231e-07 - val_acc: 1.0000\n",
      "Epoch 743/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 6.9806e-07 - acc: 1.0000 - val_loss: 5.6123e-07 - val_acc: 1.0000\n",
      "Epoch 744/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 7.8673e-05 - acc: 1.0000 - val_loss: 2.0025e-06 - val_acc: 1.0000\n",
      "Epoch 745/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0071 - acc: 0.9996 - val_loss: 2.9409e-06 - val_acc: 1.0000\n",
      "Epoch 746/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.8305e-04 - acc: 1.0000 - val_loss: 3.0138e-07 - val_acc: 1.0000\n",
      "Epoch 747/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 3.9098e-07 - acc: 1.0000 - val_loss: 2.7847e-07 - val_acc: 1.0000\n",
      "Epoch 748/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 2.4736e-06 - acc: 1.0000 - val_loss: 2.7754e-07 - val_acc: 1.0000\n",
      "Epoch 749/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 2.2860e-06 - acc: 1.0000 - val_loss: 2.4606e-07 - val_acc: 1.0000\n",
      "Epoch 750/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 5.6039e-05 - val_acc: 1.0000\n",
      "Epoch 751/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.9429e-06 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9938\n",
      "Epoch 752/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 2.5123e-04 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9938\n",
      "Epoch 753/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 6.8692e-07 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9969\n",
      "Epoch 754/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 0.0023 - val_acc: 0.9969\n",
      "Epoch 755/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0070 - acc: 0.9991 - val_loss: 0.0252 - val_acc: 0.9969\n",
      "Epoch 756/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.6701e-06 - acc: 1.0000 - val_loss: 0.0258 - val_acc: 0.9969\n",
      "Epoch 757/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.6259e-04 - acc: 1.0000 - val_loss: 6.0919e-06 - val_acc: 1.0000\n",
      "Epoch 758/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 4.3121e-07 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9969\n",
      "Epoch 759/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 4.7107e-07 - acc: 1.0000 - val_loss: 0.0501 - val_acc: 0.9938\n",
      "Epoch 760/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 4.0787e-07 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 0.9969\n",
      "Epoch 761/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 4.2624e-07 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 0.9969\n",
      "Epoch 762/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0277 - val_acc: 0.9969\n",
      "Epoch 763/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1.3959e-06 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 0.9969\n",
      "Epoch 764/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.4308e-06 - acc: 1.0000 - val_loss: 0.0275 - val_acc: 0.9969\n",
      "Epoch 765/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4688e-05 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 0.9969\n",
      "Epoch 766/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 3.2071e-06 - acc: 1.0000 - val_loss: 0.0270 - val_acc: 0.9969\n",
      "Epoch 767/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.7572e-07 - acc: 1.0000 - val_loss: 0.0271 - val_acc: 0.9969\n",
      "Epoch 768/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1264e-06 - acc: 1.0000 - val_loss: 0.0271 - val_acc: 0.9969\n",
      "Epoch 769/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 2.1983e-06 - acc: 1.0000 - val_loss: 3.9327e-06 - val_acc: 1.0000\n",
      "Epoch 770/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 8.2050e-07 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 0.9969\n",
      "Epoch 771/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0569 - val_acc: 0.9906\n",
      "Epoch 772/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.6885e-04 - acc: 0.9996 - val_loss: 0.0142 - val_acc: 0.9969\n",
      "Epoch 773/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.1479e-06 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 0.9938\n",
      "Epoch 774/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.4713e-06 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 0.9938\n",
      "Epoch 775/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.4122e-07 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9969\n",
      "Epoch 776/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.4569e-07 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 0.9969\n",
      "Epoch 777/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.1053e-07 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 0.9969\n",
      "Epoch 778/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.9957e-07 - acc: 1.0000 - val_loss: 3.6564e-07 - val_acc: 1.0000\n",
      "Epoch 779/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.5874e-07 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9969\n",
      "Epoch 780/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.2454e-07 - acc: 1.0000 - val_loss: 7.7192e-07 - val_acc: 1.0000\n",
      "Epoch 781/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.6605e-07 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9969\n",
      "Epoch 782/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 7.7054e-07 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9969\n",
      "Epoch 783/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 4.1731e-07 - acc: 1.0000 - val_loss: 2.0172e-07 - val_acc: 1.0000\n",
      "Epoch 784/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.2163e-07 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9969\n",
      "Epoch 785/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0036 - acc: 0.9996 - val_loss: 0.0254 - val_acc: 0.9969\n",
      "Epoch 786/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.0021e-05 - acc: 1.0000 - val_loss: 0.0275 - val_acc: 0.9969\n",
      "Epoch 787/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.8815e-06 - acc: 1.0000 - val_loss: 2.9620e-06 - val_acc: 1.0000\n",
      "Epoch 788/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.1151e-06 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 0.9969\n",
      "Epoch 789/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3363e-05 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 0.9969\n",
      "Epoch 790/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.3556e-06 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 0.9969\n",
      "Epoch 791/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.9765e-04 - acc: 0.9996 - val_loss: 0.0253 - val_acc: 0.9969\n",
      "Epoch 792/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.1462e-06 - acc: 1.0000 - val_loss: 1.0786e-04 - val_acc: 1.0000\n",
      "Epoch 793/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 1.1852e-06 - acc: 1.0000 - val_loss: 6.2013e-05 - val_acc: 1.0000\n",
      "Epoch 794/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 1.0894e-06 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 0.9969\n",
      "Epoch 795/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.3783e-06 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 0.9969\n",
      "Epoch 796/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.0472e-06 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 0.9969\n",
      "Epoch 797/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 9.8229e-07 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 0.9969\n",
      "Epoch 798/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 9.8157e-07 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 0.9969\n",
      "Epoch 799/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 1.0508e-06 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 0.9969\n",
      "Epoch 800/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.0255e-06 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 0.9969\n",
      "Epoch 801/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 1.0324e-06 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 0.9969\n",
      "Epoch 802/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.0029e-06 - acc: 1.0000 - val_loss: 2.1055e-05 - val_acc: 1.0000\n",
      "Epoch 803/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.0708e-06 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 0.9969\n",
      "Epoch 804/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 9.7324e-07 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 0.9969\n",
      "Epoch 805/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.0257e-06 - acc: 1.0000 - val_loss: 1.4845e-05 - val_acc: 1.0000\n",
      "Epoch 806/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 8.1889e-07 - acc: 1.0000 - val_loss: 0.0427 - val_acc: 0.9938\n",
      "Epoch 807/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 8.5519e-07 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 0.9969\n",
      "Epoch 808/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 9.9828e-04 - acc: 0.9991 - val_loss: 0.0034 - val_acc: 0.9969\n",
      "Epoch 809/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.6070e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 810/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1.9126e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 811/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.8807e-06 - acc: 1.0000 - val_loss: 7.1891e-04 - val_acc: 1.0000\n",
      "Epoch 812/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.5187e-06 - acc: 1.0000 - val_loss: 6.9800e-04 - val_acc: 1.0000\n",
      "Epoch 813/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.5496e-06 - acc: 1.0000 - val_loss: 7.2934e-04 - val_acc: 1.0000\n",
      "Epoch 814/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 1.3032e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 815/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.5320e-06 - acc: 1.0000 - val_loss: 3.8427e-05 - val_acc: 1.0000\n",
      "Epoch 816/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3471e-06 - acc: 1.0000 - val_loss: 7.6061e-04 - val_acc: 1.0000\n",
      "Epoch 817/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.4631e-06 - acc: 1.0000 - val_loss: 7.9262e-04 - val_acc: 1.0000\n",
      "Epoch 818/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2246e-06 - acc: 1.0000 - val_loss: 2.4155e-05 - val_acc: 1.0000\n",
      "Epoch 819/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1.2468e-06 - acc: 1.0000 - val_loss: 8.1419e-04 - val_acc: 1.0000\n",
      "Epoch 820/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 2.6002e-06 - acc: 1.0000 - val_loss: 1.4458e-05 - val_acc: 1.0000\n",
      "Epoch 821/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.3994e-06 - acc: 1.0000 - val_loss: 8.0422e-04 - val_acc: 1.0000\n",
      "Epoch 822/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.1820e-06 - acc: 1.0000 - val_loss: 8.2792e-04 - val_acc: 1.0000\n",
      "Epoch 823/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.0605e-06 - acc: 1.0000 - val_loss: 9.0284e-04 - val_acc: 1.0000\n",
      "Epoch 824/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.1529e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 825/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 2.1875e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 826/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.8049e-07 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 827/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4053e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 828/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 8.6572e-07 - acc: 1.0000 - val_loss: 7.5662e-06 - val_acc: 1.0000\n",
      "Epoch 829/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 14ms/step - loss: 8.9876e-07 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 830/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 8.0632e-07 - acc: 1.0000 - val_loss: 2.0433e-06 - val_acc: 1.0000\n",
      "Epoch 831/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.7986e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 0.9969\n",
      "Epoch 832/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 8.5571e-07 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9938\n",
      "Epoch 833/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1.3447e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9969\n",
      "Epoch 834/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.1435e-07 - acc: 1.0000 - val_loss: 2.6917e-06 - val_acc: 1.0000\n",
      "Epoch 835/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 7.0781e-07 - acc: 1.0000 - val_loss: 7.2811e-07 - val_acc: 1.0000\n",
      "Epoch 836/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.8318e-07 - acc: 1.0000 - val_loss: 7.2932e-04 - val_acc: 1.0000\n",
      "Epoch 837/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.1211e-07 - acc: 1.0000 - val_loss: 7.2603e-04 - val_acc: 1.0000\n",
      "Epoch 838/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.0775e-07 - acc: 1.0000 - val_loss: 7.5498e-04 - val_acc: 1.0000\n",
      "Epoch 839/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.0205e-07 - acc: 1.0000 - val_loss: 9.2135e-04 - val_acc: 1.0000\n",
      "Epoch 840/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.3277e-07 - acc: 1.0000 - val_loss: 9.5353e-04 - val_acc: 1.0000\n",
      "Epoch 841/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 6.9377e-07 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 842/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 4.8398e-07 - acc: 1.0000 - val_loss: 4.8988e-07 - val_acc: 1.0000\n",
      "Epoch 843/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.9200e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 844/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.6641e-07 - acc: 1.0000 - val_loss: 7.9777e-04 - val_acc: 1.0000\n",
      "Epoch 845/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.4942e-07 - acc: 1.0000 - val_loss: 5.1600e-04 - val_acc: 1.0000\n",
      "Epoch 846/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.8592e-07 - acc: 1.0000 - val_loss: 5.8901e-04 - val_acc: 1.0000\n",
      "Epoch 847/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.9250e-07 - acc: 1.0000 - val_loss: 3.8844e-04 - val_acc: 1.0000\n",
      "Epoch 848/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 3.4586e-07 - acc: 1.0000 - val_loss: 2.0154e-07 - val_acc: 1.0000\n",
      "Epoch 849/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.9486e-07 - acc: 1.0000 - val_loss: 6.8580e-04 - val_acc: 1.0000\n",
      "Epoch 850/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 4.0065e-07 - acc: 1.0000 - val_loss: 4.9026e-04 - val_acc: 1.0000\n",
      "Epoch 851/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 4.1969e-07 - acc: 1.0000 - val_loss: 2.7489e-04 - val_acc: 1.0000\n",
      "Epoch 852/1000\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 4.1242e-07 - acc: 1.0000 - val_loss: 1.6895e-04 - val_acc: 1.0000\n",
      "Epoch 853/1000\n",
      "72/72 [==============================] - 2s 23ms/step - loss: 3.3321e-07 - acc: 1.0000 - val_loss: 1.0997e-04 - val_acc: 1.0000\n",
      "Epoch 854/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 3.1882e-07 - acc: 1.0000 - val_loss: 8.1051e-05 - val_acc: 1.0000\n",
      "Epoch 855/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 3.7398e-07 - acc: 1.0000 - val_loss: 6.4728e-05 - val_acc: 1.0000\n",
      "Epoch 856/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 5.3290e-06 - acc: 1.0000 - val_loss: 4.3294e-05 - val_acc: 1.0000\n",
      "Epoch 857/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.9094e-07 - acc: 1.0000 - val_loss: 2.9273e-05 - val_acc: 1.0000\n",
      "Epoch 858/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 3.9272e-07 - acc: 1.0000 - val_loss: 2.4540e-05 - val_acc: 1.0000\n",
      "Epoch 859/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.3418e-07 - acc: 1.0000 - val_loss: 2.1349e-05 - val_acc: 1.0000\n",
      "Epoch 860/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.3055e-07 - acc: 1.0000 - val_loss: 1.7732e-07 - val_acc: 1.0000\n",
      "Epoch 861/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 2.2880e-07 - acc: 1.0000 - val_loss: 1.4824e-05 - val_acc: 1.0000\n",
      "Epoch 862/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.4590e-07 - acc: 1.0000 - val_loss: 1.7378e-07 - val_acc: 1.0000\n",
      "Epoch 863/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.1317e-07 - acc: 1.0000 - val_loss: 1.1911e-05 - val_acc: 1.0000\n",
      "Epoch 864/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.3560e-07 - acc: 1.0000 - val_loss: 9.5258e-06 - val_acc: 1.0000\n",
      "Epoch 865/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 2.6041e-07 - acc: 1.0000 - val_loss: 1.6279e-05 - val_acc: 1.0000\n",
      "Epoch 866/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.2303e-07 - acc: 1.0000 - val_loss: 1.6578e-07 - val_acc: 1.0000\n",
      "Epoch 867/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 2.1829e-07 - acc: 1.0000 - val_loss: 6.2152e-06 - val_acc: 1.0000\n",
      "Epoch 868/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 2.0347e-07 - acc: 1.0000 - val_loss: 1.1185e-05 - val_acc: 1.0000\n",
      "Epoch 869/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.0192e-07 - acc: 1.0000 - val_loss: 5.1174e-06 - val_acc: 1.0000\n",
      "Epoch 870/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 1.9917e-07 - acc: 1.0000 - val_loss: 8.9985e-06 - val_acc: 1.0000\n",
      "Epoch 871/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.0911e-07 - acc: 1.0000 - val_loss: 1.6671e-07 - val_acc: 1.0000\n",
      "Epoch 872/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 2.0254e-07 - acc: 1.0000 - val_loss: 1.6242e-07 - val_acc: 1.0000\n",
      "Epoch 873/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 2.0070e-07 - acc: 1.0000 - val_loss: 3.3602e-06 - val_acc: 1.0000\n",
      "Epoch 874/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 2.6090e-07 - acc: 1.0000 - val_loss: 3.1321e-06 - val_acc: 1.0000\n",
      "Epoch 875/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 3.1803e-07 - acc: 1.0000 - val_loss: 2.7487e-06 - val_acc: 1.0000\n",
      "Epoch 876/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0135 - acc: 0.9983 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 877/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1.0579e-04 - acc: 1.0000 - val_loss: 8.0397e-04 - val_acc: 1.0000\n",
      "Epoch 878/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 9.2123e-07 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 879/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.2041e-07 - acc: 1.0000 - val_loss: 8.1279e-06 - val_acc: 1.0000\n",
      "Epoch 880/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 6.8266e-07 - acc: 1.0000 - val_loss: 8.0360e-04 - val_acc: 1.0000\n",
      "Epoch 881/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 5.5978e-07 - acc: 1.0000 - val_loss: 8.1167e-04 - val_acc: 1.0000\n",
      "Epoch 882/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 6.2784e-07 - acc: 1.0000 - val_loss: 8.1887e-04 - val_acc: 1.0000\n",
      "Epoch 883/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 5.5070e-07 - acc: 1.0000 - val_loss: 7.6235e-06 - val_acc: 1.0000\n",
      "Epoch 884/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 4.9510e-07 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 885/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.1099e-07 - acc: 1.0000 - val_loss: 8.4077e-04 - val_acc: 1.0000\n",
      "Epoch 886/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 5.7639e-07 - acc: 1.0000 - val_loss: 8.6198e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 887/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 5.1288e-07 - acc: 1.0000 - val_loss: 1.4261e-05 - val_acc: 1.0000\n",
      "Epoch 888/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.7261e-07 - acc: 1.0000 - val_loss: 8.6212e-04 - val_acc: 1.0000\n",
      "Epoch 889/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.5239e-07 - acc: 1.0000 - val_loss: 8.9075e-04 - val_acc: 1.0000\n",
      "Epoch 890/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.4129e-07 - acc: 1.0000 - val_loss: 8.8332e-04 - val_acc: 1.0000\n",
      "Epoch 891/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 4.6530e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 892/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.0721e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 893/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.7001e-07 - acc: 1.0000 - val_loss: 9.4727e-04 - val_acc: 1.0000\n",
      "Epoch 894/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0276 - val_acc: 0.9906\n",
      "Epoch 895/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.3866e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 896/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.1214e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 897/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.5963e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 898/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.4295e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 899/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.3909e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 900/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 4.1646e-07 - acc: 1.0000 - val_loss: 1.5983e-06 - val_acc: 1.0000\n",
      "Epoch 901/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.3516e-07 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 902/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.4018e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 903/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.2980e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 904/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.4879e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 905/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.3901e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 906/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.5522e-07 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 907/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.4685e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 908/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.1169e-07 - acc: 1.0000 - val_loss: 1.5245e-06 - val_acc: 1.0000\n",
      "Epoch 909/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 2.2473e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 910/1000\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 2.2391e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 911/1000\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 2.3296e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 912/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0088 - acc: 0.9987 - val_loss: 0.0028 - val_acc: 0.9969\n",
      "Epoch 913/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 4.1647e-04 - val_acc: 1.0000\n",
      "Epoch 914/1000\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 1.6039e-07 - acc: 1.0000 - val_loss: 4.1881e-04 - val_acc: 1.0000\n",
      "Epoch 915/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.5796e-07 - acc: 1.0000 - val_loss: 4.2002e-04 - val_acc: 1.0000\n",
      "Epoch 916/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 1.4935e-07 - acc: 1.0000 - val_loss: 4.2599e-04 - val_acc: 1.0000\n",
      "Epoch 917/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0032 - acc: 0.9996 - val_loss: 1.6067e-04 - val_acc: 1.0000\n",
      "Epoch 918/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.2008e-07 - acc: 1.0000 - val_loss: 1.1958e-07 - val_acc: 1.0000\n",
      "Epoch 919/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 1.8341e-04 - val_acc: 1.0000\n",
      "Epoch 920/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 1.5191e-07 - acc: 1.0000 - val_loss: 1.8652e-04 - val_acc: 1.0000\n",
      "Epoch 921/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.3773e-07 - acc: 1.0000 - val_loss: 1.8643e-04 - val_acc: 1.0000\n",
      "Epoch 922/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 1.8651e-04 - val_acc: 1.0000\n",
      "Epoch 923/1000\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 1.3838e-07 - acc: 1.0000 - val_loss: 1.2014e-07 - val_acc: 1.0000\n",
      "Epoch 924/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.3668e-05 - acc: 1.0000 - val_loss: 0.0381 - val_acc: 0.9969\n",
      "Epoch 925/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 3.4420e-07 - acc: 1.0000 - val_loss: 1.4938e-07 - val_acc: 1.0000\n",
      "Epoch 926/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.3217e-07 - acc: 1.0000 - val_loss: 1.2610e-07 - val_acc: 1.0000\n",
      "Epoch 927/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.3978e-07 - acc: 1.0000 - val_loss: 4.4950e-04 - val_acc: 1.0000\n",
      "Epoch 928/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 1.2629e-07 - val_acc: 1.0000\n",
      "Epoch 929/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0093 - acc: 0.9987 - val_loss: 0.0603 - val_acc: 0.9938\n",
      "Epoch 930/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0274 - acc: 0.9978 - val_loss: 0.1147 - val_acc: 0.9875\n",
      "Epoch 931/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0069 - acc: 0.9996 - val_loss: 0.0337 - val_acc: 0.9969\n",
      "Epoch 932/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 4.8378e-06 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9938\n",
      "Epoch 933/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 5.6876e-06 - acc: 1.0000 - val_loss: 8.3970e-06 - val_acc: 1.0000\n",
      "Epoch 934/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 9.2073e-06 - acc: 1.0000 - val_loss: 5.3498e-07 - val_acc: 1.0000\n",
      "Epoch 935/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0150 - acc: 0.9987 - val_loss: 2.7772e-07 - val_acc: 1.0000\n",
      "Epoch 936/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 5.8400e-05 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 937/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0210 - acc: 0.9987 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 938/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0374 - val_acc: 0.9969\n",
      "Epoch 939/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 2.2203e-07 - acc: 1.0000 - val_loss: 7.3667e-04 - val_acc: 1.0000\n",
      "Epoch 940/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 6.2108e-06 - acc: 1.0000 - val_loss: 1.5795e-07 - val_acc: 1.0000\n",
      "Epoch 941/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.3926e-07 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 942/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 6.6916e-07 - acc: 1.0000 - val_loss: 5.6257e-05 - val_acc: 1.0000\n",
      "Epoch 943/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.2268e-07 - acc: 1.0000 - val_loss: 4.8628e-05 - val_acc: 1.0000\n",
      "Epoch 944/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 5.4492e-07 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 945/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 17ms/step - loss: 1.3390e-07 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 946/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 947/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0023 - acc: 0.9987 - val_loss: 2.5130e-04 - val_acc: 1.0000\n",
      "Epoch 948/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.8678e-07 - acc: 1.0000 - val_loss: 1.1244e-04 - val_acc: 1.0000\n",
      "Epoch 949/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.1828e-06 - acc: 1.0000 - val_loss: 1.3571e-05 - val_acc: 1.0000\n",
      "Epoch 950/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.1364e-07 - acc: 1.0000 - val_loss: 7.8486e-06 - val_acc: 1.0000\n",
      "Epoch 951/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.8609e-07 - acc: 1.0000 - val_loss: 4.3368e-06 - val_acc: 1.0000\n",
      "Epoch 952/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.6862e-07 - acc: 1.0000 - val_loss: 3.9842e-06 - val_acc: 1.0000\n",
      "Epoch 953/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.7641e-07 - acc: 1.0000 - val_loss: 3.8939e-06 - val_acc: 1.0000\n",
      "Epoch 954/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 2.3596e-07 - acc: 1.0000 - val_loss: 3.1668e-06 - val_acc: 1.0000\n",
      "Epoch 955/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.8311e-07 - acc: 1.0000 - val_loss: 4.0458e-07 - val_acc: 1.0000\n",
      "Epoch 956/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.6200e-07 - acc: 1.0000 - val_loss: 3.9303e-07 - val_acc: 1.0000\n",
      "Epoch 957/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.6461e-07 - acc: 1.0000 - val_loss: 3.1189e-06 - val_acc: 1.0000\n",
      "Epoch 958/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.7969e-07 - acc: 1.0000 - val_loss: 3.1196e-06 - val_acc: 1.0000\n",
      "Epoch 959/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.8313e-07 - acc: 1.0000 - val_loss: 3.1187e-06 - val_acc: 1.0000\n",
      "Epoch 960/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.7312e-07 - acc: 1.0000 - val_loss: 3.1040e-06 - val_acc: 1.0000\n",
      "Epoch 961/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.6342e-07 - acc: 1.0000 - val_loss: 1.6168e-07 - val_acc: 1.0000\n",
      "Epoch 962/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.7651e-07 - acc: 1.0000 - val_loss: 3.0041e-06 - val_acc: 1.0000\n",
      "Epoch 963/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.7511e-07 - acc: 1.0000 - val_loss: 3.1780e-06 - val_acc: 1.0000\n",
      "Epoch 964/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.6389e-07 - acc: 1.0000 - val_loss: 3.1258e-06 - val_acc: 1.0000\n",
      "Epoch 965/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.7341e-07 - acc: 1.0000 - val_loss: 3.0818e-06 - val_acc: 1.0000\n",
      "Epoch 966/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.5951e-07 - acc: 1.0000 - val_loss: 3.4702e-07 - val_acc: 1.0000\n",
      "Epoch 967/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 3.9032e-06 - val_acc: 1.0000\n",
      "Epoch 968/1000\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 2.2454e-05 - acc: 1.0000 - val_loss: 4.3289e-07 - val_acc: 1.0000\n",
      "Epoch 969/1000\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 2.2292e-07 - acc: 1.0000 - val_loss: 7.3558e-07 - val_acc: 1.0000\n",
      "Epoch 970/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 2.3863e-07 - acc: 1.0000 - val_loss: 8.8515e-07 - val_acc: 1.0000\n",
      "Epoch 971/1000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 2.3764e-07 - acc: 1.0000 - val_loss: 4.6809e-07 - val_acc: 1.0000\n",
      "Epoch 972/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 2.7578e-07 - acc: 1.0000 - val_loss: 6.2661e-07 - val_acc: 1.0000\n",
      "Epoch 973/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.5505e-07 - acc: 1.0000 - val_loss: 6.2568e-07 - val_acc: 1.0000\n",
      "Epoch 974/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.7482e-07 - acc: 1.0000 - val_loss: 6.2437e-07 - val_acc: 1.0000\n",
      "Epoch 975/1000\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 2.6199e-07 - acc: 1.0000 - val_loss: 4.4742e-07 - val_acc: 1.0000\n",
      "Epoch 976/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 6.6754e-06 - acc: 1.0000 - val_loss: 6.7304e-05 - val_acc: 1.0000\n",
      "Epoch 977/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.7285e-07 - acc: 1.0000 - val_loss: 5.8986e-05 - val_acc: 1.0000\n",
      "Epoch 978/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.8310e-07 - acc: 1.0000 - val_loss: 1.8688e-05 - val_acc: 1.0000\n",
      "Epoch 979/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.7171e-07 - acc: 1.0000 - val_loss: 2.8787e-05 - val_acc: 1.0000\n",
      "Epoch 980/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.7870e-07 - acc: 1.0000 - val_loss: 8.9153e-06 - val_acc: 1.0000\n",
      "Epoch 981/1000\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.4396e-07 - acc: 1.0000 - val_loss: 5.6700e-07 - val_acc: 1.0000\n",
      "Epoch 982/1000\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 2.6134e-07 - acc: 1.0000 - val_loss: 9.8990e-06 - val_acc: 1.0000\n",
      "Epoch 983/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0060 - acc: 0.9996 - val_loss: 1.2402e-05 - val_acc: 1.0000\n",
      "Epoch 984/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 9.8086e-06 - acc: 1.0000 - val_loss: 3.0141e-05 - val_acc: 1.0000\n",
      "Epoch 985/1000\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 9.4140e-07 - acc: 1.0000 - val_loss: 1.5003e-05 - val_acc: 1.0000\n",
      "Epoch 986/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 9.5146e-07 - acc: 1.0000 - val_loss: 9.5411e-06 - val_acc: 1.0000\n",
      "Epoch 987/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 8.8846e-07 - acc: 1.0000 - val_loss: 2.2920e-06 - val_acc: 1.0000\n",
      "Epoch 988/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.9376e-07 - acc: 1.0000 - val_loss: 3.4262e-06 - val_acc: 1.0000\n",
      "Epoch 989/1000\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 7.0660e-07 - acc: 1.0000 - val_loss: 6.3368e-07 - val_acc: 1.0000\n",
      "Epoch 990/1000\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 6.5780e-07 - acc: 1.0000 - val_loss: 1.3889e-06 - val_acc: 1.0000\n",
      "Epoch 991/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 5.3823e-07 - acc: 1.0000 - val_loss: 2.3398e-06 - val_acc: 1.0000\n",
      "Epoch 992/1000\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 5.2431e-07 - acc: 1.0000 - val_loss: 2.2840e-06 - val_acc: 1.0000\n",
      "Epoch 993/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 7.0087e-07 - acc: 1.0000 - val_loss: 1.5345e-06 - val_acc: 1.0000\n",
      "Epoch 994/1000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 2.6415e-05 - val_acc: 1.0000\n",
      "Epoch 995/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 2.2532e-06 - acc: 1.0000 - val_loss: 4.9249e-07 - val_acc: 1.0000\n",
      "Epoch 996/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0045 - acc: 0.9991 - val_loss: 1.1344e-06 - val_acc: 1.0000\n",
      "Epoch 997/1000\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0076 - acc: 0.9991 - val_loss: 1.8776e-07 - val_acc: 1.0000\n",
      "Epoch 998/1000\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0112 - acc: 0.9991 - val_loss: 1.5572e-05 - val_acc: 1.0000\n",
      "Epoch 999/1000\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 6.4794e-04 - acc: 0.9996 - val_loss: 2.5015e-07 - val_acc: 1.0000\n",
      "Epoch 1000/1000\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 7.8348e-07 - acc: 1.0000 - val_loss: 7.2313e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating model: A_A_inceptionv3-l2-final_1000_Nadam.h5 ===\n",
      "\n",
      "Accuracy: 0.998\n",
      "\n",
      "Confusion Matrix\n",
      "[[310   1]\n",
      " [  0 329]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       311\n",
      "          1       1.00      1.00      1.00       329\n",
      "\n",
      "avg / total       1.00      1.00      1.00       640\n",
      "\n",
      "=== Evaluating model: A_A_inceptionv3-l2-best_1000_Nadam.h5 ===\n",
      "\n",
      "Accuracy: 0.997\n",
      "\n",
      "Confusion Matrix\n",
      "[[310   2]\n",
      " [  0 328]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00       312\n",
      "          1       0.99      1.00      1.00       328\n",
      "\n",
      "avg / total       1.00      1.00      1.00       640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input: Elementwise Euclidean Distance\n",
    "# In [32]:\n",
    "train_gen = data_generator(train_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "val_gen = data_generator(val_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "# In [33]:\n",
    "def euclidean_distance(vecs):\n",
    "    x, y = vecs\n",
    "    return K.sqrt(K.sum(K.stack([K.square(x), -K.square(y)], axis=1), axis=1))\n",
    "\n",
    "'''\n",
    "stack  将秩 为 R 的张量列表堆叠成秩为 R + 1 的张量。\n",
    "square 元素级的平方操作。\n",
    "sum    计算张量在某一指定轴的和。\n",
    "sqrt   元素级的平方根操作。\n",
    "'''\n",
    "\n",
    "def euclidean_distance_output_shape(shapes):\n",
    "    xshape, yshape = shapes\n",
    "    return xshape\n",
    "\n",
    "vecs = [np.random.random((10,)), np.random.random((10,))]\n",
    "print(vecs[0].shape, vecs[1].shape)\n",
    "s = euclidean_distance(vecs)\n",
    "print(s.shape)\n",
    "\n",
    "# In [34]:\n",
    "input_1 = Input(shape=(VECTOR_SIZE,))\n",
    "input_2 = Input(shape=(VECTOR_SIZE,))\n",
    "merged = Lambda(euclidean_distance, \n",
    "                output_shape=euclidean_distance_output_shape)([input_1, input_2])\n",
    "\n",
    "fc1 = Dense(512, kernel_initializer=\"glorot_uniform\")(merged)\n",
    "fc1 = Dropout(0.2)(fc1)\n",
    "fc1 = Activation(\"relu\")(fc1)\n",
    "\n",
    "fc2 = Dense(128, kernel_initializer=\"glorot_uniform\")(fc1)\n",
    "fc2 = Dropout(0.2)(fc2)\n",
    "fc2 = Activation(\"relu\")(fc2)\n",
    "\n",
    "pred = Dense(2, kernel_initializer=\"glorot_uniform\")(fc2)\n",
    "pred = Activation(\"softmax\")(pred)\n",
    "# In [35]:\n",
    "model = Model(inputs=[input_1, input_2], outputs=pred)\n",
    "# model.summary()\n",
    "# In [36]:\n",
    "model.compile(optimizer=\"Nadam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# In [37]:\n",
    "best_model_name = get_model_file(DATA_DIR, \"inceptionv3\", \"l2\", \"best\")\n",
    "checkpoint = ModelCheckpoint(best_model_name, save_best_only=True)\n",
    "train_steps_per_epoch = len(train_triples) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(val_triples) // BATCH_SIZE\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps_per_epoch, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              validation_data=val_gen, validation_steps=val_steps_per_epoch,\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# In [39]:\n",
    "final_model_name = get_model_file(DATA_DIR, \"inceptionv3\", \"l2\", \"final\")\n",
    "model.save(final_model_name)\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "final_accuracy = evaluate_model(final_model_name, test_gen)\n",
    "\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "best_accuracy = evaluate_model(best_model_name, test_gen)\n",
    "\n",
    "scores[0, 3] = best_accuracy if best_accuracy > final_accuracy else final_accuracy\n",
    "# === Evaluating model: inceptionv3-l2-final.h5 ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating model: A_A_resnet50-cat-final_10.h5 ===\n",
      "\n",
      "Accuracy: 0.995\n",
      "\n",
      "Confusion Matrix\n",
      "[[306   2]\n",
      " [  1 331]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00       308\n",
      "          1       0.99      1.00      1.00       332\n",
      "\n",
      "avg / total       1.00      1.00      1.00       640\n",
      "\n",
      "=== Evaluating model: A_A_inceptionv3-l2-best_10.h5 ===\n",
      "\n",
      "Accuracy: 0.995\n",
      "\n",
      "Confusion Matrix\n",
      "[[311   2]\n",
      " [  1 326]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00       313\n",
      "          1       0.99      1.00      1.00       327\n",
      "\n",
      "avg / total       1.00      1.00      1.00       640\n",
      "\n",
      "Epoch 1/10\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.5344 - acc: 0.7292 - val_loss: 0.2602 - val_acc: 0.9219\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1692 - acc: 0.9440 - val_loss: 0.1010 - val_acc: 0.9750\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1069 - acc: 0.9631 - val_loss: 0.1323 - val_acc: 0.9594\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0942 - acc: 0.9670 - val_loss: 0.0535 - val_acc: 0.9812\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0513 - acc: 0.9831 - val_loss: 0.1063 - val_acc: 0.9781\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0280 - acc: 0.9922 - val_loss: 0.0549 - val_acc: 0.9875\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0224 - acc: 0.9922 - val_loss: 0.0449 - val_acc: 0.9812\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0267 - acc: 0.9896 - val_loss: 0.0670 - val_acc: 0.9812\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0283 - acc: 0.9900 - val_loss: 0.0862 - val_acc: 0.9719\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0456 - acc: 0.9835 - val_loss: 0.0203 - val_acc: 0.9969\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In [48]:\n",
    "final_model_name = get_model_file(DATA_DIR, \"resnet50\", \"cat\", \"final\")\n",
    "model.save(final_model_name)\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "final_accuracy = evaluate_model(final_model_name, test_gen)\n",
    "\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "best_accuracy = evaluate_model(best_model_name, test_gen)\n",
    "\n",
    "scores[1, 0] = best_accuracy if best_accuracy > final_accuracy else final_accuracy\n",
    "# === Evaluating model: resnet50-cat-final.h5 ===\n",
    "\n",
    "\n",
    "# Input: Elementwise Cosine Distance\n",
    "# In [49]:\n",
    "train_gen = data_generator(train_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "val_gen = data_generator(val_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "# In [50]:\n",
    "input_1 = Input(shape=(VECTOR_SIZE,))\n",
    "input_2 = Input(shape=(VECTOR_SIZE,))\n",
    "merged = Lambda(cosine_distance, \n",
    "                  output_shape=cosine_distance_output_shape)([input_1, input_2])\n",
    "\n",
    "fc1 = Dense(512, kernel_initializer=\"glorot_uniform\")(merged)\n",
    "fc1 = Dropout(0.2)(fc1)\n",
    "fc1 = Activation(\"relu\")(fc1)\n",
    "\n",
    "fc2 = Dense(128, kernel_initializer=\"glorot_uniform\")(fc1)\n",
    "fc2 = Dropout(0.2)(fc2)\n",
    "fc2 = Activation(\"relu\")(fc2)\n",
    "\n",
    "pred = Dense(2, kernel_initializer=\"glorot_uniform\")(fc2)\n",
    "pred = Activation(\"softmax\")(pred)\n",
    "# In [51]:\n",
    "model = Model(inputs=[input_1, input_2], outputs=pred)\n",
    "# model.summary()\n",
    "# In [52]:\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# In [53]:\n",
    "best_model_name = get_model_file(DATA_DIR, \"resnet50\", \"dot\", \"best\")\n",
    "checkpoint = ModelCheckpoint(best_model_name, save_best_only=True)\n",
    "train_steps_per_epoch = len(train_triples) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(val_triples) // BATCH_SIZE\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps_per_epoch, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              validation_data=val_gen, validation_steps=val_steps_per_epoch,\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "# In [54]:\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.7965 - acc: 0.5668 - val_loss: 0.5289 - val_acc: 0.7688\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.4306 - acc: 0.7999 - val_loss: 0.2926 - val_acc: 0.9062\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.2032 - acc: 0.9236 - val_loss: 0.2457 - val_acc: 0.8969\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.1458 - acc: 0.9488 - val_loss: 0.1218 - val_acc: 0.9656\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.0832 - acc: 0.9740 - val_loss: 0.1672 - val_acc: 0.9469\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0740 - acc: 0.9740 - val_loss: 0.0930 - val_acc: 0.9625\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0473 - acc: 0.9857 - val_loss: 0.0958 - val_acc: 0.9688\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0410 - acc: 0.9878 - val_loss: 0.1247 - val_acc: 0.9688\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.1178 - acc: 0.9553 - val_loss: 0.1527 - val_acc: 0.9625\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0689 - acc: 0.9792 - val_loss: 0.1949 - val_acc: 0.9437\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ResNet 50 Vectors\n",
    "# In [40]:\n",
    "VECTOR_SIZE = 2048\n",
    "VECTOR_FILE = os.path.join(DATA_DIR,\"weights\" , \"accton-resnet-vectors.tsv\")\n",
    "# In [41]:\n",
    "vec_dict = load_vectors(VECTOR_FILE)\n",
    "# Input: Concatenate vectors\n",
    "# In [42]:\n",
    "train_gen = data_generator(train_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "val_gen = data_generator(val_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "# In [43]:\n",
    "input_1 = Input(shape=(VECTOR_SIZE,))\n",
    "input_2 = Input(shape=(VECTOR_SIZE,))\n",
    "merged = Concatenate(axis=-1)([input_1, input_2])\n",
    "\n",
    "fc1 = Dense(512, kernel_initializer=\"glorot_uniform\")(merged)\n",
    "fc1 = Dropout(0.2)(fc1)\n",
    "fc1 = Activation(\"relu\")(fc1)\n",
    "\n",
    "fc2 = Dense(128, kernel_initializer=\"glorot_uniform\")(fc1)\n",
    "fc2 = Dropout(0.2)(fc2)\n",
    "fc2 = Activation(\"relu\")(fc2)\n",
    "\n",
    "pred = Dense(2, kernel_initializer=\"glorot_uniform\")(fc2)\n",
    "pred = Activation(\"softmax\")(pred)\n",
    "# In [44]:\n",
    "model = Model(inputs=[input_1, input_2], outputs=pred)\n",
    "# model.summary()\n",
    "# In [45]:\n",
    "model.compile(optimizer=\"Nadam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# In [46]:\n",
    "best_model_name = get_model_file(DATA_DIR, \"resnet50\", \"cat\", \"best\")\n",
    "checkpoint = ModelCheckpoint(best_model_name, save_best_only=True)\n",
    "train_steps_per_epoch = len(train_triples) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(val_triples) // BATCH_SIZE\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps_per_epoch, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              validation_data=val_gen, validation_steps=val_steps_per_epoch,\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "# In [47]:\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating model: A_A_resnet50-dot-final_10.h5 ===\n",
      "\n",
      "Accuracy: 0.953\n",
      "\n",
      "Confusion Matrix\n",
      "[[279  30]\n",
      " [  0 331]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95       309\n",
      "          1       0.92      1.00      0.96       331\n",
      "\n",
      "avg / total       0.96      0.95      0.95       640\n",
      "\n",
      "=== Evaluating model: A_A_resnet50-cat-best_10.h5 ===\n",
      "\n",
      "Accuracy: 0.964\n",
      "\n",
      "Confusion Matrix\n",
      "[[292  21]\n",
      " [  2 325]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.93      0.96       313\n",
      "          1       0.94      0.99      0.97       327\n",
      "\n",
      "avg / total       0.97      0.96      0.96       640\n",
      "\n",
      "Epoch 1/10\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.4064 - acc: 0.8138 - val_loss: 0.1506 - val_acc: 0.9531\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0696 - acc: 0.9852 - val_loss: 0.0622 - val_acc: 0.9938\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0292 - acc: 0.9913 - val_loss: 0.0237 - val_acc: 0.9938\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0139 - acc: 0.9965 - val_loss: 0.0109 - val_acc: 0.9969\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0113 - acc: 0.9978 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0373 - acc: 0.9887 - val_loss: 0.1173 - val_acc: 0.9656\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0194 - acc: 0.9935 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0392 - val_acc: 0.9844\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.0029 - val_acc: 0.9969\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating model: A_A_resnet50-l1-final_10.h5 ===\n",
      "\n",
      "Accuracy: 1.000\n",
      "\n",
      "Confusion Matrix\n",
      "[[310   0]\n",
      " [  0 330]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       310\n",
      "          1       1.00      1.00      1.00       330\n",
      "\n",
      "avg / total       1.00      1.00      1.00       640\n",
      "\n",
      "=== Evaluating model: A_A_resnet50-l1-best_10.h5 ===\n",
      "\n",
      "Accuracy: 1.000\n",
      "\n",
      "Confusion Matrix\n",
      "[[309   0]\n",
      " [  0 331]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       309\n",
      "          1       1.00      1.00      1.00       331\n",
      "\n",
      "avg / total       1.00      1.00      1.00       640\n",
      "\n",
      "Epoch 1/10\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.5162 - acc: 0.7201 - val_loss: 0.2774 - val_acc: 0.9094\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1990 - acc: 0.9345 - val_loss: 0.2373 - val_acc: 0.9375\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0856 - acc: 0.9783 - val_loss: 0.0817 - val_acc: 0.9625\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0426 - acc: 0.9896 - val_loss: 0.1645 - val_acc: 0.9531\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0784 - acc: 0.9753 - val_loss: 0.0855 - val_acc: 0.9719\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0397 - acc: 0.9900 - val_loss: 0.1064 - val_acc: 0.9656\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0273 - acc: 0.9931 - val_loss: 0.0556 - val_acc: 0.9812\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0142 - acc: 0.9961 - val_loss: 0.0654 - val_acc: 0.9812\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0149 - acc: 0.9965 - val_loss: 0.0516 - val_acc: 0.9781\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.1706 - val_acc: 0.9656\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating model: A_A_resnet50-l2-final_10.h5 ===\n",
      "\n",
      "Accuracy: 0.964\n",
      "\n",
      "Confusion Matrix\n",
      "[[287  23]\n",
      " [  0 330]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96       310\n",
      "          1       0.93      1.00      0.97       330\n",
      "\n",
      "avg / total       0.97      0.96      0.96       640\n",
      "\n",
      "=== Evaluating model: A_A_resnet50-l2-best_10.h5 ===\n",
      "\n",
      "Accuracy: 0.994\n",
      "\n",
      "Confusion Matrix\n",
      "[[306   2]\n",
      " [  2 330]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       308\n",
      "          1       0.99      0.99      0.99       332\n",
      "\n",
      "avg / total       0.99      0.99      0.99       640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In [55]:\n",
    "final_model_name = get_model_file(DATA_DIR, \"resnet50\", \"dot\", \"final\")\n",
    "model.save(final_model_name)\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "final_accuracy = evaluate_model(final_model_name, test_gen)\n",
    "\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "best_accuracy = evaluate_model(best_model_name, test_gen)\n",
    "\n",
    "scores[1, 1] = best_accuracy if best_accuracy > final_accuracy else final_accuracy\n",
    "# === Evaluating model: resnet50-dot-final.h5 ===\n",
    "\n",
    "# Input: Elementwise Absolute Difference\n",
    "# In [56]:\n",
    "train_gen = data_generator(train_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "val_gen = data_generator(val_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "# In [57]:\n",
    "input_1 = Input(shape=(VECTOR_SIZE,))\n",
    "input_2 = Input(shape=(VECTOR_SIZE,))\n",
    "merged = Lambda(absdiff, output_shape=absdiff_output_shape)([input_1, input_2])\n",
    "\n",
    "fc1 = Dense(512, kernel_initializer=\"glorot_uniform\")(merged)\n",
    "fc1 = Dropout(0.2)(fc1)\n",
    "fc1 = Activation(\"relu\")(fc1)\n",
    "\n",
    "fc2 = Dense(128, kernel_initializer=\"glorot_uniform\")(fc1)\n",
    "fc2 = Dropout(0.2)(fc2)\n",
    "fc2 = Activation(\"relu\")(fc2)\n",
    "\n",
    "pred = Dense(2, kernel_initializer=\"glorot_uniform\")(fc2)\n",
    "pred = Activation(\"softmax\")(pred)\n",
    "# In [58]:\n",
    "model = Model(inputs=[input_1, input_2], outputs=pred)\n",
    "# model.summary()\n",
    "# In [59]:\n",
    "model.compile(optimizer=\"Nadam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# In [60]:\n",
    "best_model_name = get_model_file(DATA_DIR, \"resnet50\", \"l1\", \"best\")\n",
    "checkpoint = ModelCheckpoint(best_model_name, save_best_only=True)\n",
    "train_steps_per_epoch = len(train_triples) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(val_triples) // BATCH_SIZE\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps_per_epoch, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              validation_data=val_gen, validation_steps=val_steps_per_epoch,\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# In [62]:\n",
    "final_model_name = get_model_file(DATA_DIR, \"resnet50\", \"l1\", \"final\")\n",
    "model.save(final_model_name)\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "final_accuracy = evaluate_model(final_model_name, test_gen)\n",
    "\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "best_accuracy = evaluate_model(best_model_name, test_gen)\n",
    "\n",
    "scores[1, 2] = best_accuracy if best_accuracy > final_accuracy else final_accuracy\n",
    "# === Evaluating model: resnet50-l1-final.h5 ===\n",
    "\n",
    "\n",
    "# Input: Elementwise Euclidean Distance\n",
    "# In [63]:\n",
    "train_gen = data_generator(train_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "val_gen = data_generator(val_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "# In [64]:\n",
    "input_1 = Input(shape=(VECTOR_SIZE,))\n",
    "input_2 = Input(shape=(VECTOR_SIZE,))\n",
    "merged = Lambda(euclidean_distance, \n",
    "                output_shape=euclidean_distance_output_shape)([input_1, input_2])\n",
    "\n",
    "fc1 = Dense(512, kernel_initializer=\"glorot_uniform\")(merged)\n",
    "fc1 = Dropout(0.2)(fc1)\n",
    "fc1 = Activation(\"relu\")(fc1)\n",
    "\n",
    "fc2 = Dense(128, kernel_initializer=\"glorot_uniform\")(fc1)\n",
    "fc2 = Dropout(0.2)(fc2)\n",
    "fc2 = Activation(\"relu\")(fc2)\n",
    "\n",
    "pred = Dense(2, kernel_initializer=\"glorot_uniform\")(fc2)\n",
    "pred = Activation(\"softmax\")(pred)\n",
    "# In [65]:\n",
    "model = Model(inputs=[input_1, input_2], outputs=pred)\n",
    "# model.summary()\n",
    "# In [66]:\n",
    "model.compile(optimizer=\"Nadam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# In [67]:\n",
    "best_model_name = get_model_file(DATA_DIR, \"resnet50\", \"l2\", \"best\")\n",
    "checkpoint = ModelCheckpoint(best_model_name, save_best_only=True)\n",
    "train_steps_per_epoch = len(train_triples) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(val_triples) // BATCH_SIZE\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps_per_epoch, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              validation_data=val_gen, validation_steps=val_steps_per_epoch,\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "# In [68]:\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# In [69]:\n",
    "final_model_name = get_model_file(DATA_DIR, \"resnet50\", \"l2\", \"final\")\n",
    "model.save(final_model_name)\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "final_accuracy = evaluate_model(final_model_name, test_gen)\n",
    "\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "best_accuracy = evaluate_model(best_model_name, test_gen)\n",
    "\n",
    "scores[1, 3] = best_accuracy if best_accuracy > final_accuracy else final_accuracy\n",
    "# === Evaluating model: resnet50-l2-final.h5 ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Neural Network Classifiers with Image Vectors')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In [71]:\n",
    "width=0.35\n",
    "plt.bar(np.arange(scores.shape[1]), scores[0], width, color=\"g\", label=\"Inception-V3\")\n",
    "plt.bar(np.arange(scores.shape[1])+width, scores[1], width, color=\"y\", label=\"ResNet-50\")\n",
    "plt.legend(loc=4)\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"merge strategy\")\n",
    "plt.xticks(np.arange(scores.shape[1])+0.5*width, [\"Concat\", \"Dot\", \"L1\", \"L2\"],\n",
    "          rotation=30)\n",
    "plt.title(\"Neural Network Classifiers with Image Vectors\")\n",
    "# Out[71]:\n",
    "# <matplotlib.text.Text at 0x7fe1aa6d1050>\n",
    "\n",
    "# In [ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

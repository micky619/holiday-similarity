{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras import backend as K\n",
    "from keras.applications import inception_v3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.core import Activation, Dense, Dropout, Lambda\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from random import shuffle\n",
    "from scipy.misc import imresize\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3312\n",
      "[('410008.jpg', '410009.jpg', 1), ('420008.jpg', '420006.jpg', 1), ('430003.jpg', '430002.jpg', 1), ('120003.jpg', '070002.jpg', 0), ('450006.jpg', '400005.jpg', 0)]\n",
      "images from 0/3312 pairs loaded to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:50: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images from 1000/3312 pairs loaded to cache\n",
      "images from 2000/3312 pairs loaded to cache\n",
      "images from 3000/3312 pairs loaded to cache\n",
      "images from 3311/3312 pairs loaded to cache, COMPLETE\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"\"\n",
    "# IMAGE_DIR = os.path.join(DATA_DIR, \"holiday-photos/jpg\")\n",
    "IMAGE_DIR = os.path.join(DATA_DIR, \"images\")\n",
    "\n",
    "HOLIDAY_FILE_IDS = os.path.join(DATA_DIR, \"holiday-ids.txt\")\n",
    "HOLIDAY_VECS_FILE = os.path.join(DATA_DIR, \"holiday-vecs.npy\")\n",
    "\n",
    "def get_random_image(img_groups, group_names, gid):\n",
    "    gname = group_names[gid]\n",
    "    photos = img_groups[gname]\n",
    "    pid = np.random.choice(np.arange(len(photos)), size=1)[0]\n",
    "    pname = photos[pid]\n",
    "    return gname + pname + \".jpg\"\n",
    "    \n",
    "def create_triples(image_dir):\n",
    "    img_groups = {}\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        if (img_file[-3:] == 'jpg'):\n",
    "            prefix, suffix = img_file.split(\".\")\n",
    "            gid, pid = prefix[0:4], prefix[4:]\n",
    "            if gid in img_groups:\n",
    "                img_groups[gid].append(pid)\n",
    "            else:\n",
    "                img_groups[gid] = [pid]\n",
    "            \n",
    "    pos_triples, neg_triples = [], []\n",
    "    # positive pairs are any combination of images in same group\n",
    "    for key in img_groups.keys():\n",
    "        triples = [(key + x[0] + \".jpg\", key + x[1] + \".jpg\", 1) \n",
    "                 for x in itertools.combinations(img_groups[key], 2)]\n",
    "        pos_triples.extend(triples)\n",
    "    # need equal number of negative examples\n",
    "    group_names = list(img_groups.keys())\n",
    "    for i in range(len(pos_triples)):\n",
    "        g1, g2 = np.random.choice(np.arange(len(group_names)), size=2, replace=False)\n",
    "        left = get_random_image(img_groups, group_names, g1)\n",
    "        right = get_random_image(img_groups, group_names, g2)\n",
    "        neg_triples.append((left, right, 0))\n",
    "    pos_triples.extend(neg_triples)\n",
    "    shuffle(pos_triples)\n",
    "    return pos_triples\n",
    "\n",
    "triples_data = create_triples(IMAGE_DIR)\n",
    "\n",
    "print(len(triples_data))\n",
    "print(triples_data[0:5])\n",
    "\n",
    "def load_image_cache(image_cache, image_filename):\n",
    "    image = plt.imread(os.path.join(IMAGE_DIR, image_filename))\n",
    "    image = imresize(image, (299, 299))\n",
    "    image = image.astype(\"float32\")\n",
    "    image = inception_v3.preprocess_input(image)\n",
    "    image_cache[image_filename] = image\n",
    "    \n",
    "image_cache = {}\n",
    "num_pairs = len(triples_data)\n",
    "for i, (image_filename_l, image_filename_r, _) in enumerate(triples_data):\n",
    "    if i % 1000 == 0:\n",
    "        print(\"images from {:d}/{:d} pairs loaded to cache\".format(i, num_pairs))\n",
    "    if image_filename_l not in image_cache:\n",
    "        load_image_cache(image_cache, image_filename_l)\n",
    "    if image_filename_r not in image_cache:\n",
    "        load_image_cache(image_cache, image_filename_r)\n",
    "print(\"images from {:d}/{:d} pairs loaded to cache, COMPLETE\".format(i, num_pairs))\n",
    "\n",
    "def pair_generator(triples, image_cache, datagens, batch_size=32):\n",
    "    while True:\n",
    "        # shuffle once per batch\n",
    "        indices = np.random.permutation(np.arange(len(triples)))\n",
    "        num_batches = len(triples) // batch_size\n",
    "        for bid in range(num_batches):\n",
    "            batch_indices = indices[bid * batch_size : (bid + 1) * batch_size]\n",
    "            batch = [triples[i] for i in batch_indices]\n",
    "            X1 = np.zeros((batch_size, 299, 299, 3))\n",
    "            X2 = np.zeros((batch_size, 299, 299, 3))\n",
    "            Y = np.zeros((batch_size, 2))\n",
    "            for i, (image_filename_l, image_filename_r, label) in enumerate(batch):\n",
    "                if datagens is None or len(datagens) == 0:\n",
    "                    X1[i] = image_cache[image_filename_l]\n",
    "                    X2[i] = image_cache[image_filename_r]\n",
    "                else:\n",
    "                    X1[i] = datagens[0].random_transform(image_cache[image_filename_l])\n",
    "                    X2[i] = datagens[1].random_transform(image_cache[image_filename_r])\n",
    "                Y[i] = [1, 0] if label == 0 else [0, 1]\n",
    "            yield [X1, X2], Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 299, 299, 3) (32, 299, 299, 3) (32, 2)\n"
     ]
    }
   ],
   "source": [
    "from skimage import exposure\n",
    "\n",
    "def AHE(img):\n",
    "    img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "    return img_adapteq\n",
    "\n",
    "datagen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    preprocessing_function=AHE,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "datagens = [ImageDataGenerator(**datagen_args),\n",
    "            ImageDataGenerator(**datagen_args)]\n",
    "pair_gen = pair_generator(triples_data, image_cache, datagens, 32)\n",
    "[X1, X2], Y = pair_gen.__next__()\n",
    "print(X1.shape, X2.shape, Y.shape)\n",
    "\n",
    "# (32, 299, 299, 3) (32, 299, 299, 3) (32, 2)\n",
    "# Define Model\n",
    "# The model is composed of two pretrained Inception V3 networks without their last prediction layer, \n",
    "# connected to a merge layer that computes element-wise dot product of the two (2048,) sized vectors produced \n",
    "# by the Inception V3. This is then fed into a 3 layer fully connected network that produces the similar / not \n",
    "# similar prediction.\n",
    "# The Inception V3 network weights are frozen, and the Fully Connected network weights are loaded from one trained \n",
    "# using pre-computed image vectors and allowed to be fine-tuned.\n",
    "# In [6]:\n",
    "# distance measure\n",
    "\n",
    "def absdiff(vecs):\n",
    "    x, y = vecs\n",
    "    return K.abs(K.sum(K.stack([x, -y], axis=1), axis=1))\n",
    "\n",
    "def absdiff_output_shape(shapes):\n",
    "    return shapes[0]\n",
    "\n",
    "# BEST_MODEL_FILE = os.path.join(DATA_DIR, \"models\", \"inception-ft-best.h5\")\n",
    "# FINAL_MODEL_FILE = os.path.join(DATA_DIR, \"models\", \"inception-ft-final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,) (10,)\n",
      "(10,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "softmax() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-10dbc0b87f70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# in case of a siamese network, the same instance of the network will be trained,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# but in our case the network is untrainable, so we can have 2 copies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0minception_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minception_v3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInceptionV3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0minception_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minception_v3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInceptionV3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# In [8]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras_applications/inception_v3.py\u001b[0m in \u001b[0;36mInceptionV3\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# Classification block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avg_pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpooling\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/activations.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m   3147\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3148\u001b[0m     \"\"\"\n\u001b[0;32m-> 3149\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "vecs = [np.random.random((10,)), np.random.random((10,))]\n",
    "print(vecs[0].shape, vecs[1].shape)\n",
    "s = absdiff(vecs)\n",
    "print(s.shape)\n",
    "\n",
    "# (10,) (10,)\n",
    "# (10,)\n",
    "# In [7]:\n",
    "# load 2 copies of the inception model\n",
    "# in case of a siamese network, the same instance of the network will be trained,\n",
    "# but in our case the network is untrainable, so we can have 2 copies\n",
    "inception_1 = inception_v3.InceptionV3(weights=\"imagenet\", include_top=True)\n",
    "inception_2 = inception_v3.InceptionV3(weights=\"imagenet\", include_top=True)\n",
    "# In [8]:\n",
    "# Here the last two layers are avg_pool and prediction as shown below:\n",
    "#    avg_pool (None, 8, 8, 2048) (None, 2048)\n",
    "#    predictions (None, 2048) (None, 1000)\n",
    "#\n",
    "# for layer in inception_1.layers:\n",
    "#     print(layer.name, layer.input_shape, layer.output_shape)\n",
    "# In [9]:\n",
    "# freeze weights on the inception network and give each layer a unique name\n",
    "# since we will combine them into a single network\n",
    "for layer in inception_1.layers:\n",
    "    layer.trainable = False\n",
    "    layer.name = layer.name + \"_1\"\n",
    "for layer in inception_2.layers:\n",
    "    layer.trainable = False\n",
    "    layer.name = layer.name + \"_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [10]:\n",
    "# outputs of the inception networks, these will be connected to our head FCN\n",
    "vector_1 = inception_1.get_layer(\"avg_pool_1\").output\n",
    "vector_2 = inception_2.get_layer(\"avg_pool_2\").output\n",
    "# In [11]:\n",
    "# load the pretrained similarity head network. This has been trained to predict similar\n",
    "# images using image vectors\n",
    "sim_head = load_model(os.path.join(DATA_DIR, \"models\", \"A_A_inceptionv3-l1-final_100_adam.h5\"))\n",
    "for layer in sim_head.layers:\n",
    "    print(layer.name, layer.input_shape, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [12]:\n",
    "# attach output of the inception networks to the similarity head\n",
    "# output is a prediction tensor\n",
    "prediction = sim_head([vector_1, vector_2])\n",
    "# In [13]:\n",
    "# declare a model that takes image inputs on its truncated Inception subnetworks\n",
    "# and returns the prediction as the output. Inputs are Input(shape=(299, 299, 3))\n",
    "model = Model(inputs=[inception_1.input, inception_2.input], outputs=prediction)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# Train Network\n",
    "# In [14]:\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 100\n",
    "BEST_MODEL_FILE = os.path.join(DATA_DIR, \"models\", \"A_A_inceptionv3-l1-f-best_100_args6_adam.h5\")\n",
    "FINAL_MODEL_FILE = os.path.join(DATA_DIR, \"models\", \"A_A_inceptionv3-l1-f-final_100_args6_adam.h5\")\n",
    "# In [15]:\n",
    "triples_data_trainval, triples_data_test = train_test_split(triples_data, train_size=0.8)\n",
    "triples_data_train, triples_data_val = train_test_split(triples_data_trainval, train_size=0.9)\n",
    "print(len(triples_data_train), len(triples_data_val), len(triples_data_test))\n",
    "# 2983 332 829\n",
    "# In [16]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'triples_data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4e46f3dca738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m datagens = [ImageDataGenerator(**datagen_args),\n\u001b[1;32m     59\u001b[0m             ImageDataGenerator(**datagen_args)]\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mtrain_pair_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriples_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatagens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mval_pair_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriples_data_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# In [17]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'triples_data_train' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# 2_A_A_inceptionv3-l1-ft-best_10.h5\n",
    "datagen_args = dict(rotation_range=10,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "#                     shear_range = 0.2, ###\n",
    "                    zoom_range=0.2)\n",
    "'''\n",
    "# 2_A_A_inceptionv3-l1-ft-best_10_args2.h5\n",
    "\n",
    "# from skimage import exposure\n",
    "\n",
    "# def AHE(img):\n",
    "#     img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "#     return img_adapteq\n",
    "\n",
    "datagen_args = dict(# featurewise_center=True, #args5\n",
    "                    # featurewise_std_normalization=True, #args5\n",
    "                    featurewise_center=True,\n",
    "                    rotation_range=0.2,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True, #args6\n",
    "#                     preprocessing_function=AHE, #args7\n",
    "                    fill_mode='nearest',\n",
    "                    data_format='channels_last', #args6\n",
    "                    zca_whitening=False) #args6\n",
    "'''\n",
    "# args3\n",
    "from skimage import exposure\n",
    "\n",
    "def AHE(img):\n",
    "    img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "    return img_adapteq\n",
    "\n",
    "datagen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    preprocessing_function=AHE,\n",
    "                    fill_mode='nearest')\n",
    "'''\n",
    "'''\n",
    "# args4\n",
    "datagen_args = dict(featurewise_center=True,\n",
    "                    featurewise_std_normalization=True,\n",
    "                    rotation_range=20,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    horizontal_flip=True)\n",
    "'''\n",
    "\n",
    "datagens = [ImageDataGenerator(**datagen_args),\n",
    "            ImageDataGenerator(**datagen_args)]\n",
    "train_pair_gen = pair_generator(triples_data_train, image_cache, datagens, BATCH_SIZE)\n",
    "val_pair_gen = pair_generator(triples_data_val, image_cache, None, BATCH_SIZE)\n",
    "# In [17]:\n",
    "num_train_steps = len(triples_data_train) // BATCH_SIZE\n",
    "num_val_steps = len(triples_data_val) // BATCH_SIZE\n",
    "# In [18]:\n",
    "checkpoint = ModelCheckpoint(filepath=BEST_MODEL_FILE, save_best_only=True)\n",
    "history = model.fit_generator(train_pair_gen, \n",
    "                             steps_per_epoch=num_train_steps,\n",
    "                             epochs=NUM_EPOCHS,\n",
    "                             validation_data=val_pair_gen,\n",
    "                             validation_steps=num_val_steps,\n",
    "                             callbacks=[checkpoint])\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"blue\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"red\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"blue\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"red\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# In [20]:\n",
    "model.save(FINAL_MODEL_FILE, overwrite=True)\n",
    "# Predictions\n",
    "# In [21]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageDataGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    ytest, ytest_ = [], []\n",
    "    test_pair_gen = pair_generator(triples_data_test, image_cache, None, BATCH_SIZE)\n",
    "    num_test_steps = len(triples_data_test) // BATCH_SIZE\n",
    "    curr_test_steps = 0\n",
    "    for [X1test, X2test], Ytest in test_pair_gen:\n",
    "        if curr_test_steps > num_test_steps:\n",
    "            break\n",
    "        Ytest_ = model.predict([X1test, X2test])\n",
    "        ytest.extend(np.argmax(Ytest, axis=1).tolist())\n",
    "        ytest_.extend(np.argmax(Ytest_, axis=1).tolist())\n",
    "        curr_test_steps += 1\n",
    "    acc = accuracy_score(ytest, ytest_)\n",
    "    cm = confusion_matrix(ytest, ytest_)\n",
    "    return acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Evaluation Results: final model on test set ====\n",
      "Accuracy Score: 0.990\n",
      "Confusion Matrix\n",
      "[[312   4]\n",
      " [  3 353]]\n"
     ]
    }
   ],
   "source": [
    "print(\"==== Evaluation Results: final model on test set ====\")\n",
    "final_model = load_model(FINAL_MODEL_FILE)\n",
    "acc, cm = evaluate_model(final_model)\n",
    "print(\"Accuracy Score: {:.3f}\".format(acc))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Evaluation Results: best model on test set ====\n",
      "Accuracy Score: 0.991\n",
      "Confusion Matrix\n",
      "[[322   5]\n",
      " [  1 344]]\n"
     ]
    }
   ],
   "source": [
    "print(\"==== Evaluation Results: best model on test set ====\")\n",
    "best_model = load_model(BEST_MODEL_FILE)\n",
    "acc, cm = evaluate_model(best_model)\n",
    "print(\"Accuracy Score: {:.3f}\".format(acc))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "image = plt.imread(os.path.join(IMAGE_DIR, '100001.jpg'))\n",
    "image = imresize(image, (299, 299))\n",
    "image = image.astype(\"float32\")\n",
    "image = inception_v3.preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title=\"Confusion Matrix\", cmap=plt.cm.Blues):\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plot_confusion_matrix(cm, range(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object pair_generator at 0x7fb24077bf10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest, ytest_ = [], []\n",
    "test_pair_gen = pair_generator(triples_data_test, image_cache, None, BATCH_SIZE)\n",
    "num_test_steps = len(triples_data_test) // BATCH_SIZE\n",
    "curr_test_steps = 0\n",
    "test_pair_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.89803922 -0.92941177 -0.92156863]\n",
      "   [-0.89803922 -0.92941177 -0.92156863]\n",
      "   [-0.89803922 -0.92941177 -0.92156863]\n",
      "   ...\n",
      "   [ 0.45098042  0.7019608   0.65490198]\n",
      "   [ 0.45882356  0.71764708  0.66274512]\n",
      "   [ 0.47450984  0.73333335  0.67843139]]\n",
      "\n",
      "  [[-0.88235295 -0.9137255  -0.9137255 ]\n",
      "   [-0.88235295 -0.9137255  -0.9137255 ]\n",
      "   [-0.88235295 -0.9137255  -0.9137255 ]\n",
      "   ...\n",
      "   [ 0.43529415  0.67843139  0.64705884]\n",
      "   [ 0.44313729  0.7019608   0.65490198]\n",
      "   [ 0.45882356  0.71764708  0.67058825]]\n",
      "\n",
      "  [[-0.85882354 -0.89019608 -0.9137255 ]\n",
      "   [-0.85882354 -0.89019608 -0.9137255 ]\n",
      "   [-0.86666667 -0.89803922 -0.9137255 ]\n",
      "   ...\n",
      "   [ 0.41176474  0.65490198  0.63921571]\n",
      "   [ 0.42745101  0.67843139  0.65490198]\n",
      "   [ 0.44313729  0.69411767  0.67058825]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.04313725 -0.01960784 -0.09019607]\n",
      "   [-0.05882353 -0.03529412 -0.13725489]\n",
      "   [-0.06666666 -0.04313725 -0.1607843 ]\n",
      "   ...\n",
      "   [ 0.05882359 -0.20784312 -0.53725493]\n",
      "   [ 0.082353   -0.18431371 -0.50588238]\n",
      "   [ 0.12156868 -0.0745098  -0.34901959]]\n",
      "\n",
      "  [[-0.05882353 -0.05882353 -0.12156862]\n",
      "   [-0.05098039 -0.04313725 -0.13725489]\n",
      "   [-0.06666666 -0.05882353 -0.16862744]\n",
      "   ...\n",
      "   [ 0.05882359 -0.21568626 -0.57647061]\n",
      "   [ 0.06666672 -0.17647058 -0.54509807]\n",
      "   [ 0.11372554 -0.02745098 -0.35686272]]\n",
      "\n",
      "  [[-0.2235294  -0.2235294  -0.3098039 ]\n",
      "   [-0.2235294  -0.23137254 -0.30196077]\n",
      "   [-0.23137254 -0.23921567 -0.30196077]\n",
      "   ...\n",
      "   [-0.12156862 -0.36470586 -0.59215689]\n",
      "   [-0.12941176 -0.32549018 -0.56862748]\n",
      "   [-0.08235294 -0.17647058 -0.38823527]]]\n",
      "\n",
      "\n",
      " [[[-0.05882353 -0.19999999 -0.23137254]\n",
      "   [-0.03529412 -0.1607843  -0.19215685]\n",
      "   [-0.01176471 -0.12156862 -0.1607843 ]\n",
      "   ...\n",
      "   [-0.74901962 -0.77254903 -0.78823531]\n",
      "   [-0.75686276 -0.7647059  -0.78823531]\n",
      "   [-0.75686276 -0.74901962 -0.78823531]]\n",
      "\n",
      "  [[ 0.23137259  0.082353    0.03529418]\n",
      "   [ 0.25490201  0.12156868  0.06666672]\n",
      "   [ 0.28627455  0.17647064  0.11372554]\n",
      "   ...\n",
      "   [-0.7019608  -0.70980394 -0.74117649]\n",
      "   [-0.7019608  -0.70980394 -0.74117649]\n",
      "   [-0.68627453 -0.7019608  -0.73333335]]\n",
      "\n",
      "  [[ 0.38823533  0.23921573  0.17647064]\n",
      "   [ 0.39607847  0.26274514  0.19215691]\n",
      "   [ 0.41176474  0.30196083  0.23137259]\n",
      "   ...\n",
      "   [-0.70980394 -0.7019608  -0.74117649]\n",
      "   [-0.69411767 -0.70980394 -0.73333335]\n",
      "   [-0.67058825 -0.71764708 -0.74117649]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.74901962 -0.78823531 -0.81176472]\n",
      "   [-0.75686276 -0.79607844 -0.81960785]\n",
      "   [-0.75686276 -0.79607844 -0.81960785]\n",
      "   ...\n",
      "   [-0.54509807 -0.63137257 -0.65490198]\n",
      "   [-0.5529412  -0.63921571 -0.66274512]\n",
      "   [-0.56078434 -0.64705884 -0.67058825]]\n",
      "\n",
      "  [[-0.74901962 -0.78823531 -0.81176472]\n",
      "   [-0.74901962 -0.78823531 -0.81176472]\n",
      "   [-0.74901962 -0.78823531 -0.81176472]\n",
      "   ...\n",
      "   [-0.54509807 -0.63137257 -0.64705884]\n",
      "   [-0.5529412  -0.63921571 -0.66274512]\n",
      "   [-0.56078434 -0.64705884 -0.67058825]]\n",
      "\n",
      "  [[-0.74901962 -0.78823531 -0.81176472]\n",
      "   [-0.74901962 -0.78823531 -0.81176472]\n",
      "   [-0.74901962 -0.78823531 -0.81176472]\n",
      "   ...\n",
      "   [-0.54509807 -0.62352943 -0.67843139]\n",
      "   [-0.5529412  -0.63137257 -0.69411767]\n",
      "   [-0.56078434 -0.63921571 -0.7019608 ]]]\n",
      "\n",
      "\n",
      " [[[-0.63921571 -0.75686276 -0.80392158]\n",
      "   [-0.63921571 -0.75686276 -0.81176472]\n",
      "   [-0.6156863  -0.73333335 -0.78039217]\n",
      "   ...\n",
      "   [-0.15294117 -0.27058822 -0.3098039 ]\n",
      "   [-0.15294117 -0.27058822 -0.29411763]\n",
      "   [-0.16862744 -0.28627449 -0.3098039 ]]\n",
      "\n",
      "  [[-0.64705884 -0.77254903 -0.78039217]\n",
      "   [-0.65490198 -0.78039217 -0.78823531]\n",
      "   [-0.63137257 -0.75686276 -0.7647059 ]\n",
      "   ...\n",
      "   [-0.16862744 -0.28627449 -0.3098039 ]\n",
      "   [-0.16862744 -0.28627449 -0.3098039 ]\n",
      "   [-0.17647058 -0.29411763 -0.31764704]]\n",
      "\n",
      "  [[-0.64705884 -0.7647059  -0.77254903]\n",
      "   [-0.63921571 -0.7647059  -0.77254903]\n",
      "   [-0.62352943 -0.74901962 -0.75686276]\n",
      "   ...\n",
      "   [-0.18431371 -0.30196077 -0.32549018]\n",
      "   [-0.18431371 -0.30196077 -0.32549018]\n",
      "   [-0.19215685 -0.3098039  -0.33333331]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.082353    0.04313731 -0.00392157]\n",
      "   [ 0.06666672  0.02745104 -0.01960784]\n",
      "   [ 0.09803927  0.06666672  0.01176476]\n",
      "   ...\n",
      "   [ 0.07450986  0.05882359 -0.05098039]\n",
      "   [ 0.05098045  0.00392163 -0.09019607]\n",
      "   [ 0.05098045 -0.02745098 -0.11372548]]\n",
      "\n",
      "  [[ 0.07450986  0.03529418 -0.01176471]\n",
      "   [ 0.06666672  0.02745104 -0.01960784]\n",
      "   [ 0.09803927  0.05882359  0.01176476]\n",
      "   ...\n",
      "   [ 0.04313731  0.0196079  -0.0745098 ]\n",
      "   [ 0.03529418  0.00392163 -0.08235294]\n",
      "   [ 0.0196079  -0.01176471 -0.10588235]]\n",
      "\n",
      "  [[-0.11372548 -0.15294117 -0.19215685]\n",
      "   [-0.11372548 -0.15294117 -0.19215685]\n",
      "   [-0.08235294 -0.12156862 -0.1607843 ]\n",
      "   ...\n",
      "   [-0.12941176 -0.1607843  -0.2235294 ]\n",
      "   [-0.12156862 -0.13725489 -0.20784312]\n",
      "   [-0.15294117 -0.1607843  -0.23137254]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.59215689 -0.67843139 -0.60000002]\n",
      "   [-0.53725493 -0.63137257 -0.56862748]\n",
      "   [-0.52156866 -0.60784316 -0.56078434]\n",
      "   ...\n",
      "   [ 0.09803927  0.15294123  0.30196083]\n",
      "   [ 0.12941182  0.23137259  0.37254906]\n",
      "   [ 0.10588241  0.26274514  0.4039216 ]]\n",
      "\n",
      "  [[-0.51372552 -0.60784316 -0.5529412 ]\n",
      "   [-0.49803919 -0.58431375 -0.51372552]\n",
      "   [-0.49803919 -0.59215689 -0.49019605]\n",
      "   ...\n",
      "   [ 0.082353    0.14509809  0.28627455]\n",
      "   [ 0.12941182  0.21568632  0.35686278]\n",
      "   [ 0.12941182  0.25490201  0.4039216 ]]\n",
      "\n",
      "  [[-0.46666664 -0.5529412  -0.48235291]\n",
      "   [-0.4588235  -0.5529412  -0.4588235 ]\n",
      "   [-0.46666664 -0.56862748 -0.45098037]\n",
      "   ...\n",
      "   [ 0.06666672  0.13725495  0.27058828]\n",
      "   [ 0.11372554  0.18431377  0.33333337]\n",
      "   [ 0.15294123  0.22352946  0.39607847]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.09803921 -0.19215685 -0.09803921]\n",
      "   [-0.08235294 -0.13725489 -0.0745098 ]\n",
      "   [-0.04313725 -0.0745098   0.03529418]\n",
      "   ...\n",
      "   [ 0.23921573  0.27843142  0.16078436]\n",
      "   [ 0.26274514  0.30980396  0.27058828]\n",
      "   [ 0.36470592  0.52156866  0.57647061]]\n",
      "\n",
      "  [[-0.10588235 -0.19999999 -0.10588235]\n",
      "   [-0.12156862 -0.19999999 -0.12156862]\n",
      "   [-0.09803921 -0.17647058 -0.05098039]\n",
      "   ...\n",
      "   [ 0.3176471   0.35686278  0.25490201]\n",
      "   [ 0.34901965  0.39607847  0.35686278]\n",
      "   [ 0.33333337  0.49803925  0.52941179]]\n",
      "\n",
      "  [[-0.3098039  -0.35686272 -0.27843136]\n",
      "   [-0.3098039  -0.35686272 -0.29411763]\n",
      "   [-0.28627449 -0.34901959 -0.23921567]\n",
      "   ...\n",
      "   [-0.01960784  0.00392163 -0.02745098]\n",
      "   [ 0.04313731  0.09019613  0.05098045]\n",
      "   [ 0.11372554  0.27058828  0.23921573]]]\n",
      "\n",
      "\n",
      " [[[ 0.11372554 -0.09803921 -0.29411763]\n",
      "   [ 0.13725495 -0.08235294 -0.2235294 ]\n",
      "   [ 0.12156868 -0.11372548 -0.19215685]\n",
      "   ...\n",
      "   [ 0.14509809 -0.09019607 -0.20784312]\n",
      "   [ 0.15294123 -0.06666666 -0.18431371]\n",
      "   [ 0.1686275  -0.03529412 -0.29411763]]\n",
      "\n",
      "  [[ 0.12156868 -0.08235294 -0.26274508]\n",
      "   [ 0.12941182 -0.09019607 -0.2235294 ]\n",
      "   [ 0.13725495 -0.09019607 -0.18431371]\n",
      "   ...\n",
      "   [ 0.15294123 -0.06666666 -0.20784312]\n",
      "   [ 0.18431377 -0.06666666 -0.1607843 ]\n",
      "   [ 0.15294123 -0.06666666 -0.2235294 ]]\n",
      "\n",
      "  [[ 0.14509809 -0.05098039 -0.20784312]\n",
      "   [ 0.12941182 -0.06666666 -0.21568626]\n",
      "   [ 0.14509809 -0.06666666 -0.19999999]\n",
      "   ...\n",
      "   [ 0.17647064 -0.05098039 -0.19999999]\n",
      "   [ 0.20784318 -0.08235294 -0.18431371]\n",
      "   [ 0.1686275  -0.0745098  -0.18431371]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.35686278  0.19215691 -0.11372548]\n",
      "   [ 0.34901965  0.21568632 -0.12941176]\n",
      "   [ 0.32549024  0.22352946 -0.0745098 ]\n",
      "   ...\n",
      "   [ 0.27058828  0.14509809 -0.16862744]\n",
      "   [ 0.27843142  0.15294123 -0.20784312]\n",
      "   [ 0.29411769  0.16078436 -0.15294117]]\n",
      "\n",
      "  [[ 0.34901965  0.21568632 -0.04313725]\n",
      "   [ 0.34901965  0.23137259 -0.05882353]\n",
      "   [ 0.34117651  0.23921573 -0.05882353]\n",
      "   ...\n",
      "   [ 0.30196083  0.23137259 -0.04313725]\n",
      "   [ 0.3176471   0.25490201 -0.03529412]\n",
      "   [ 0.30196083  0.23921573 -0.03529412]]\n",
      "\n",
      "  [[ 0.09019613  0.01176476 -0.16862744]\n",
      "   [ 0.09803927  0.01176476 -0.17647058]\n",
      "   [ 0.09803927  0.0196079  -0.19215685]\n",
      "   ...\n",
      "   [ 0.07450986  0.04313731 -0.13725489]\n",
      "   [ 0.09803927  0.07450986 -0.09803921]\n",
      "   [ 0.10588241  0.082353   -0.09803921]]]\n",
      "\n",
      "\n",
      " [[[-0.96862745 -0.93725491 -0.92941177]\n",
      "   [-0.96862745 -0.93725491 -0.92941177]\n",
      "   [-0.96862745 -0.93725491 -0.92941177]\n",
      "   ...\n",
      "   [-0.98431373 -0.93725491 -0.95294118]\n",
      "   [-0.98431373 -0.93725491 -0.95294118]\n",
      "   [-0.97647059 -0.92941177 -0.95294118]]\n",
      "\n",
      "  [[-0.98431373 -0.95294118 -0.94509804]\n",
      "   [-0.97647059 -0.94509804 -0.93725491]\n",
      "   [-0.96862745 -0.93725491 -0.92941177]\n",
      "   ...\n",
      "   [-0.93725491 -0.88235295 -0.93725491]\n",
      "   [-0.94509804 -0.89019608 -0.94509804]\n",
      "   [-0.94509804 -0.89019608 -0.95294118]]\n",
      "\n",
      "  [[-0.98431373 -0.95294118 -0.94509804]\n",
      "   [-0.98431373 -0.95294118 -0.94509804]\n",
      "   [-0.98431373 -0.95294118 -0.94509804]\n",
      "   ...\n",
      "   [-0.95294118 -0.89803922 -0.95294118]\n",
      "   [-0.95294118 -0.89803922 -0.95294118]\n",
      "   [-0.95294118 -0.89803922 -0.95294118]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.96862745 -0.92941177 -0.96078432]\n",
      "   [-0.96862745 -0.92941177 -0.96078432]\n",
      "   [-0.95294118 -0.9137255  -0.95294118]\n",
      "   ...\n",
      "   [-0.11372548 -0.19999999 -0.23137254]\n",
      "   [-0.11372548 -0.19999999 -0.23137254]\n",
      "   [-0.09803921 -0.19215685 -0.2235294 ]]\n",
      "\n",
      "  [[-0.96078432 -0.92156863 -0.95294118]\n",
      "   [-0.96078432 -0.92156863 -0.95294118]\n",
      "   [-0.96078432 -0.92156863 -0.96078432]\n",
      "   ...\n",
      "   [-0.14509803 -0.2235294  -0.25490195]\n",
      "   [-0.16862744 -0.23921567 -0.27843136]\n",
      "   [-0.17647058 -0.24705881 -0.28627449]]\n",
      "\n",
      "  [[-0.96862745 -0.92941177 -0.96078432]\n",
      "   [-0.97647059 -0.93725491 -0.96862745]\n",
      "   [-0.97647059 -0.93725491 -0.96862745]\n",
      "   ...\n",
      "   [-0.26274508 -0.31764704 -0.35686272]\n",
      "   [-0.27843136 -0.33333331 -0.372549  ]\n",
      "   [-0.30196077 -0.35686272 -0.39607841]]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0]\n",
      "[1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0]\n",
      "Accuracy Score: 1.000\n",
      "Confusion Matrix\n",
      "[[14  0]\n",
      " [ 0 18]]\n"
     ]
    }
   ],
   "source": [
    "ytest, ytest_ = [], []\n",
    "i = 0\n",
    "for [X1test, X2test], Ytest in test_pair_gen:\n",
    "    i += 1\n",
    "    print(X1test)\n",
    "    if curr_test_steps > num_test_steps:\n",
    "        break\n",
    "    Ytest_ = best_model.predict([X1test, X2test])\n",
    "    ytest.extend(np.argmax(Ytest, axis=1).tolist())\n",
    "    ytest_.extend(np.argmax(Ytest_, axis=1).tolist())\n",
    "    curr_test_steps += 1\n",
    "    print(ytest)\n",
    "    print(ytest_)\n",
    "    break\n",
    "\n",
    "acc = accuracy_score(ytest, ytest_)\n",
    "cm = confusion_matrix(ytest, ytest_)\n",
    "\n",
    "print(\"Accuracy Score: {:.3f}\".format(acc))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras import backend as K\n",
    "from keras.applications import inception_v3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.core import Activation, Dense, Dropout, Lambda\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from random import shuffle\n",
    "from scipy.misc import imresize\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628\n",
      "4469\n",
      "[['010001.jpg', '010006.jpg', '0'], ['010001.jpg', '010007.jpg', '0'], ['010001.jpg', '010008.jpg', '0'], ['010001.jpg', '010009.jpg', '0'], ['010001.jpg', '010010.jpg', '0']]\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"\"\n",
    "# IMAGE_DIR = os.path.join(DATA_DIR, \"holiday-photos/jpg\")\n",
    "# IMAGE_DIR = os.path.join(DATA_DIR, \"train_folder\")\n",
    "IMAGE_DIR = os.path.join(DATA_DIR, \"new_test_folder\")\n",
    "    \n",
    "# image_dir = 'new_test_folder'\n",
    "file_name = []\n",
    "dfcols = ['img_name']\n",
    "df = pd.DataFrame(columns=dfcols)\n",
    "\n",
    "for img_file in os.listdir(IMAGE_DIR):\n",
    "    if img_file.find(\".jpg\") != -1:\n",
    "        df = df.append(pd.Series([img_file], index=dfcols),\n",
    "                            ignore_index=True) \n",
    "df = df.sort_values(\"img_name\", ascending=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv('all.csv', encoding='utf-8', index=False)\n",
    " \n",
    "    \n",
    "group1 = ['0001', '0002', '0003']\n",
    "group2 = ['0006', '0007', '0008', '0009']\n",
    "mlabel = ''\n",
    "all_triples = []\n",
    "triples = []\n",
    "for index_1, row_1 in df.iterrows():\n",
    "    for index_2, row_2 in df.iterrows():\n",
    "        if index_2 > index_1:\n",
    "            if row_1['img_name'][2:6] in group1:\n",
    "                mg_l = '1'\n",
    "            else:\n",
    "                mg_l = '2'\n",
    "            if row_2['img_name'][2:6] in group1:\n",
    "                mg_r = '1'\n",
    "            else:\n",
    "                mg_r = '2'\n",
    "            mlabel = '0'\n",
    "            triples = []\n",
    "            if (row_1['img_name'][0:2] == row_2['img_name'][0:2] and mg_l == '2' and mg_r == '2') :   \n",
    "                mlabel = '1'\n",
    "                triples = [row_1['img_name'],row_2['img_name'],mlabel]\n",
    "#             if (row_1['img_name'][0:2] != row_2['img_name'][0:2] and mg_l == '2' and mg_r == '2') :   \n",
    "#                 mlabel = '0'\n",
    "#                 triples = [row_1['img_name'],row_2['img_name'],mlabel]\n",
    "            if (row_1['img_name'][0:2] == row_2['img_name'][0:2] and mg_l != mg_r ) :   \n",
    "                mlabel = '0'\n",
    "                triples = [row_1['img_name'],row_2['img_name'],mlabel]\n",
    "            if len(triples) != 0 :    \n",
    "                all_triples.append(triples)\n",
    "\n",
    "triples_data = all_triples # create_triples(IMAGE_DIR)\n",
    "\n",
    "print(len(df))\n",
    "print(len(all_triples))\n",
    "print(triples_data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images from 0/4469 pairs loaded to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images from 1000/4469 pairs loaded to cache\n",
      "images from 2000/4469 pairs loaded to cache\n",
      "images from 3000/4469 pairs loaded to cache\n",
      "images from 4000/4469 pairs loaded to cache\n",
      "images from 4468/4469 pairs loaded to cache, COMPLETE\n"
     ]
    }
   ],
   "source": [
    "def load_image_cache(image_cache, image_filename):\n",
    "    image = plt.imread(os.path.join(IMAGE_DIR, image_filename))\n",
    "    image = imresize(image, (299, 299))\n",
    "    image = image.astype(\"float32\")\n",
    "    image = inception_v3.preprocess_input(image)\n",
    "    image_cache[image_filename] = image\n",
    "    \n",
    "image_cache = {}\n",
    "num_pairs = len(triples_data)\n",
    "for i, (image_filename_l, image_filename_r, _) in enumerate(triples_data):\n",
    "    if i % 1000 == 0:\n",
    "        print(\"images from {:d}/{:d} pairs loaded to cache\".format(i, num_pairs))\n",
    "    if image_filename_l not in image_cache:\n",
    "        load_image_cache(image_cache, image_filename_l)\n",
    "    if image_filename_r not in image_cache:\n",
    "        load_image_cache(image_cache, image_filename_r)\n",
    "print(\"images from {:d}/{:d} pairs loaded to cache, COMPLETE\".format(i, num_pairs))\n",
    "\n",
    "def pair_generator(triples, image_cache, datagens, batch_size=32):\n",
    "    while True:\n",
    "        # shuffle once per batch\n",
    "        indices = np.random.permutation(np.arange(len(triples)))\n",
    "        num_batches = len(triples) // batch_size\n",
    "        for bid in range(num_batches):\n",
    "            batch_indices = indices[bid * batch_size : (bid + 1) * batch_size]\n",
    "            batch = [triples[i] for i in batch_indices]\n",
    "            X1 = np.zeros((batch_size, 299, 299, 3))\n",
    "            X2 = np.zeros((batch_size, 299, 299, 3))\n",
    "            Y = np.zeros((batch_size, 2))\n",
    "            for i, (image_filename_l, image_filename_r, label) in enumerate(batch):\n",
    "                if datagens is None or len(datagens) == 0:\n",
    "                    X1[i] = image_cache[image_filename_l]\n",
    "                    X2[i] = image_cache[image_filename_r]\n",
    "                else:\n",
    "                    X1[i] = datagens[0].random_transform(image_cache[image_filename_l])\n",
    "                    X2[i] = datagens[1].random_transform(image_cache[image_filename_r])\n",
    "                Y[i] = [1, 0] if label == 0 else [0, 1]\n",
    "            yield [X1, X2], Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 299, 299, 3) (32, 299, 299, 3) (32, 2)\n"
     ]
    }
   ],
   "source": [
    "datagen_args = dict(rotation_range=10,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "#                     shear_range = 0.2,\n",
    "                    zoom_range=0.2)\n",
    "datagens = [ImageDataGenerator(**datagen_args),\n",
    "            ImageDataGenerator(**datagen_args)]\n",
    "pair_gen = pair_generator(triples_data, image_cache, datagens, 32)\n",
    "[X1, X2], Y = pair_gen.__next__()\n",
    "print(X1.shape, X2.shape, Y.shape)\n",
    "\n",
    "# (32, 299, 299, 3) (32, 299, 299, 3) (32, 2)\n",
    "# Define Model\n",
    "# The model is composed of two pretrained Inception V3 networks without their last prediction layer, \n",
    "# connected to a merge layer that computes element-wise dot product of the two (2048,) sized vectors produced \n",
    "# by the Inception V3. This is then fed into a 3 layer fully connected network that produces the similar / not \n",
    "# similar prediction.\n",
    "# The Inception V3 network weights are frozen, and the Fully Connected network weights are loaded from one trained \n",
    "# using pre-computed image vectors and allowed to be fine-tuned.\n",
    "# In [6]:\n",
    "# distance measure\n",
    "\n",
    "def absdiff(vecs):\n",
    "    x, y = vecs\n",
    "    return K.abs(K.sum(K.stack([x, -y], axis=1), axis=1))\n",
    "\n",
    "def absdiff_output_shape(shapes):\n",
    "    return shapes[0]\n",
    "\n",
    "# BEST_MODEL_FILE = os.path.join(DATA_DIR, \"models\", \"inception-ft-best.h5\")\n",
    "# FINAL_MODEL_FILE = os.path.join(DATA_DIR, \"models\", \"inception-ft-final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,) (10,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "vecs = [np.random.random((10,)), np.random.random((10,))]\n",
    "print(vecs[0].shape, vecs[1].shape)\n",
    "s = absdiff(vecs)\n",
    "print(s.shape)\n",
    "\n",
    "# (10,) (10,)\n",
    "# (10,)\n",
    "# In [7]:\n",
    "# load 2 copies of the inception model\n",
    "# in case of a siamese network, the same instance of the network will be trained,\n",
    "# but in our case the network is untrainable, so we can have 2 copies\n",
    "inception_1 = inception_v3.InceptionV3(weights=\"imagenet\", include_top=True)\n",
    "inception_2 = inception_v3.InceptionV3(weights=\"imagenet\", include_top=True)\n",
    "# In [8]:\n",
    "# Here the last two layers are avg_pool and prediction as shown below:\n",
    "#    avg_pool (None, 8, 8, 2048) (None, 2048)\n",
    "#    predictions (None, 2048) (None, 1000)\n",
    "#\n",
    "# for layer in inception_1.layers:\n",
    "#     print(layer.name, layer.input_shape, layer.output_shape)\n",
    "# In [9]:\n",
    "# freeze weights on the inception network and give each layer a unique name\n",
    "# since we will combine them into a single network\n",
    "for layer in inception_1.layers:\n",
    "    layer.trainable = False\n",
    "    layer.name = layer.name + \"_1\"\n",
    "for layer in inception_2.layers:\n",
    "    layer.trainable = False\n",
    "    layer.name = layer.name + \"_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_5 (None, 2048) (None, 2048)\n",
      "input_6 (None, 2048) (None, 2048)\n",
      "lambda_2 [(None, 2048), (None, 2048)] (None, 2048)\n",
      "dense_7 (None, 2048) (None, 512)\n",
      "dropout_5 (None, 512) (None, 512)\n",
      "activation_7 (None, 512) (None, 512)\n",
      "dense_8 (None, 512) (None, 128)\n",
      "dropout_6 (None, 128) (None, 128)\n",
      "activation_8 (None, 128) (None, 128)\n",
      "dense_9 (None, 128) (None, 2)\n",
      "activation_9 (None, 2) (None, 2)\n"
     ]
    }
   ],
   "source": [
    "# In [10]:\n",
    "# outputs of the inception networks, these will be connected to our head FCN\n",
    "vector_1 = inception_1.get_layer(\"avg_pool_1\").output\n",
    "vector_2 = inception_2.get_layer(\"avg_pool_2\").output\n",
    "# In [11]:\n",
    "# load the pretrained similarity head network. This has been trained to predict similar\n",
    "# images using image vectors\n",
    "sim_head = load_model(os.path.join(DATA_DIR, \"models\", \"A_A_inceptionv3-l1-final_10.h5\"))\n",
    "for layer in sim_head.layers:\n",
    "    print(layer.name, layer.input_shape, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3217 358 894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# In [12]:\n",
    "# attach output of the inception networks to the similarity head\n",
    "# output is a prediction tensor\n",
    "prediction = sim_head([vector_1, vector_2])\n",
    "# In [13]:\n",
    "# declare a model that takes image inputs on its truncated Inception subnetworks\n",
    "# and returns the prediction as the output. Inputs are Input(shape=(299, 299, 3))\n",
    "model = Model(inputs=[inception_1.input, inception_2.input], outputs=prediction)\n",
    "\n",
    "model.compile(optimizer=\"Nadam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# Train Network\n",
    "# In [14]:\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "BEST_MODEL_FILE = os.path.join(DATA_DIR, \"models\", \"A_A_inceptionv3-l1-ft-best_10_v2.h5\")\n",
    "FINAL_MODEL_FILE = os.path.join(DATA_DIR, \"models\", \"A_A_inceptionv3-l1-ft-final_10_v2.h5\")\n",
    "# In [15]:\n",
    "triples_data_trainval, triples_data_test = train_test_split(triples_data, train_size=0.8)\n",
    "triples_data_train, triples_data_val = train_test_split(triples_data_trainval, train_size=0.9)\n",
    "print(len(triples_data_train), len(triples_data_val), len(triples_data_test))\n",
    "# 3217 358 894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 363s 4s/step - loss: 5.7553e-05 - acc: 1.0000 - val_loss: 6.9935e-07 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 353s 4s/step - loss: 2.6492e-06 - acc: 1.0000 - val_loss: 3.9522e-07 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 352s 4s/step - loss: 1.9945e-07 - acc: 1.0000 - val_loss: 3.5407e-07 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 352s 4s/step - loss: 3.3647e-06 - acc: 1.0000 - val_loss: 2.3893e-07 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 352s 4s/step - loss: 1.8042e-06 - acc: 1.0000 - val_loss: 1.6848e-07 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 352s 4s/step - loss: 1.5161e-06 - acc: 1.0000 - val_loss: 1.5934e-07 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 352s 4s/step - loss: 1.2526e-07 - acc: 1.0000 - val_loss: 1.5511e-07 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 352s 4s/step - loss: 1.2187e-07 - acc: 1.0000 - val_loss: 1.5477e-07 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 352s 4s/step - loss: 8.9292e-07 - acc: 1.0000 - val_loss: 1.6154e-07 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 352s 4s/step - loss: 1.2090e-07 - acc: 1.0000 - val_loss: 1.2954e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In [16]:\n",
    "datagen_args = dict(rotation_range=10,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "#                     shear_range = 0.2, ###\n",
    "                    zoom_range=0.2)\n",
    "datagens = [ImageDataGenerator(**datagen_args),\n",
    "            ImageDataGenerator(**datagen_args)]\n",
    "train_pair_gen = pair_generator(triples_data_train, image_cache, datagens, BATCH_SIZE)\n",
    "val_pair_gen = pair_generator(triples_data_val, image_cache, None, BATCH_SIZE)\n",
    "# In [17]:\n",
    "num_train_steps = len(triples_data_train) // BATCH_SIZE\n",
    "num_val_steps = len(triples_data_val) // BATCH_SIZE\n",
    "# In [18]:\n",
    "checkpoint = ModelCheckpoint(filepath=BEST_MODEL_FILE, save_best_only=True)\n",
    "history = model.fit_generator(train_pair_gen, \n",
    "                             steps_per_epoch=num_train_steps,\n",
    "                             epochs=NUM_EPOCHS,\n",
    "                             validation_data=val_pair_gen,\n",
    "                             validation_steps=num_val_steps,\n",
    "                             callbacks=[checkpoint])\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"blue\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"red\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"blue\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"red\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# In [20]:\n",
    "model.save(FINAL_MODEL_FILE, overwrite=True)\n",
    "# Predictions\n",
    "# In [21]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    ytest, ytest_ = [], []\n",
    "    test_pair_gen = pair_generator(triples_data_test, image_cache, None, BATCH_SIZE)\n",
    "    num_test_steps = len(triples_data_test) // BATCH_SIZE\n",
    "    curr_test_steps = 0\n",
    "    for [X1test, X2test], Ytest in test_pair_gen:\n",
    "        if curr_test_steps > num_test_steps:\n",
    "            break\n",
    "        Ytest_ = model.predict([X1test, X2test])\n",
    "        ytest.extend(np.argmax(Ytest, axis=1).tolist())\n",
    "        ytest_.extend(np.argmax(Ytest_, axis=1).tolist())\n",
    "        curr_test_steps += 1\n",
    "    acc = accuracy_score(ytest, ytest_)\n",
    "    cm = confusion_matrix(ytest, ytest_)\n",
    "    return acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Evaluation Results: final model on test set ====\n",
      "Accuracy Score: 1.000\n",
      "Confusion Matrix\n",
      "[[896]]\n"
     ]
    }
   ],
   "source": [
    "print(\"==== Evaluation Results: final model on test set ====\")\n",
    "final_model = load_model(FINAL_MODEL_FILE)\n",
    "acc, cm = evaluate_model(final_model)\n",
    "print(\"Accuracy Score: {:.3f}\".format(acc))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Evaluation Results: best model on test set ====\n",
      "Accuracy Score: 1.000\n",
      "Confusion Matrix\n",
      "[[896]]\n"
     ]
    }
   ],
   "source": [
    "print(\"==== Evaluation Results: best model on test set ====\")\n",
    "best_model = load_model(BEST_MODEL_FILE)\n",
    "acc, cm = evaluate_model(best_model)\n",
    "print(\"Accuracy Score: {:.3f}\".format(acc))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "image = plt.imread(os.path.join(IMAGE_DIR, '100001.jpg'))\n",
    "image = imresize(image, (299, 299))\n",
    "image = image.astype(\"float32\")\n",
    "image = inception_v3.preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title=\"Confusion Matrix\", cmap=plt.cm.Blues):\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plot_confusion_matrix(cm, range(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object pair_generator at 0x7f55bd5061a8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest, ytest_ = [], []\n",
    "test_pair_gen = pair_generator(triples_data_test, image_cache, None, BATCH_SIZE)\n",
    "num_test_steps = len(triples_data_test) // BATCH_SIZE\n",
    "curr_test_steps = 0\n",
    "test_pair_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.23921567 -0.38823527 -0.35686272]\n",
      "   [-0.24705881 -0.39607841 -0.36470586]\n",
      "   [-0.24705881 -0.39607841 -0.35686272]\n",
      "   ...\n",
      "   [-0.27058822 -0.39607841 -0.41960782]\n",
      "   [-0.3098039  -0.42745095 -0.45098037]\n",
      "   [-0.48235291 -0.60000002 -0.62352943]]\n",
      "\n",
      "  [[-0.25490195 -0.41176468 -0.33333331]\n",
      "   [-0.24705881 -0.40392154 -0.33333331]\n",
      "   [-0.24705881 -0.40392154 -0.33333331]\n",
      "   ...\n",
      "   [-0.25490195 -0.372549   -0.39607841]\n",
      "   [-0.29411763 -0.41176468 -0.43529409]\n",
      "   [-0.372549   -0.49019605 -0.51372552]]\n",
      "\n",
      "  [[-0.26274508 -0.41176468 -0.34117645]\n",
      "   [-0.25490195 -0.41176468 -0.34117645]\n",
      "   [-0.23921567 -0.39607841 -0.33333331]\n",
      "   ...\n",
      "   [-0.2235294  -0.34901959 -0.372549  ]\n",
      "   [-0.25490195 -0.372549   -0.39607841]\n",
      "   [-0.3098039  -0.42745095 -0.45098037]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.3098039  -0.45098037 -0.49803919]\n",
      "   [-0.30196077 -0.45098037 -0.49019605]\n",
      "   [-0.30196077 -0.44313723 -0.48235291]\n",
      "   ...\n",
      "   [ 0.15294123  0.15294123  0.04313731]\n",
      "   [ 0.1686275   0.17647064  0.06666672]\n",
      "   [ 0.20000005  0.20784318  0.09019613]]\n",
      "\n",
      "  [[-0.25490195 -0.38039213 -0.42745095]\n",
      "   [-0.23921567 -0.36470586 -0.41176468]\n",
      "   [-0.24705881 -0.36470586 -0.41176468]\n",
      "   ...\n",
      "   [ 0.18431377  0.18431377  0.09019613]\n",
      "   [ 0.22352946  0.22352946  0.12941182]\n",
      "   [ 0.21568632  0.22352946  0.12156868]]\n",
      "\n",
      "  [[-0.28627449 -0.36470586 -0.38823527]\n",
      "   [-0.28627449 -0.36470586 -0.38823527]\n",
      "   [-0.29411763 -0.38039213 -0.39607841]\n",
      "   ...\n",
      "   [-0.03529412 -0.03529412 -0.10588235]\n",
      "   [-0.01176471 -0.01176471 -0.08235294]\n",
      "   [-0.00392157 -0.00392157 -0.0745098 ]]]\n",
      "\n",
      "\n",
      " [[[-0.51372552 -0.5529412  -0.43529409]\n",
      "   [-0.44313723 -0.53725493 -0.40392154]\n",
      "   [-0.41176468 -0.54509807 -0.38823527]\n",
      "   ...\n",
      "   [-0.93725491 -0.98431373 -0.98431373]\n",
      "   [-0.93725491 -0.98431373 -0.98431373]\n",
      "   [-0.92156863 -0.96862745 -0.96862745]]\n",
      "\n",
      "  [[-0.48235291 -0.54509807 -0.41960782]\n",
      "   [-0.42745095 -0.52156866 -0.38039213]\n",
      "   [-0.41960782 -0.54509807 -0.39607841]\n",
      "   ...\n",
      "   [-0.93725491 -0.98431373 -0.98431373]\n",
      "   [-0.92941177 -0.97647059 -0.97647059]\n",
      "   [-0.9137255  -0.96078432 -0.96078432]]\n",
      "\n",
      "  [[-0.45098037 -0.53725493 -0.40392154]\n",
      "   [-0.41960782 -0.51372552 -0.372549  ]\n",
      "   [-0.43529409 -0.53725493 -0.40392154]\n",
      "   ...\n",
      "   [-0.93725491 -0.98431373 -0.98431373]\n",
      "   [-0.92941177 -0.97647059 -0.97647059]\n",
      "   [-0.90588236 -0.95294118 -0.95294118]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.93725491 -0.95294118 -0.94509804]\n",
      "   [-0.93725491 -0.95294118 -0.94509804]\n",
      "   [-0.92941177 -0.94509804 -0.93725491]\n",
      "   ...\n",
      "   [-0.05882353 -0.0745098  -0.06666666]\n",
      "   [-0.08235294 -0.10588235 -0.03529412]\n",
      "   [-0.0745098  -0.09019607 -0.0745098 ]]\n",
      "\n",
      "  [[-0.93725491 -0.95294118 -0.94509804]\n",
      "   [-0.92941177 -0.94509804 -0.93725491]\n",
      "   [-0.92941177 -0.94509804 -0.93725491]\n",
      "   ...\n",
      "   [-0.05882353 -0.0745098  -0.05882353]\n",
      "   [-0.0745098  -0.09019607 -0.05098039]\n",
      "   [-0.06666666 -0.08235294 -0.05882353]]\n",
      "\n",
      "  [[-0.95294118 -0.96862745 -0.96078432]\n",
      "   [-0.94509804 -0.96078432 -0.95294118]\n",
      "   [-0.94509804 -0.95294118 -0.95294118]\n",
      "   ...\n",
      "   [-0.25490195 -0.27058822 -0.23921567]\n",
      "   [-0.23921567 -0.25490195 -0.23921567]\n",
      "   [-0.21568626 -0.23137254 -0.20784312]]]\n",
      "\n",
      "\n",
      " [[[-0.90588236 -0.8509804  -0.90588236]\n",
      "   [-0.9137255  -0.85882354 -0.9137255 ]\n",
      "   [-0.9137255  -0.85882354 -0.90588236]\n",
      "   ...\n",
      "   [-0.96078432 -0.92156863 -0.89019608]\n",
      "   [-0.96078432 -0.92156863 -0.89019608]\n",
      "   [-0.96078432 -0.92156863 -0.89019608]]\n",
      "\n",
      "  [[-0.92156863 -0.86666667 -0.88235295]\n",
      "   [-0.92156863 -0.87450981 -0.88235295]\n",
      "   [-0.9137255  -0.86666667 -0.88235295]\n",
      "   ...\n",
      "   [-0.92156863 -0.87450981 -0.89803922]\n",
      "   [-0.92156863 -0.87450981 -0.89019608]\n",
      "   [-0.92156863 -0.86666667 -0.89019608]]\n",
      "\n",
      "  [[-0.92941177 -0.88235295 -0.89803922]\n",
      "   [-0.92941177 -0.88235295 -0.89803922]\n",
      "   [-0.92941177 -0.88235295 -0.89803922]\n",
      "   ...\n",
      "   [-0.94509804 -0.89019608 -0.93725491]\n",
      "   [-0.93725491 -0.88235295 -0.92941177]\n",
      "   [-0.92941177 -0.87450981 -0.92156863]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.89019608 -0.78823531 -0.83529413]\n",
      "   [-0.89019608 -0.78823531 -0.83529413]\n",
      "   [-0.87450981 -0.77254903 -0.81176472]\n",
      "   ...\n",
      "   [ 0.00392163 -0.03529412 -0.09803921]\n",
      "   [-0.00392157 -0.03529412 -0.09803921]\n",
      "   [ 0.00392163 -0.02745098 -0.09019607]]\n",
      "\n",
      "  [[-0.89019608 -0.79607844 -0.81960785]\n",
      "   [-0.89019608 -0.79607844 -0.81960785]\n",
      "   [-0.87450981 -0.78039217 -0.80392158]\n",
      "   ...\n",
      "   [-0.01176471 -0.05098039 -0.10588235]\n",
      "   [-0.04313725 -0.0745098  -0.13725489]\n",
      "   [-0.05882353 -0.09803921 -0.15294117]]\n",
      "\n",
      "  [[-0.9137255  -0.82745099 -0.83529413]\n",
      "   [-0.90588236 -0.82745099 -0.83529413]\n",
      "   [-0.89803922 -0.81176472 -0.82745099]\n",
      "   ...\n",
      "   [-0.15294117 -0.18431371 -0.21568626]\n",
      "   [-0.17647058 -0.21568626 -0.23921567]\n",
      "   [-0.19999999 -0.23921567 -0.26274508]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.26274508 -0.40392154 -0.43529409]\n",
      "   [-0.27058822 -0.41176468 -0.44313723]\n",
      "   [-0.27058822 -0.40392154 -0.42745095]\n",
      "   ...\n",
      "   [-0.95294118 -0.96078432 -0.99215686]\n",
      "   [-0.92941177 -0.93725491 -0.97647059]\n",
      "   [-0.92941177 -0.93725491 -0.96862745]]\n",
      "\n",
      "  [[-0.26274508 -0.40392154 -0.41960782]\n",
      "   [-0.26274508 -0.40392154 -0.41960782]\n",
      "   [-0.26274508 -0.39607841 -0.41176468]\n",
      "   ...\n",
      "   [-0.96078432 -0.96862745 -0.99215686]\n",
      "   [-0.93725491 -0.94509804 -0.96862745]\n",
      "   [-0.93725491 -0.94509804 -0.96862745]]\n",
      "\n",
      "  [[-0.26274508 -0.40392154 -0.40392154]\n",
      "   [-0.25490195 -0.39607841 -0.39607841]\n",
      "   [-0.26274508 -0.39607841 -0.39607841]\n",
      "   ...\n",
      "   [-0.95294118 -0.96862745 -0.96862745]\n",
      "   [-0.94509804 -0.95294118 -0.96078432]\n",
      "   [-0.93725491 -0.95294118 -0.95294118]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.02745098 -0.28627449 -0.86666667]\n",
      "   [-0.03529412 -0.29411763 -0.8509804 ]\n",
      "   [-0.02745098 -0.29411763 -0.83529413]\n",
      "   ...\n",
      "   [-0.372549   -0.67843139 -0.96862745]\n",
      "   [-0.40392154 -0.7019608  -0.96862745]\n",
      "   [-0.44313723 -0.70980394 -0.96862745]]\n",
      "\n",
      "  [[ 0.03529418 -0.29411763 -0.90588236]\n",
      "   [ 0.02745104 -0.3098039  -0.90588236]\n",
      "   [ 0.0196079  -0.3098039  -0.88235295]\n",
      "   ...\n",
      "   [-0.35686272 -0.7019608  -0.99215686]\n",
      "   [-0.38823527 -0.70980394 -0.99215686]\n",
      "   [-0.41960782 -0.72549021 -0.99215686]]\n",
      "\n",
      "  [[-0.18431371 -0.41960782 -0.83529413]\n",
      "   [-0.19215685 -0.42745095 -0.82745099]\n",
      "   [-0.19215685 -0.43529409 -0.81960785]\n",
      "   ...\n",
      "   [-0.52941179 -0.74117649 -0.95294118]\n",
      "   [-0.52941179 -0.75686276 -0.94509804]\n",
      "   [-0.52941179 -0.77254903 -0.94509804]]]\n",
      "\n",
      "\n",
      " [[[-0.79607844 -0.88235295 -0.95294118]\n",
      "   [-0.72549021 -0.8509804  -0.83529413]\n",
      "   [-0.6156863  -0.75686276 -0.79607844]\n",
      "   ...\n",
      "   [-0.92941177 -1.         -1.        ]\n",
      "   [-0.92156863 -1.         -1.        ]\n",
      "   [-0.92941177 -0.99215686 -1.        ]]\n",
      "\n",
      "  [[-0.79607844 -0.89019608 -0.93725491]\n",
      "   [-0.70980394 -0.83529413 -0.81960785]\n",
      "   [-0.60784316 -0.74901962 -0.78039217]\n",
      "   ...\n",
      "   [-0.93725491 -0.99215686 -1.        ]\n",
      "   [-0.92941177 -0.99215686 -1.        ]\n",
      "   [-0.92156863 -1.         -1.        ]]\n",
      "\n",
      "  [[-0.78823531 -0.89019608 -0.90588236]\n",
      "   [-0.68627453 -0.81176472 -0.80392158]\n",
      "   [-0.6156863  -0.7647059  -0.7647059 ]\n",
      "   ...\n",
      "   [-0.95294118 -0.98431373 -1.        ]\n",
      "   [-0.92941177 -0.99215686 -1.        ]\n",
      "   [-0.89803922 -1.         -1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.72549021 -0.86666667 -0.89019608]\n",
      "   [-0.81176472 -0.95294118 -0.96862745]\n",
      "   [-0.8509804  -0.99215686 -0.99215686]\n",
      "   ...\n",
      "   [-0.21568626 -0.42745095 -0.46666664]\n",
      "   [-0.23137254 -0.44313723 -0.48235291]\n",
      "   [-0.23137254 -0.44313723 -0.48235291]]\n",
      "\n",
      "  [[-0.62352943 -0.80392158 -0.77254903]\n",
      "   [-0.75686276 -0.89803922 -0.89019608]\n",
      "   [-0.85882354 -0.96862745 -0.98431373]\n",
      "   ...\n",
      "   [-0.23137254 -0.41176468 -0.45098037]\n",
      "   [-0.24705881 -0.41960782 -0.4588235 ]\n",
      "   [-0.24705881 -0.41960782 -0.4588235 ]]\n",
      "\n",
      "  [[-0.65490198 -0.80392158 -0.7647059 ]\n",
      "   [-0.74901962 -0.8509804  -0.8509804 ]\n",
      "   [-0.87450981 -0.92941177 -0.96078432]\n",
      "   ...\n",
      "   [-0.40392154 -0.51372552 -0.5529412 ]\n",
      "   [-0.40392154 -0.50588238 -0.54509807]\n",
      "   [-0.38823527 -0.49019605 -0.52941179]]]\n",
      "\n",
      "\n",
      " [[[-0.48235291 -0.75686276 -0.89803922]\n",
      "   [-0.49803919 -0.70980394 -0.90588236]\n",
      "   [-0.41960782 -0.71764708 -0.90588236]\n",
      "   ...\n",
      "   [-0.56078434 -0.72549021 -0.9137255 ]\n",
      "   [-0.49803919 -0.70980394 -0.92156863]\n",
      "   [-0.44313723 -0.7019608  -0.93725491]]\n",
      "\n",
      "  [[-0.42745095 -0.73333335 -0.92156863]\n",
      "   [-0.49019605 -0.72549021 -0.90588236]\n",
      "   [-0.45098037 -0.71764708 -0.86666667]\n",
      "   ...\n",
      "   [-0.54509807 -0.74117649 -0.87450981]\n",
      "   [-0.49803919 -0.71764708 -0.88235295]\n",
      "   [-0.4588235  -0.70980394 -0.89803922]]\n",
      "\n",
      "  [[-0.41176468 -0.7019608  -0.92156863]\n",
      "   [-0.45098037 -0.70980394 -0.88235295]\n",
      "   [-0.4588235  -0.72549021 -0.84313726]\n",
      "   ...\n",
      "   [-0.53725493 -0.7647059  -0.87450981]\n",
      "   [-0.52156866 -0.74117649 -0.88235295]\n",
      "   [-0.48235291 -0.70980394 -0.89019608]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.03529418 -0.01960784 -0.19215685]\n",
      "   [ 0.06666672 -0.01960784 -0.18431371]\n",
      "   [ 0.09019613 -0.02745098 -0.18431371]\n",
      "   ...\n",
      "   [ 0.23137259  0.17647064 -0.23137254]\n",
      "   [ 0.15294123  0.02745104 -0.27058822]\n",
      "   [ 0.30196083  0.20784318 -0.13725489]]\n",
      "\n",
      "  [[ 0.05098045 -0.01176471 -0.17647058]\n",
      "   [ 0.06666672 -0.00392157 -0.16862744]\n",
      "   [ 0.07450986  0.00392163 -0.1607843 ]\n",
      "   ...\n",
      "   [ 0.20784318  0.18431377 -0.17647058]\n",
      "   [ 0.22352946  0.15294123 -0.10588235]\n",
      "   [ 0.20784318  0.13725495 -0.16862744]]\n",
      "\n",
      "  [[-0.12156862 -0.18431371 -0.30196077]\n",
      "   [-0.12156862 -0.17647058 -0.29411763]\n",
      "   [-0.12156862 -0.17647058 -0.29411763]\n",
      "   ...\n",
      "   [-0.27843136 -0.34117645 -0.46666664]\n",
      "   [-0.27843136 -0.31764704 -0.48235291]\n",
      "   [-0.23137254 -0.27843136 -0.38823527]]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Accuracy Score: 1.000\n",
      "Confusion Matrix\n",
      "[[32]]\n"
     ]
    }
   ],
   "source": [
    "ytest, ytest_ = [], []\n",
    "i = 0\n",
    "for [X1test, X2test], Ytest in test_pair_gen:\n",
    "    i += 1\n",
    "    print(X1test)\n",
    "    if curr_test_steps > num_test_steps:\n",
    "        break\n",
    "    Ytest_ = best_model.predict([X1test, X2test])\n",
    "    ytest.extend(np.argmax(Ytest, axis=1).tolist())\n",
    "    ytest_.extend(np.argmax(Ytest_, axis=1).tolist())\n",
    "    curr_test_steps += 1\n",
    "    print(ytest)\n",
    "    print(ytest_)\n",
    "    break\n",
    "\n",
    "acc = accuracy_score(ytest, ytest_)\n",
    "cm = confusion_matrix(ytest, ytest_)\n",
    "\n",
    "print(\"Accuracy Score: {:.3f}\".format(acc))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
